# Normal Error Regression Model


**Learning Outcomes:**     

1. Explain when it is appropriate to use "theory-based" standard error formulas.   
2. Interpret estimates, standard errors, test statistics, and p-values resulting from linear model output in R.   
3. List the assumptions made in the normal error regression model.   
4. Calculate p-values corresponding to t-statistics and F-statistics in R.   
5. Interpret confidence intervals for an expected response, and prediction intervals, and distinguish between these two types of intervals.   
6. Assess the whether linear model assumptions are reasonably satisfied, using residual plots, histograms, and normal QQ plots.  
7. Explain when we should or should not expect p-values and confidence intervals obtained via "theory-based" approaches to agree with those obtained via simulation.   

8. Identify situations where a log transformation of the response variable is appropriate.   
9. Calculate predicted values for models involving a log transformation of the response variable.    
10. Interpret regression coefficients in models involving a log transformation of the response variable.   
11. Explain the regression effect.   

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, fig.height = 3, fig.width = 7, cache=TRUE)
library(ggformula)
library(moderndive)
library(gridExtra)
library(skimr)
library(Bolstad)
library(GGally)
library(Lock5Data)
library(knitr)
library(caret)
library(MASS)
library(tidyverse)
options(scipen=999)
set.seed(07302020)
```



## Estimating Standard Error 

### Standard Error vs Standard Deviation 

Recall that standard error is the standard deviation of the distribution of a statistic (sample mean, proportion, regression coefficient, etc.). It describes the amount of variability in this statistic between samples of a given size.  

This is different than the sample standard deviation, which pertains to the amount of variability between individuals in the sample. 

For example, the histogram displays the distribution of mercury levels in our sample of 53 lakes in Florida.

```{r}
Lakes_Hist
```

Standard Deviation of Mercury Levels Between Lakes:

```{r}
sd(FloridaLakes$Mercury)
```


The standard deviation in mercury levels between individual lakes is 0.341 ppm. This describes the amount of variability in mercury levels between individual lakes. 

Bootstrap Distribution for Mean Mercury Level ($n=53$)

```{r}
Lakes_Bootstrap_Mean_Plot + xlim(c(0,1.5))
```

Standard Error for Mean: 

```{r}
SE <- sd(Lakes_Bootstrap_Results_Mean$Bootstrap_Mean); SE
```

The standard deviation in the distribution for mean mercury levels between different samples of 53 lakes is approximately `r SE` ppm. This describes the amount of variability in mean mercury levels between different samples of 53 lakes.  

There is less variability in average among samples of size 53, than there is between mercury levels of individual lakes. Although mercury levels might vary quite a bit between individual lakes, in a sample of size 53, the higher and lower levels tend to average out to something in the middle, resulting in less variability associated with the average than with individual lakes. 

### Sample Size and Standard Error

**Question:**   

Suppose the sample consisted of 10 lakes, or 30 lakes, or 100 lakes, instead of 53, and that the distribution of the  lakes in the sample was otherwise similar to that of the original 53. Would you expect the mercury level of individual lakes to increase, decrease, or stay about the same? What about the standard error of the mean mercury level?    


```{r, echo=FALSE}
set.seed(10122022)
LakesSample10 <- sample_n(FloridaLakes, 10, replace=TRUE)
LakesSample30 <- sample_n(FloridaLakes, 30, replace=TRUE)
LakesSample100 <- sample_n(FloridaLakes, 1000, replace=TRUE)
```

```{r, echo=FALSE, fig.width=12, fig.height=6}
Lakes_Hist10 <- ggplot(data=LakesSample10, aes(x=Mercury)) + 
  geom_histogram(color="white", fill="lightblue", binwidth = 0.2) + 
  ggtitle("n=10") + 
  xlab("Mercury Level") + ylab("Frequency") + xlim(c(-0.2,1.7))

Lakes_Hist30 <- ggplot(data=LakesSample30, aes(x=Mercury)) + 
  geom_histogram(color="white", fill="lightblue", binwidth = 0.2) + 
  ggtitle("n=30") + 
  xlab("Mercury Level") + ylab("Frequency") + xlim(c(-0.2,1.7))

Lakes_Hist53 <- Lakes_Hist + ggtitle("n=53") + xlim(c(-0.2,1.7))
Lakes_Hist100 <- ggplot(data=LakesSample100, aes(x=Mercury)) + 
  geom_histogram(color="white", fill="lightblue", binwidth = 0.2) + 
  ggtitle("n=100") + 
  xlab("Mercury Level") + ylab("Frequency") + xlim(c(-0.2,1.7))

grid.arrange(Lakes_Hist10, Lakes_Hist30, Lakes_Hist53,Lakes_Hist100, ncol=2)
```

The table shows the standard deviation in each of the samples. 

```{r, echo=FALSE}
SD10 <- sd(LakesSample10$Mercury)
SD30 <- sd(LakesSample30$Mercury)
SD53 <- sd(FloridaLakes$Mercury)
SD100 <- sd(LakesSample100$Mercury)
Sample_Size <- c(10,30,53,100)
SD <- c(SD10, SD30, SD53, SD100)
kable(data.frame(Sample_Size, SD))
```

Sample size does not impact the amount of variability between individual lakes. Standard deviation in mercury levels between individual lakes does not systematically increase or decrease based on sample size (of course it varies a little based on the lakes randomly chosen in the sample).   

Now, we'll examine what happens to the standard error of the mean as the sample size changes.      

```{r, echo=FALSE}
MeanHg10 <- rep(NA, 10000)
MeanHg30 <- rep(NA, 10000)
MeanHg100 <- rep(NA, 10000)

for (i in 1:10000){
BootstrapSample <- sample_n(LakesSample10, 10, replace=TRUE) 
MeanHg10[i] <- mean(BootstrapSample$Mercury)
BootstrapSample <- sample_n(LakesSample30, 30, replace=TRUE) 
MeanHg30[i] <- mean(BootstrapSample$Mercury)
BootstrapSample <- sample_n(LakesSample100, 100, replace=TRUE) 
MeanHg100[i] <- mean(BootstrapSample$Mercury)
}
Lakes_Bootstrap_Results_Mean_Comp <- data.frame(MeanHg10, MeanHg30, MeanHg100)
```

**Distributions of Mean Between Different Samples**

```{r, echo=FALSE, fig.width=12, fig.height=6}
Lakes_Bootstrap_Mean10 <- ggplot(data=Lakes_Bootstrap_Results_Mean_Comp, aes(x=MeanHg10)) +  
  geom_histogram(color="white", fill="lightblue") +
  xlab("Sample Mean") + ylab("Frequency") +
  ggtitle("n=10") + xlim(c(0,1)) + 
  theme(legend.position = "none")

Lakes_Bootstrap_Mean30 <- ggplot(data=Lakes_Bootstrap_Results_Mean_Comp, aes(x=MeanHg30)) +  
  geom_histogram(color="white", fill="lightblue") +
  xlab("Sample Mean") + ylab("Frequency") +
  ggtitle("n=30") + xlim(c(0,1)) +
  theme(legend.position = "none") 

Lakes_Bootstrap_Mean53 <- Lakes_Bootstrap_Mean_Plot + ggtitle("n=53)") + xlim(c(0,1)) + xlab("Sample Mean")

Lakes_Bootstrap_Mean100 <- ggplot(data=Lakes_Bootstrap_Results_Mean_Comp, aes(x=MeanHg100)) +  
  geom_histogram(color="white", fill="lightblue", bins=60) +
  xlab("Sample Mean") + ylab("Frequency") +
  ggtitle("n=100") + xlim(c(0,1)) +
  theme(legend.position = "none") 

grid.arrange(Lakes_Bootstrap_Mean10, Lakes_Bootstrap_Mean30, Lakes_Bootstrap_Mean53, Lakes_Bootstrap_Mean100, ncol=2)
```


The table shows the standard error of the mean for samples of different size:

```{r, echo=FALSE}
SE10 <- sd(Lakes_Bootstrap_Results_Mean_Comp$MeanHg10)
SE30 <- sd(Lakes_Bootstrap_Results_Mean_Comp$MeanHg30)
SE53 <- sd(Lakes_Bootstrap_Results_Mean$Bootstrap_Mean)
SE100 <- sd(Lakes_Bootstrap_Results_Mean_Comp$MeanHg100)
Sample_Size <- c(10,30,53,100)
SE <- c(SE10, SE30, SE53, SE100)
kable(data.frame(Sample_Size, SE))
```

As sample size increases, variability between means of different samples decreases. Standard error of the mean decreases. This is also true of standard errors for other statistics (i.e. difference in means, regression slopes, etc.)

### Standard Error Formulas

So far, we've used simulation (permutation tests and bootstrap intervals) to determine the amount of variability associated with a test statistic or estimate, in order to perform hypotheses tests and create confidence intervals. In special situations, there are mathematical formulas, based on probability theory, that can be used to approximate the amount of variability without having to perform the simulations. 

These approximations only exist for certain kinds of statistics, and they are only valid when the sampling distribution for the statistic is symmetric and bell-shaped. Thus, they cannot be used in all situations, and we should be careful to check whether they are appropriate before applying them. Nevertheless, when appropriate, they can allow us to bypass the computation required in a simulation.   

**Theory-Based Standard Error Formulas**

|Scenario| Standard Error | 
|---------|-----|     
| Single Mean | $SE(b_0)=\frac{s}{\sqrt{n}}$ |   
| Difference in Means | $SE(b_j)=s\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}$ |   
| Single Proportion| $SE(\hat{p}) = \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$|
| Difference in Proportions| $SE(\hat{p}) = \sqrt{\left(\frac{\hat{p_1}(1-\hat{p}_1)}{n_1}+\frac{\hat{p_2}(1-\hat{p_2})}{n_2}\right)}$|
| Intercept in Simple Linear Regression | $SE(b_0)=s\sqrt{\frac{1}{n}+\frac{\bar{x}^2}{\sum(x_i-\bar{x})^2}}$ |    
| Slope in Simple Linear Regression | $SE(b_1)=\sqrt{\frac{s^2}{\sum(x_i-\bar{x})^2}}=\sqrt{\frac{1}{n-2}\frac{{\sum(\hat{y}_i-y_i)^2}}{\sum(x_i-\bar{x})^2}}$ | 

* $s=\sqrt{\frac{\displaystyle\sum_{i=1}^n(y_i-\hat{y}_i)^2}{(n-(p+1))}}$, (p is number of regression coefficients not including $b_0$) is sample standard deviation. Note that in the one-sample case, this simplifies to the standard deviation formula we've seen previously.        

* In the 2nd formula, the standard error estimate $s\sqrt{\frac{1}{n_1+n_2}}$ is called a "pooled" estimate since it combines information from all groups. When there is reason to believe standard deviation differs between groups, we often use an "unpooled" standard error estimate of $\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}$, where $s_1, s_2$ represent the standard deviation for groups 1 and 2. 

There is no theory-based formula for standard error associated with the median or standard deviation. For these, and many other statistics, we rely on simulation to estimate variability between samples. 

There are formulas for standard errors associated with coefficients in multiple regression, but these require mathematics beyond what is assumed in this class. They involve linear algebra and matrix inversion, which you can read about [here](https://web.stanford.edu/~mrosenfe/soc_meth_proj3/matrix_OLS_NYU_notes.pdf) if you are interested. 


### One-Sample Mean Example

We use the first formula to calculate the standard error of the mean mercury concentration associated with samples of 53 lakes. 

$SE(\bar{x})=\frac{s}{\sqrt{n}} = \frac{0.341}{\sqrt{53}}=0.04684$

The calculation in R is shown below. 

```{r}
sd(FloridaLakes$Mercury)/sqrt(53)
```

The standard error column in the R summary output is calculated using the theory-based formulas.  

```{r}
M <- lm(data=FloridaLakes, Mercury~1)
summary(M)
```


Let's compare this to the standard error we obtained using 10,000 bootstrap simulations.  

```{r}
Lakes_Bootstrap_Mean_Plot
```

Bootstrap standard error: 

```{r}
SE <- sd(Lakes_Bootstrap_Results_Mean$Bootstrap_Mean); SE
```

The theory-based formula gives a standard error estimate very close to the one we obtained via bootstrap simulation.   



### Difference in Means Example

We use the probability-based formula to calculate the standard error for difference in means between 33 lakes in North Florida, and 20 lakes in South Florida

\[
SE(\bar{x}_1-\bar{x}_2)=s\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}, 
\]


```{r}
s <- sqrt(sum(Lakes_M$residuals^2)/(53-2))
SE <- s*sqrt(1/20+1/33); SE
```

R model summary output:

```{r}
Lakes_M <- lm(data=FloridaLakes, Mercury~Location)
summary(Lakes_M)
```

Comparison to Bootstrap standard error:    

```{r}
NS_Lakes_Bootstrap_Plot_b1 <- ggplot(data=NS_Lakes_Bootstrap_Results, aes(x=Bootstrap_b1)) +  
  geom_histogram(color="white", fill="lightblue") + 
  xlab("b1 in Bootstrap Sample") + ylab("Frequency") +
  ggtitle("Northern vs Southern Lakes: Bootstrap Distribution for b1") 
NS_Lakes_Bootstrap_Plot_b1 
```

```{r}
sd(NS_Lakes_Bootstrap_Results$Bootstrap_b1)
```

The mathematical standard error approximation is close to the one observed in our simulation, though not exact. 


### Regression Example            

We use the theory-based approach to calculate standard error associated with the slope of the regression line relating mercury level and pH in Florida lakes.  


$SE(b_1)=\sqrt{\frac{s^2}{\sum(x_i-\bar{x})^2}}=\sqrt{\frac{1}{n-2}\frac{{\sum(\hat{y}_i-y_i)^2}}{\sum(x_i-\bar{x})^2}}$ 

```{r}
M <- lm(data=FloridaLakes, Mercury~pH) # fit model
s2 <- sum(M$residuals^2)/(53-2) #calculate s^2
x <- FloridaLakes$pH
SSx <- sum((x-mean(x))^2) #calculate denominator
SE <- sqrt(s2/SSx) # calculate SE
SE
```

R model summary output:


```{r}
Lakes_M_pH <- lm(data=FloridaLakes, Mercury~pH)
summary(Lakes_M_pH)
```

Comparison to bootstrap standard error:

```{r}
Lakes_Bootstrap_Plot_Slope
```

```{r}
SE_b1 <- sd(Lakes_Bootstrap_Slope_Results$Bootstrap_b1)
SE_b1
```

The mathematical standard error approximation is again close to the one observed in our simulation. 


### Theory-Based Confidence Intervals


If the sampling distribution for a statistic is symmetric and bell-shaped, we can obtain an approximate 95% confidence interval using the formula:

\[
\text{Statistic} \pm 2\times{\text{Standard Error}},
\]

where the standard error is calculated by formula, rather than via bootstrap simulations. 

The `confint` command in R provides confidence intervals associate with each of the model parameters, which are calculated using the theory-based standard errors

**Confidence Intervals for N vs S Florida Lakes**

```{r}
confint(Lakes_M)
```

**Intercept Interval:**

$\approx 0.42455  \pm  2\times0.05519$

We are 95% confident that the average mercury level among all lakes in North Florida is between 0.313 and 0.535 ppm.   

**LocationS Interpretation**

$\approx -0.15230  \pm  0.03031$

We are 95% confident that the average mercury level among all lakes in South Florida is between 0.09 and 0.45 ppm higher than the average mercury concentration among all lakes in North Florida.   

Note that the use of 2 in the confidence interval formula is an approximation, though one that is reasonable and widely used. Rather than using 2, R uses a value very close to 2, which varies depending on the sample size. Thus R's calculations will not exactly match the formulas shown, but are similar enough for practical purposes. Remember that in statistics, everything is an approximation. 

**Confidence Intervals for pH and Mercury in Florida Lakes**

```{r}
confint(Lakes_M_pH)
```

**Intercept Interval:**

$\approx 1.53092  \pm  2\times 0.20349$

We are 95% confident that the average mercury concentration among all lakes with pH level 0 is between 1.12 and 1.94 ppm. This is not a meaningful interpretation, since none of the lakes in our sample have a pH level anywhere close to 0.  

**pH Interval**

$\approx -0.15230   \pm 2\times 0.03031$

We are 95% confident that for each one-unit increase in pH, mercury level is expected to decrease between 0.09 and 0.21 ppm, on average.   




### CI Method Comparison

We've now seen 3 different ways to obtain confidence intervals based on statistics calculated from data.    

The table below tells us what must be true of the sampling distribution for a statistic in order to use each technique.     


|  Technique  | No Gaps | Bell-Shaped | Known Formula for SE |
|----------|------------|------------|--------------------|
| Bootstrap Percentile |  x  |    |    |
| Bootstrap Standard Error |  x   |   x   |    |
| Theory-Based | x  |  x   |  x   | 



## Theory-Based Hypothesis Tests

### `lm` `summary` Output 

Recall our linear model for mercury levels of lakes in Northern Florida, compared to Southern Florida. 

The equation of the model is:

\[
\widehat{\text{Mercury}} = \beta_0+\beta_1\times\text{South}
\]

We fit the model in R and display its summary output below.  

```{r}
summary(Lakes_M)
```

The estimated regression equation is 

\[
\widehat{\text{Mercury}} = 0.42455+0.27195\times\text{South}
\]

We've seen how to obtain the first two columns of the summary table, labeled "Estimate" and "Std. Error". 

The last column, labeled "Pr(>|t|)" is, in fact a p-value associated with associated with the null hypothesis that the regression parameter on that line is zero. (i.e. $\beta_j=0$).    

**Columns in Linear Model `summary()` Output**

* **Estimate** gives the least-squares estimates $b_0, b_1, \ldots, b_p$     

* **Standard Error** gives estimates of the standard deviation in the sampling distribution for estimate. (i.e. how much uncertainty is there about the estimate?) These are computed using the formulas in Section 4.7.   

* **t value** is the estimate divided by its standard error.     

* **Pr(>|t|)** is a p-value for the hypothesis test of $\beta_j=0$, where $\beta_j$ is the relevant population parameter represented.  (i.e. mean, difference in means, slope, etc.) 

R does not perform its hypothesis test using permutation. Instead, it relies on a mathematical approximation based on probability theory.   

### N vs S Florida Lakes

**Hypothesis Test for line (intercept)**

**Null Hypothesis:** The average mercury level among all lakes in North Florida is 0 ($\beta_0=0$).   

**Alternative Hypothesis:** The average mercury level among all lakes in Northern Florida is not 0 ($\beta_0\neq 0$).  

We already know the average mercury level among all lakes in North Florida is not 0, so this is a silly test. 

**Hypothesis Test for line LocationS**

**Null Hypothesis:** There is no difference in average mercury levels between Northern and Southern Florida ($\beta_1=0$).   

**Alternative Hypothesis:** There is a difference in average mercury levels in Northern and Southern Florida ($\beta_1\neq 0$).  

This test is relevant to us.  

### Recall Permuation Test

Recall our results when we performed this hypothesis test using permutation. 

**Permutation Test**

```{r}
NSLakes_SimulationResultsPlot
```

p-value:

```{r}
b1 <- Lakes_M$coef[2] ## record value of b1 from actual data

mean(abs(NSLakes_SimulationResults$b1Sim) > abs(b1))
```

Notice that the sampling distribution of our permutation test statistics, simulated under the assumption that the null hypothesis is true, was symmetric and bell-shaped. 


### t-distribution

When the sampling distribution of a test statistic is symmetric and bell-shaped, it can be approximated by a symmetric, bell-shaped curve, called a t-distribution. 

The t-distribution is actually a family of symmetric and bell-shaped curves, each indexed by a parameter called it *degrees of freedom*. As the number of degrees of freedom increase, the t-distribution converges to a symmetric, bell-shaped curve called a normal distribution. 

Degrees of freedom are a highly theoretical mathematical concept, which we won't pay much attention to in this class. The idea is that we are using a symmetric, bell-shaped curve to approximate the behavior of the test statistic, seen in the permutation test.  

```{r, fig.height=5, fig.width=10, warning=FALSE, message=FALSE, include=FALSE}
gf_dist("t", df=3, color = ~ "3 df", kind = "density")  %>%
gf_dist("t", df=10, color = ~ "10 df", kind = "density") %>%
gf_dist("t", df=20, color = ~ "20 df", kind = "density") %>%
gf_dist("t", df=30, color = ~ "30 df", kind = "density") %>%
gf_dist("norm", color = ~ "N(0,1)", kind = "density") + xlim(c(-3,3))
```

```{r, echo=FALSE, fig.height=5, fig.width=10}
dt1 <- function(x){
  dt(x, df=3)
}
dt2 <- function(x){
  dt(x, df=10)
}
dt3 <- function(x){
  dt(x, df=20)
}
dt4 <- function(x){
  dt(x, df=30)
}

```

```{r, echo=FALSE, fig.height=6, fig.width=8}
df <- data.frame(x = seq(from=-3, to=3, by=0.1), y = dnorm(seq(from=-3, to=3, by=0.1), 0,1/sqrt(3)))
p <- ggplot(df, aes(x = x, y = y)) + xlab("t")+
  stat_function(fun=dnorm,geom="line",color=scales::hue_pal()(5)[1]) + 
  annotate(geom="text", x=0.5, y=0.4, label="N(0,1)",
              color=scales::hue_pal()(5)[1]) +
    stat_function(fun=dt1, geom="line",color=scales::hue_pal()(5)[2]) +
   annotate(geom="text", x=0, y=0.35, label="t with 3 df",
              color=scales::hue_pal()(5)[2]) +
    stat_function(fun=dt2, geom="line",color=scales::hue_pal()(5)[3]) +
    annotate(geom="text", x=0, y=0.37, label="t with 10 df",
              color=scales::hue_pal()(5)[3]) +
      stat_function(fun=dt3, geom="line",color=scales::hue_pal()(5)[4]) +
   annotate(geom="text", x=0.5, y=0.38, label="t with 20 df",
              color=scales::hue_pal()(5)[4]) +
     stat_function(fun=dt, geom="line",color=scales::hue_pal()(5)[5]) +
   annotate(geom="text", x=0.5, y=0.39, label="t with 30 df",
              color=scales::hue_pal()(5)[5]) 
p
```

To perform a t-test, we divide the relevant estimate $b_j$ by its standard error. The standard error is calculated using the theory-based formulas in the previous section. 


\[
t= \frac{{b_j}}{\text{SE}(b_j)}  
\]

follows a t-distribution.

The $t=\frac{{b_j}}{\text{SE}(b_j)}$ is called a **t-statistic**.   

We'll use this t-statistic as the test statistic in our hypothesis test.  

### t-test for N vs S Lakes

**Test Statistic for Northern vs Southern Lakes** 

$t=\frac{{b_j}}{\text{SE}(b_j)} = \frac{0.27195}{0.08985} = 3.027$ 

**Key Question:** What is the probability of getting a t-statistic as extreme as 3.027 if $\beta_1=0$ (i.e. there is no difference in mercury levels between northern and southern lakes).  

We plot the t-statistic of 3.027 that we observed in our data and observe where it lies on a t-distribution.  

```{r, fig.height=4, fig.width=8}
ts=3.027
gf_dist("t", df=51, geom = "area", fill = ~ (abs(x)< abs(ts)), show.legend=FALSE) + geom_vline(xintercept=c(ts, -ts), color="red")  + xlab("t")
```

The following command calculates the area under the t-curve that is more extreme than our observed t-statistic of $\pm 3.027$. 

The `df` value can be found in the "Residual Standard Error" line of the model summary output.

Note: I will not actually ask you to calculate p-values this way, as we can get them directly from the R-output. This illustration is intended to show you what R is doing behind the scenes to obtain this value.  

```{r}
2*pt(-abs(ts), df=51)
```

The low p-value gives us strong evidence of a difference in average mercury levels between lakes in Northern and Southern Florida.  

Notice that the t-statistic and p-value we calculated match the values seen on the `LocationS` line of the R summary output.  

The p-value provided by the t-test is also very similar to the one we obtained previously in the permutation test. This will generally be true, as long as the sampling distribution for our test statistic is symmetric and bell-shaped.    


### t-test for pH vs Mercury

Recall our test for evidence of a relationship between pH and mercury level in Florida lakes.  

```{r}
ggplot(data=FloridaLakes, aes(y=Mercury, x=pH)) + 
  geom_point() + stat_smooth(method="lm", se=FALSE) + 
  xlim(c(3, 10)) + ylim(c(0,1.5))
```

**Null Hypothesis:** Among all Florida lakes, there is no relationship between mercury level and pH. (i.e. $\beta_1=0$)   

**Alternative Hypothesis:** Among all Florida lakes, there is a relationship between mercury level and pH.  (i.e. $\beta_1\neq 0$)       

The permutation distribution and p-value we obtained are shown below.   

```{r}
b1 <- Lakes_M_pH$coef[2] ## record value of b1 from actual data
Lakes_pHSimulationResultsPlot <- ggplot(data=Lakes_pHSimulationResults, aes(x=b1Sim)) + 
  geom_histogram(fill="lightblue", color="white") + 
  geom_vline(xintercept=c(b1, -1*b1), color="red") + 
  xlab("Simulated Value of b1") + ylab("Frequency") + 
  ggtitle("Distribution of b1 under assumption of no relationship")
Lakes_pHSimulationResultsPlot
```

**p-value:** Proportion of simulations resulting in value of $b_1$ more extreme than -0.15 

```{r}
mean(abs(b1Sim) > abs(b1))
```

The R output for the model summary is shown below. 

```{r}
summary(Lakes_M_pH)
```

Notice that the p-value shown on the `pH` line, representing slope is practically 0, which is consistent with our simulation. 

The t-statistic shown on the line `pH` line is calculated using the formula:  

$t=\frac{{b_j}}{\text{SE}(b_j)} = \frac{-0.15230}{0.03031} = -5.024$ 

**Key Question:** What is the probability of getting a t-statistic as extreme as -5.024 if $\beta_1=0$ (i.e. there is no relationship between mercury and pH among all Florida lakes).  

We plot the t-statistic of -5.024 that we observed in our data and observe where it lies on a t-distribution.  

```{r, fig.height=4, fig.width=8}
ts=-5.024
gf_dist("t", df=51, geom = "area", fill = ~ (abs(x)< abs(ts)), show.legend=FALSE) + geom_vline(xintercept=c(ts, -ts), color="red")  + xlab("t")
```

We calculate the area under the t-curve that is more extreme than our observed t-statistic of $\pm 5.024$. 

```{r}
2*pt(-abs(ts), df=51)
```

This matches the very small p-value seen in the R output, and is consistent with our simulation.  

### t-test on Intercept Line

We've talked about the hypothesis test associated with the line `pH`, in the model summary output. This line pertains to the slope of the line of best fit.   

```{r}
summary(Lakes_M_pH)
```
Notice the (Intercept) shows a t-statistic of 7.523, and a very small p-value. What should we conclude from these? What hypotheses are being tested here?

Recall that the p-value always pertains to a test that the parameter associated with that line is 0 ($\beta_j=0$). 
The parameter associated with the line (Intercept) is $\beta_0$, which represents the average mercury level among all lakes with a pH level of 0. 

Thus, the hypotheses being tested here are:

**Null Hypothesis:** The average mercury level among all Florida lakes with pH level 0 is 0.

**Alternative Hypothesis:** The average mercury level among all Florida lakes with a pH level of 0 is not 0.   

Of course, the lowest pH level among the lakes observed in our sample is just under 4, so it doesn't make sense to draw conclusions about lakes with pH level 0. Thus, this test is meaningless.   

Not every p-value provided by R tells us anything meaningful. Some attempt to answer questions that no one would ever want to ask!


## F-Distributions

## Theory-Based Inference Cautions




