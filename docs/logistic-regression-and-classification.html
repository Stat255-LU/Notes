<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Logistic Regression and Classification | Stat 255: Statistics for Data Science Notes</title>
  <meta name="description" content="Chapter 8 Logistic Regression and Classification | Stat 255: Statistics for Data Science Notes" />
  <meta name="generator" content="bookdown 0.27 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Logistic Regression and Classification | Stat 255: Statistics for Data Science Notes" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Logistic Regression and Classification | Stat 255: Statistics for Data Science Notes" />
  
  
  

<meta name="author" content="Andrew Sage - Lawrence University" />


<meta name="date" content="2023-11-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="predictive-modeling.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">STAT 255 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html"><i class="fa fa-check"></i><b>1</b> Exploratory Data Analysis</a><ul>
<li class="chapter" data-level="1.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#getting-started-in-r"><i class="fa fa-check"></i><b>1.1</b> Getting Started in R</a><ul>
<li class="chapter" data-level="1.1.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#previewing-the-data"><i class="fa fa-check"></i><b>1.1.1</b> Previewing the Data</a></li>
<li class="chapter" data-level="1.1.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#modifying-the-data"><i class="fa fa-check"></i><b>1.1.2</b> Modifying the Data</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#data-visualization"><i class="fa fa-check"></i><b>1.2</b> Data Visualization</a><ul>
<li class="chapter" data-level="1.2.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#histogram"><i class="fa fa-check"></i><b>1.2.1</b> Histogram</a></li>
<li class="chapter" data-level="1.2.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#density-plot"><i class="fa fa-check"></i><b>1.2.2</b> Density Plot</a></li>
<li class="chapter" data-level="1.2.3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boxplot"><i class="fa fa-check"></i><b>1.2.3</b> Boxplot</a></li>
<li class="chapter" data-level="1.2.4" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#violin-plot"><i class="fa fa-check"></i><b>1.2.4</b> Violin Plot</a></li>
<li class="chapter" data-level="1.2.5" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#scatterplot"><i class="fa fa-check"></i><b>1.2.5</b> Scatterplot</a></li>
<li class="chapter" data-level="1.2.6" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#bar-graph"><i class="fa fa-check"></i><b>1.2.6</b> Bar Graph</a></li>
<li class="chapter" data-level="1.2.7" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#stacked-and-side-by-side-bar-graphs"><i class="fa fa-check"></i><b>1.2.7</b> Stacked and Side-by-Side Bar Graphs</a></li>
<li class="chapter" data-level="1.2.8" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#correlation-plot"><i class="fa fa-check"></i><b>1.2.8</b> Correlation Plot</a></li>
<li class="chapter" data-level="1.2.9" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#scatterplot-matrix"><i class="fa fa-check"></i><b>1.2.9</b> Scatterplot Matrix</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#summary-tables"><i class="fa fa-check"></i><b>1.3</b> Summary Tables</a><ul>
<li class="chapter" data-level="1.3.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#calculating-summary-statistics"><i class="fa fa-check"></i><b>1.3.1</b> Calculating Summary Statistics</a></li>
<li class="chapter" data-level="1.3.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#grouped-summaries"><i class="fa fa-check"></i><b>1.3.2</b> Grouped Summaries</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html"><i class="fa fa-check"></i><b>2</b> Introduction to Statistical Models</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#fitting-models-to-data"><i class="fa fa-check"></i><b>2.1</b> Fitting Models to Data</a><ul>
<li class="chapter" data-level="2.1.1" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#terminology"><i class="fa fa-check"></i><b>2.1.1</b> Terminology</a></li>
<li class="chapter" data-level="2.1.2" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#model-with-quantitative-explanatory-variable"><i class="fa fa-check"></i><b>2.1.2</b> Model with Quantitative Explanatory Variable</a></li>
<li class="chapter" data-level="2.1.3" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#model-with-categorical-variable"><i class="fa fa-check"></i><b>2.1.3</b> Model with Categorical Variable</a></li>
<li class="chapter" data-level="2.1.4" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#model-with-multiple-explanatory-variables"><i class="fa fa-check"></i><b>2.1.4</b> Model with Multiple Explanatory Variables</a></li>
<li class="chapter" data-level="2.1.5" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#model-with-no-explanatory-variable"><i class="fa fa-check"></i><b>2.1.5</b> Model with No Explanatory Variable</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#variability-explained-by-a-model"><i class="fa fa-check"></i><b>2.2</b> Variability Explained by a Model</a><ul>
<li class="chapter" data-level="2.2.1" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#quantifying-variability"><i class="fa fa-check"></i><b>2.2.1</b> Quantifying Variability</a></li>
<li class="chapter" data-level="2.2.2" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#total-variability"><i class="fa fa-check"></i><b>2.2.2</b> Total Variability</a></li>
<li class="chapter" data-level="2.2.3" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#residuals"><i class="fa fa-check"></i><b>2.2.3</b> Residuals</a></li>
<li class="chapter" data-level="2.2.4" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#variability-explained-by-sq.-ft.-model"><i class="fa fa-check"></i><b>2.2.4</b> Variability Explained by Sq. Ft. Model</a></li>
<li class="chapter" data-level="2.2.5" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#linear-correlation-coefficient"><i class="fa fa-check"></i><b>2.2.5</b> Linear Correlation Coefficient</a></li>
<li class="chapter" data-level="2.2.6" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#variability-explained-by-waterfront-model"><i class="fa fa-check"></i><b>2.2.6</b> Variability Explained by Waterfront Model</a></li>
<li class="chapter" data-level="2.2.7" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#variability-explained-by-multiple-regression-model"><i class="fa fa-check"></i><b>2.2.7</b> Variability Explained by Multiple Regression Model</a></li>
<li class="chapter" data-level="2.2.8" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#summary-sst-ssr-ssm-r2"><i class="fa fa-check"></i><b>2.2.8</b> Summary: SST, SSR, SSM, <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="2.2.9" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#r2-visually"><i class="fa fa-check"></i><b>2.2.9</b> <span class="math inline">\(R^2\)</span> Visually</a></li>
<li class="chapter" data-level="2.2.10" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#model-comparison-summary"><i class="fa fa-check"></i><b>2.2.10</b> Model Comparison Summary</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#models-with-interaction"><i class="fa fa-check"></i><b>2.3</b> Models with Interaction</a><ul>
<li class="chapter" data-level="2.3.1" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#definition-of-interaction"><i class="fa fa-check"></i><b>2.3.1</b> Definition of Interaction</a></li>
<li class="chapter" data-level="2.3.2" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#interaction-term"><i class="fa fa-check"></i><b>2.3.2</b> Interaction Term</a></li>
<li class="chapter" data-level="2.3.3" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#interaction-models-in-r"><i class="fa fa-check"></i><b>2.3.3</b> Interaction Models in R</a></li>
<li class="chapter" data-level="2.3.4" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#r2-for-interaction-model"><i class="fa fa-check"></i><b>2.3.4</b> <span class="math inline">\(R^2\)</span> for Interaction Model</a></li>
<li class="chapter" data-level="2.3.5" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#considerations-for-using-interactions"><i class="fa fa-check"></i><b>2.3.5</b> Considerations for Using Interactions</a></li>
<li class="chapter" data-level="2.3.6" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#interaction-vs-correlation"><i class="fa fa-check"></i><b>2.3.6</b> Interaction vs Correlation</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#least-squares-estimation-lse"><i class="fa fa-check"></i><b>2.4</b> Least Squares Estimation (LSE)</a><ul>
<li class="chapter" data-level="2.4.1" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#estimating-regression-coefficients"><i class="fa fa-check"></i><b>2.4.1</b> Estimating Regression Coefficients</a></li>
<li class="chapter" data-level="2.4.2" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#mathematics-of-lse-for-slr"><i class="fa fa-check"></i><b>2.4.2</b> Mathematics of LSE for SLR</a></li>
<li class="chapter" data-level="2.4.3" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#lse-for-categorical-variable"><i class="fa fa-check"></i><b>2.4.3</b> LSE for Categorical Variable</a></li>
<li class="chapter" data-level="2.4.4" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#lse-more-generally"><i class="fa fa-check"></i><b>2.4.4</b> LSE More Generally</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#analysis-of-variance"><i class="fa fa-check"></i><b>2.5</b> ANalysis Of VAriance</a><ul>
<li class="chapter" data-level="2.5.1" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#submodels"><i class="fa fa-check"></i><b>2.5.1</b> Submodels</a></li>
<li class="chapter" data-level="2.5.2" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#f-statistics"><i class="fa fa-check"></i><b>2.5.2</b> F-Statistics</a></li>
<li class="chapter" data-level="2.5.3" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#comparing-3-or-more-categories"><i class="fa fa-check"></i><b>2.5.3</b> Comparing 3 or More Categories</a></li>
<li class="chapter" data-level="2.5.4" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#f-statistic-illustration"><i class="fa fa-check"></i><b>2.5.4</b> F-Statistic Illustration</a></li>
<li class="chapter" data-level="2.5.5" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#alternative-f-statistic-formula"><i class="fa fa-check"></i><b>2.5.5</b> Alternative F-Statistic Formula</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html"><i class="fa fa-check"></i><b>3</b> Hypothesis Testing via Permutation</a><ul>
<li class="chapter" data-level="3.1" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#test-for-difference-in-means"><i class="fa fa-check"></i><b>3.1</b> Test for Difference in Means</a><ul>
<li class="chapter" data-level="3.1.1" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#mercury-levels-in-florida-lakes"><i class="fa fa-check"></i><b>3.1.1</b> Mercury Levels in Florida Lakes</a></li>
<li class="chapter" data-level="3.1.2" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#model-for-mercury-level"><i class="fa fa-check"></i><b>3.1.2</b> Model for Mercury Level</a></li>
<li class="chapter" data-level="3.1.3" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#hypotheses-and-key-question"><i class="fa fa-check"></i><b>3.1.3</b> Hypotheses and Key Question</a></li>
<li class="chapter" data-level="3.1.4" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#permutation-test-for-difference-in-means"><i class="fa fa-check"></i><b>3.1.4</b> Permutation Test for Difference in Means</a></li>
<li class="chapter" data-level="3.1.5" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#five-permutations-in-r"><i class="fa fa-check"></i><b>3.1.5</b> Five Permutations in R</a></li>
<li class="chapter" data-level="3.1.6" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#r-code-for-permutation-test"><i class="fa fa-check"></i><b>3.1.6</b> R Code for Permutation Test</a></li>
<li class="chapter" data-level="3.1.7" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#p-values"><i class="fa fa-check"></i><b>3.1.7</b> p-values</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#general-permutation-tests"><i class="fa fa-check"></i><b>3.2</b> General Permutation Tests</a><ul>
<li class="chapter" data-level="3.2.1" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#other-test-statistics"><i class="fa fa-check"></i><b>3.2.1</b> Other Test Statistics</a></li>
<li class="chapter" data-level="3.2.2" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#general-permutation-test-procedure"><i class="fa fa-check"></i><b>3.2.2</b> General Permutation Test Procedure</a></li>
<li class="chapter" data-level="3.2.3" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#difference-in-standard-deviation"><i class="fa fa-check"></i><b>3.2.3</b> Difference in Standard Deviation</a></li>
<li class="chapter" data-level="3.2.4" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#permutation-test-for-slope"><i class="fa fa-check"></i><b>3.2.4</b> Permutation Test for Slope</a></li>
<li class="chapter" data-level="3.2.5" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#f-statistic"><i class="fa fa-check"></i><b>3.2.5</b> F-Statistic</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#responsible-hypothesis-testing"><i class="fa fa-check"></i><b>3.3</b> Responsible Hypothesis Testing</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html"><i class="fa fa-check"></i><b>4</b> Bootstrap Interval Estimation</a><ul>
<li class="chapter" data-level="4.1" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#sampling-distributions"><i class="fa fa-check"></i><b>4.1</b> Sampling Distributions</a><ul>
<li class="chapter" data-level="4.1.1" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#sampling-from-a-population"><i class="fa fa-check"></i><b>4.1.1</b> Sampling From a Population</a></li>
<li class="chapter" data-level="4.1.2" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#confidence-intervals"><i class="fa fa-check"></i><b>4.1.2</b> Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrapping"><i class="fa fa-check"></i><b>4.2</b> Bootstrapping</a><ul>
<li class="chapter" data-level="4.2.1" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#mercury-levels-in-florida-lakes-1"><i class="fa fa-check"></i><b>4.2.1</b> Mercury Levels in Florida Lakes</a></li>
<li class="chapter" data-level="4.2.2" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrap-sampling"><i class="fa fa-check"></i><b>4.2.2</b> Bootstrap Sampling</a></li>
<li class="chapter" data-level="4.2.3" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrap-samples-of-lakes"><i class="fa fa-check"></i><b>4.2.3</b> Bootstrap Samples of Lakes</a></li>
<li class="chapter" data-level="4.2.4" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrap-distribution"><i class="fa fa-check"></i><b>4.2.4</b> Bootstrap Distribution</a></li>
<li class="chapter" data-level="4.2.5" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrap-se-confidence-interval"><i class="fa fa-check"></i><b>4.2.5</b> Bootstrap SE Confidence Interval</a></li>
<li class="chapter" data-level="4.2.6" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrap-distribution-vs-sampling-distribution"><i class="fa fa-check"></i><b>4.2.6</b> Bootstrap Distribution vs Sampling Distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrap-confidence-interval-example"><i class="fa fa-check"></i><b>4.3</b> Bootstrap Confidence Interval Example</a><ul>
<li class="chapter" data-level="4.3.1" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrapping-other-statistics"><i class="fa fa-check"></i><b>4.3.1</b> Bootstrapping Other Statistics</a></li>
<li class="chapter" data-level="4.3.2" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#ci-for-mean"><i class="fa fa-check"></i><b>4.3.2</b> CI for Mean</a></li>
<li class="chapter" data-level="4.3.3" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#ci-for-standard-deviation"><i class="fa fa-check"></i><b>4.3.3</b> CI for Standard Deviation</a></li>
<li class="chapter" data-level="4.3.4" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#ci-for-median"><i class="fa fa-check"></i><b>4.3.4</b> CI for Median</a></li>
<li class="chapter" data-level="4.3.5" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#ci-for-difference-in-means"><i class="fa fa-check"></i><b>4.3.5</b> CI for Difference in Means</a></li>
<li class="chapter" data-level="4.3.6" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#ci-for-regression-slope"><i class="fa fa-check"></i><b>4.3.6</b> CI for Regression Slope</a></li>
<li class="chapter" data-level="4.3.7" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#ci-for-regression-response"><i class="fa fa-check"></i><b>4.3.7</b> CI for Regression Response</a></li>
<li class="chapter" data-level="4.3.8" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#more-cis-in-regression"><i class="fa fa-check"></i><b>4.3.8</b> More CIâ€™s in Regression</a></li>
<li class="chapter" data-level="4.3.9" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrapping-cautions"><i class="fa fa-check"></i><b>4.3.9</b> Bootstrapping Cautions</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#estimating-standard-error"><i class="fa fa-check"></i><b>4.4</b> Estimating Standard Error</a><ul>
<li class="chapter" data-level="4.4.1" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#standard-error-vs-standard-deviation"><i class="fa fa-check"></i><b>4.4.1</b> Standard Error vs Standard Deviation</a></li>
<li class="chapter" data-level="4.4.2" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#sample-size-and-standard-error"><i class="fa fa-check"></i><b>4.4.2</b> Sample Size and Standard Error</a></li>
<li class="chapter" data-level="4.4.3" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#standard-error-formulas"><i class="fa fa-check"></i><b>4.4.3</b> Standard Error Formulas</a></li>
<li class="chapter" data-level="4.4.4" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#one-sample-mean-example"><i class="fa fa-check"></i><b>4.4.4</b> One-Sample Mean Example</a></li>
<li class="chapter" data-level="4.4.5" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#difference-in-means-example"><i class="fa fa-check"></i><b>4.4.5</b> Difference in Means Example</a></li>
<li class="chapter" data-level="4.4.6" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#regression-example"><i class="fa fa-check"></i><b>4.4.6</b> Regression Example</a></li>
<li class="chapter" data-level="4.4.7" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#theory-based-confidence-intervals"><i class="fa fa-check"></i><b>4.4.7</b> Theory-Based Confidence Intervals</a></li>
<li class="chapter" data-level="4.4.8" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#ci-method-comparison"><i class="fa fa-check"></i><b>4.4.8</b> CI Method Comparison</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html"><i class="fa fa-check"></i><b>5</b> Normal Error Regression Model</a><ul>
<li class="chapter" data-level="5.1" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#the-normal-error-regression-model"><i class="fa fa-check"></i><b>5.1</b> The Normal Error Regression Model</a><ul>
<li class="chapter" data-level="5.1.1" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#example-ice-cream-dispenser"><i class="fa fa-check"></i><b>5.1.1</b> Example: Ice Cream dispenser</a></li>
<li class="chapter" data-level="5.1.2" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#signal-and-noise"><i class="fa fa-check"></i><b>5.1.2</b> Signal and Noise</a></li>
<li class="chapter" data-level="5.1.3" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#normal-distribution"><i class="fa fa-check"></i><b>5.1.3</b> Normal Distribution</a></li>
<li class="chapter" data-level="5.1.4" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#signal-and-noise-in-icecream-example"><i class="fa fa-check"></i><b>5.1.4</b> Signal and Noise in Icecream Example</a></li>
<li class="chapter" data-level="5.1.5" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#normal-error-regression-model-1"><i class="fa fa-check"></i><b>5.1.5</b> Normal Error Regression Model</a></li>
<li class="chapter" data-level="5.1.6" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#examples-of-normal-error-regression-model"><i class="fa fa-check"></i><b>5.1.6</b> Examples of Normal Error Regression Model</a></li>
<li class="chapter" data-level="5.1.7" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#implications-of-normal-error-regression-model"><i class="fa fa-check"></i><b>5.1.7</b> Implications of Normal Error Regression Model</a></li>
<li class="chapter" data-level="5.1.8" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#philosophical-question"><i class="fa fa-check"></i><b>5.1.8</b> Philosophical Question</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#inference-in-normal-error-regression-model"><i class="fa fa-check"></i><b>5.2</b> Inference in Normal Error Regression Model</a><ul>
<li class="chapter" data-level="5.2.1" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#lm-summary-output"><i class="fa fa-check"></i><b>5.2.1</b> <code>lm</code> <code>summary</code> Output</a></li>
<li class="chapter" data-level="5.2.2" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#t-distribution"><i class="fa fa-check"></i><b>5.2.2</b> t-distribution</a></li>
<li class="chapter" data-level="5.2.3" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#difference-in-means-example-1"><i class="fa fa-check"></i><b>5.2.3</b> Difference in Means Example</a></li>
<li class="chapter" data-level="5.2.4" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#simple-linear-regression-example"><i class="fa fa-check"></i><b>5.2.4</b> Simple Linear Regression Example</a></li>
<li class="chapter" data-level="5.2.5" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#multiple-regression-example"><i class="fa fa-check"></i><b>5.2.5</b> Multiple Regression Example</a></li>
<li class="chapter" data-level="5.2.6" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#mr-with-interaction-example"><i class="fa fa-check"></i><b>5.2.6</b> MR with Interaction Example</a></li>
<li class="chapter" data-level="5.2.7" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#limitations"><i class="fa fa-check"></i><b>5.2.7</b> Limitations</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#f-distributions"><i class="fa fa-check"></i><b>5.3</b> F-Distributions</a><ul>
<li class="chapter" data-level="5.3.1" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#f-distribution"><i class="fa fa-check"></i><b>5.3.1</b> F-Distribution</a></li>
<li class="chapter" data-level="5.3.2" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#house-condition-example"><i class="fa fa-check"></i><b>5.3.2</b> House Condition Example</a></li>
<li class="chapter" data-level="5.3.3" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#interaction-example"><i class="fa fa-check"></i><b>5.3.3</b> Interaction Example</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#regression-model-assumptions"><i class="fa fa-check"></i><b>5.4</b> Regression Model Assumptions</a><ul>
<li class="chapter" data-level="5.4.1" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#regression-assumptions"><i class="fa fa-check"></i><b>5.4.1</b> Regression Assumptions</a></li>
<li class="chapter" data-level="5.4.2" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#checking-model-assumptions"><i class="fa fa-check"></i><b>5.4.2</b> Checking Model Assumptions</a></li>
<li class="chapter" data-level="5.4.3" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#summary-of-checks-for-model-assumptions"><i class="fa fa-check"></i><b>5.4.3</b> Summary of Checks for Model Assumptions</a></li>
<li class="chapter" data-level="5.4.4" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#example-n-v-s-lakes"><i class="fa fa-check"></i><b>5.4.4</b> Example: N v S Lakes</a></li>
<li class="chapter" data-level="5.4.5" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#example-ph-model"><i class="fa fa-check"></i><b>5.4.5</b> Example: pH Model</a></li>
<li class="chapter" data-level="5.4.6" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#example-house-prices"><i class="fa fa-check"></i><b>5.4.6</b> Example: House Prices</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#intervals-for-expected-response"><i class="fa fa-check"></i><b>5.5</b> Intervals for Expected Response</a><ul>
<li class="chapter" data-level="5.5.1" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#parameter-values-and-expected-responses"><i class="fa fa-check"></i><b>5.5.1</b> Parameter Values and Expected Responses</a></li>
<li class="chapter" data-level="5.5.2" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#estimation-and-prediction"><i class="fa fa-check"></i><b>5.5.2</b> Estimation and Prediction</a></li>
<li class="chapter" data-level="5.5.3" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#estimation-and-prediction-in-slr"><i class="fa fa-check"></i><b>5.5.3</b> Estimation and Prediction in SLR</a></li>
<li class="chapter" data-level="5.5.4" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#intervals-in-r"><i class="fa fa-check"></i><b>5.5.4</b> Intervals in R</a></li>
<li class="chapter" data-level="5.5.5" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#slr-calculations-optional"><i class="fa fa-check"></i><b>5.5.5</b> SLR Calculations (Optional)</a></li>
<li class="chapter" data-level="5.5.6" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#car-price-and-acceleration-time"><i class="fa fa-check"></i><b>5.5.6</b> Car Price and Acceleration Time</a></li>
<li class="chapter" data-level="5.5.7" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#florida-lakes-est.-and-pred."><i class="fa fa-check"></i><b>5.5.7</b> Florida Lakes Est. and Pred.</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#transformations"><i class="fa fa-check"></i><b>5.6</b> Transformations</a><ul>
<li class="chapter" data-level="5.6.1" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#cars-assumptions-check"><i class="fa fa-check"></i><b>5.6.1</b> Cars Assumptions Check</a></li>
<li class="chapter" data-level="5.6.2" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#log-transformation"><i class="fa fa-check"></i><b>5.6.2</b> Log Transformation</a></li>
<li class="chapter" data-level="5.6.3" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#log-transform-for-car-prices"><i class="fa fa-check"></i><b>5.6.3</b> Log Transform for Car Prices</a></li>
<li class="chapter" data-level="5.6.4" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#log-model-predictions"><i class="fa fa-check"></i><b>5.6.4</b> Log Model Predictions</a></li>
<li class="chapter" data-level="5.6.5" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#log-model-interpretations"><i class="fa fa-check"></i><b>5.6.5</b> Log Model Interpretations</a></li>
<li class="chapter" data-level="5.6.6" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#log-model-ci-for-beta_0-beta_1"><i class="fa fa-check"></i><b>5.6.6</b> Log Model CI for <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span></a></li>
<li class="chapter" data-level="5.6.7" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#log-model-ci-for-expected-response"><i class="fa fa-check"></i><b>5.6.7</b> Log Model CI for Expected Response</a></li>
<li class="chapter" data-level="5.6.8" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#log-model-prediction-interval"><i class="fa fa-check"></i><b>5.6.8</b> Log Model Prediction Interval</a></li>
<li class="chapter" data-level="5.6.9" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#confidence-interval-comparison"><i class="fa fa-check"></i><b>5.6.9</b> Confidence Interval Comparison</a></li>
<li class="chapter" data-level="5.6.10" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#prediction-interval-comparison"><i class="fa fa-check"></i><b>5.6.10</b> Prediction Interval Comparison</a></li>
<li class="chapter" data-level="5.6.11" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#log-model-visualization"><i class="fa fa-check"></i><b>5.6.11</b> Log Model Visualization</a></li>
<li class="chapter" data-level="5.6.12" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#comments-on-transformations"><i class="fa fa-check"></i><b>5.6.12</b> Comments on Transformations</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#case-studies"><i class="fa fa-check"></i><b>5.7</b> Case Studies</a><ul>
<li class="chapter" data-level="5.7.1" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#flights-from-ny-to-chi"><i class="fa fa-check"></i><b>5.7.1</b> Flights from NY to CHI</a></li>
<li class="chapter" data-level="5.7.2" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#smoking-during-pregnancy"><i class="fa fa-check"></i><b>5.7.2</b> Smoking During Pregnancy</a></li>
<li class="chapter" data-level="5.7.3" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#smoking-during-pregnancy-cont"><i class="fa fa-check"></i><b>5.7.3</b> Smoking During Pregnancy (cont)</a></li>
<li class="chapter" data-level="5.7.4" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#exam-scores"><i class="fa fa-check"></i><b>5.7.4</b> Exam Scores</a></li>
<li class="chapter" data-level="5.7.5" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#simulating-the-regression-effect"><i class="fa fa-check"></i><b>5.7.5</b> Simulating the Regression Effect</a></li>
<li class="chapter" data-level="5.7.6" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#nfl-wins"><i class="fa fa-check"></i><b>5.7.6</b> NFL Wins</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#impact-of-model-assumption-violations"><i class="fa fa-check"></i><b>5.8</b> Impact of Model Assumption Violations</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html"><i class="fa fa-check"></i><b>6</b> Building Models for Interpretation</a><ul>
<li class="chapter" data-level="6.1" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#model-building---sat-scores"><i class="fa fa-check"></i><b>6.1</b> Model Building - SAT Scores</a><ul>
<li class="chapter" data-level="6.1.1" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#modeling-for-interpretation"><i class="fa fa-check"></i><b>6.1.1</b> Modeling for Interpretation</a></li>
<li class="chapter" data-level="6.1.2" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#sat-scores-dataset"><i class="fa fa-check"></i><b>6.1.2</b> SAT Scores Dataset</a></li>
<li class="chapter" data-level="6.1.3" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#research-question"><i class="fa fa-check"></i><b>6.1.3</b> Research Question</a></li>
<li class="chapter" data-level="6.1.4" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#teacher-salary-and-sat-score"><i class="fa fa-check"></i><b>6.1.4</b> Teacher Salary and SAT score</a></li>
<li class="chapter" data-level="6.1.5" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#a-deeper-investigation"><i class="fa fa-check"></i><b>6.1.5</b> A Deeper Investigation</a></li>
<li class="chapter" data-level="6.1.6" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#student-to-teacher-ratio"><i class="fa fa-check"></i><b>6.1.6</b> Student-to-Teacher Ratio</a></li>
<li class="chapter" data-level="6.1.7" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#multicollinearity"><i class="fa fa-check"></i><b>6.1.7</b> Multicollinearity</a></li>
<li class="chapter" data-level="6.1.8" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#check-model-assumptions"><i class="fa fa-check"></i><b>6.1.8</b> Check Model Assumptions</a></li>
<li class="chapter" data-level="6.1.9" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#quadratic-term"><i class="fa fa-check"></i><b>6.1.9</b> Quadratic Term</a></li>
<li class="chapter" data-level="6.1.10" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#account-for-region"><i class="fa fa-check"></i><b>6.1.10</b> Account for Region?</a></li>
<li class="chapter" data-level="6.1.11" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#predictions-and-intervals"><i class="fa fa-check"></i><b>6.1.11</b> Predictions and Intervals</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#modeling-car-price"><i class="fa fa-check"></i><b>6.2</b> Modeling Car Price</a><ul>
<li class="chapter" data-level="6.2.1" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#model-for-price-of-2015-cars"><i class="fa fa-check"></i><b>6.2.1</b> Model for Price of 2015 Cars</a></li>
<li class="chapter" data-level="6.2.2" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#acc.-and-qrt.-mile-time"><i class="fa fa-check"></i><b>6.2.2</b> Acc. and Qrt. Mile Time</a></li>
<li class="chapter" data-level="6.2.3" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#adding-weight-to-model"><i class="fa fa-check"></i><b>6.2.3</b> Adding Weight to Model</a></li>
<li class="chapter" data-level="6.2.4" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#adding-more-variables"><i class="fa fa-check"></i><b>6.2.4</b> Adding More Variables</a></li>
<li class="chapter" data-level="6.2.5" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#check-of-model-assumptions"><i class="fa fa-check"></i><b>6.2.5</b> Check of Model Assumptions</a></li>
<li class="chapter" data-level="6.2.6" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#coefficients-and-exponentiation"><i class="fa fa-check"></i><b>6.2.6</b> Coefficients and Exponentiation</a></li>
<li class="chapter" data-level="6.2.7" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#confidence-and-prediction-intevals"><i class="fa fa-check"></i><b>6.2.7</b> Confidence and Prediction Intevals</a></li>
<li class="chapter" data-level="6.2.8" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#model-building-summary"><i class="fa fa-check"></i><b>6.2.8</b> Model Building Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="predictive-modeling.html"><a href="predictive-modeling.html"><i class="fa fa-check"></i><b>7</b> Predictive Modeling</a><ul>
<li class="chapter" data-level="7.1" data-path="predictive-modeling.html"><a href="predictive-modeling.html#modeling-for-prediction"><i class="fa fa-check"></i><b>7.1</b> Modeling for Prediction</a><ul>
<li class="chapter" data-level="7.1.1" data-path="predictive-modeling.html"><a href="predictive-modeling.html#overview"><i class="fa fa-check"></i><b>7.1.1</b> Overview</a></li>
<li class="chapter" data-level="7.1.2" data-path="predictive-modeling.html"><a href="predictive-modeling.html#illustration-of-predictive-modeling"><i class="fa fa-check"></i><b>7.1.2</b> Illustration of Predictive Modeling</a></li>
<li class="chapter" data-level="7.1.3" data-path="predictive-modeling.html"><a href="predictive-modeling.html#predicting-new-data"><i class="fa fa-check"></i><b>7.1.3</b> Predicting New Data</a></li>
<li class="chapter" data-level="7.1.4" data-path="predictive-modeling.html"><a href="predictive-modeling.html#evaluating-predictions---rmspe"><i class="fa fa-check"></i><b>7.1.4</b> Evaluating Predictions - RMSPE</a></li>
<li class="chapter" data-level="7.1.5" data-path="predictive-modeling.html"><a href="predictive-modeling.html#training-data-error"><i class="fa fa-check"></i><b>7.1.5</b> Training Data Error</a></li>
<li class="chapter" data-level="7.1.6" data-path="predictive-modeling.html"><a href="predictive-modeling.html#graph-of-rmspe"><i class="fa fa-check"></i><b>7.1.6</b> Graph of RMSPE</a></li>
<li class="chapter" data-level="7.1.7" data-path="predictive-modeling.html"><a href="predictive-modeling.html#best-model"><i class="fa fa-check"></i><b>7.1.7</b> Best Model</a></li>
<li class="chapter" data-level="7.1.8" data-path="predictive-modeling.html"><a href="predictive-modeling.html#model-complexity-training-error-and-test-error"><i class="fa fa-check"></i><b>7.1.8</b> Model Complexity, Training Error, and Test Error</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="predictive-modeling.html"><a href="predictive-modeling.html#variance-bias-tradeoff"><i class="fa fa-check"></i><b>7.2</b> Variance-Bias Tradeoff</a><ul>
<li class="chapter" data-level="7.2.1" data-path="predictive-modeling.html"><a href="predictive-modeling.html#what-contributes-to-prediction-error"><i class="fa fa-check"></i><b>7.2.1</b> What Contributes to Prediction Error?</a></li>
<li class="chapter" data-level="7.2.2" data-path="predictive-modeling.html"><a href="predictive-modeling.html#variance-and-bias"><i class="fa fa-check"></i><b>7.2.2</b> Variance and Bias</a></li>
<li class="chapter" data-level="7.2.3" data-path="predictive-modeling.html"><a href="predictive-modeling.html#variance-bias-tradeoff-1"><i class="fa fa-check"></i><b>7.2.3</b> Variance-Bias Tradeoff</a></li>
<li class="chapter" data-level="7.2.4" data-path="predictive-modeling.html"><a href="predictive-modeling.html#modeling-for-prediction-1"><i class="fa fa-check"></i><b>7.2.4</b> Modeling for Prediction</a></li>
<li class="chapter" data-level="7.2.5" data-path="predictive-modeling.html"><a href="predictive-modeling.html#cross-validation"><i class="fa fa-check"></i><b>7.2.5</b> Cross-Validation</a></li>
<li class="chapter" data-level="7.2.6" data-path="predictive-modeling.html"><a href="predictive-modeling.html#cross-validation-illustration"><i class="fa fa-check"></i><b>7.2.6</b> Cross-Validation Illustration</a></li>
<li class="chapter" data-level="7.2.7" data-path="predictive-modeling.html"><a href="predictive-modeling.html#cv-in-r"><i class="fa fa-check"></i><b>7.2.7</b> CV in R</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="predictive-modeling.html"><a href="predictive-modeling.html#ridge-regression"><i class="fa fa-check"></i><b>7.3</b> Ridge Regression</a><ul>
<li class="chapter" data-level="7.3.1" data-path="predictive-modeling.html"><a href="predictive-modeling.html#complexity-in-model-coefficients"><i class="fa fa-check"></i><b>7.3.1</b> Complexity in Model Coefficients</a></li>
<li class="chapter" data-level="7.3.2" data-path="predictive-modeling.html"><a href="predictive-modeling.html#ridge-regression-penalty"><i class="fa fa-check"></i><b>7.3.2</b> Ridge Regression Penalty</a></li>
<li class="chapter" data-level="7.3.3" data-path="predictive-modeling.html"><a href="predictive-modeling.html#choosing-lambda"><i class="fa fa-check"></i><b>7.3.3</b> Choosing <span class="math inline">\(\lambda\)</span></a></li>
<li class="chapter" data-level="7.3.4" data-path="predictive-modeling.html"><a href="predictive-modeling.html#ridge-regression-on-housing-dataset"><i class="fa fa-check"></i><b>7.3.4</b> Ridge Regression on Housing Dataset</a></li>
<li class="chapter" data-level="7.3.5" data-path="predictive-modeling.html"><a href="predictive-modeling.html#ridge-vs-ols"><i class="fa fa-check"></i><b>7.3.5</b> Ridge vs OLS</a></li>
<li class="chapter" data-level="7.3.6" data-path="predictive-modeling.html"><a href="predictive-modeling.html#lasso-and-elastic-net"><i class="fa fa-check"></i><b>7.3.6</b> Lasso and Elastic Net</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="predictive-modeling.html"><a href="predictive-modeling.html#decision-trees"><i class="fa fa-check"></i><b>7.4</b> Decision Trees</a><ul>
<li class="chapter" data-level="7.4.1" data-path="predictive-modeling.html"><a href="predictive-modeling.html#basics-of-decision-trees"><i class="fa fa-check"></i><b>7.4.1</b> Basics of Decision Trees</a></li>
<li class="chapter" data-level="7.4.2" data-path="predictive-modeling.html"><a href="predictive-modeling.html#partitioning-in-a-decision-tree"><i class="fa fa-check"></i><b>7.4.2</b> Partitioning in A Decision Tree</a></li>
<li class="chapter" data-level="7.4.3" data-path="predictive-modeling.html"><a href="predictive-modeling.html#next-splits"><i class="fa fa-check"></i><b>7.4.3</b> Next Splits</a></li>
<li class="chapter" data-level="7.4.4" data-path="predictive-modeling.html"><a href="predictive-modeling.html#recursive-partitioning"><i class="fa fa-check"></i><b>7.4.4</b> Recursive Partitioning</a></li>
<li class="chapter" data-level="7.4.5" data-path="predictive-modeling.html"><a href="predictive-modeling.html#model-complexity-in-trees"><i class="fa fa-check"></i><b>7.4.5</b> Model Complexity in Trees</a></li>
<li class="chapter" data-level="7.4.6" data-path="predictive-modeling.html"><a href="predictive-modeling.html#cross-validation-on-housing-data"><i class="fa fa-check"></i><b>7.4.6</b> Cross-Validation on Housing Data</a></li>
<li class="chapter" data-level="7.4.7" data-path="predictive-modeling.html"><a href="predictive-modeling.html#comparing-ols-lasso-ridge-and-tree"><i class="fa fa-check"></i><b>7.4.7</b> Comparing OLS, Lasso, Ridge, and Tree</a></li>
<li class="chapter" data-level="7.4.8" data-path="predictive-modeling.html"><a href="predictive-modeling.html#random-forest"><i class="fa fa-check"></i><b>7.4.8</b> Random Forest</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="predictive-modeling.html"><a href="predictive-modeling.html#regression-splines"><i class="fa fa-check"></i><b>7.5</b> Regression Splines</a><ul>
<li class="chapter" data-level="7.5.1" data-path="predictive-modeling.html"><a href="predictive-modeling.html#regression-splines-1"><i class="fa fa-check"></i><b>7.5.1</b> Regression Splines</a></li>
<li class="chapter" data-level="7.5.2" data-path="predictive-modeling.html"><a href="predictive-modeling.html#two-models-with-high-bias"><i class="fa fa-check"></i><b>7.5.2</b> Two Models with High Bias</a></li>
<li class="chapter" data-level="7.5.3" data-path="predictive-modeling.html"><a href="predictive-modeling.html#cubic-splines"><i class="fa fa-check"></i><b>7.5.3</b> Cubic Splines</a></li>
<li class="chapter" data-level="7.5.4" data-path="predictive-modeling.html"><a href="predictive-modeling.html#predicting-test-data"><i class="fa fa-check"></i><b>7.5.4</b> Predicting Test Data</a></li>
<li class="chapter" data-level="7.5.5" data-path="predictive-modeling.html"><a href="predictive-modeling.html#implementation-of-splines"><i class="fa fa-check"></i><b>7.5.5</b> Implementation of Splines</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="predictive-modeling.html"><a href="predictive-modeling.html#summary-and-comparision"><i class="fa fa-check"></i><b>7.6</b> Summary and Comparision</a><ul>
<li class="chapter" data-level="7.6.1" data-path="predictive-modeling.html"><a href="predictive-modeling.html#modeling-with-ols"><i class="fa fa-check"></i><b>7.6.1</b> Modeling with OLS</a></li>
<li class="chapter" data-level="7.6.2" data-path="predictive-modeling.html"><a href="predictive-modeling.html#ridge-regression-with-housing-data"><i class="fa fa-check"></i><b>7.6.2</b> Ridge Regression with Housing Data</a></li>
<li class="chapter" data-level="7.6.3" data-path="predictive-modeling.html"><a href="predictive-modeling.html#decision-tree"><i class="fa fa-check"></i><b>7.6.3</b> Decision Tree</a></li>
<li class="chapter" data-level="7.6.4" data-path="predictive-modeling.html"><a href="predictive-modeling.html#comparing-performance"><i class="fa fa-check"></i><b>7.6.4</b> Comparing Performance</a></li>
<li class="chapter" data-level="7.6.5" data-path="predictive-modeling.html"><a href="predictive-modeling.html#predictions-on-new-data"><i class="fa fa-check"></i><b>7.6.5</b> Predictions on New Data</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="predictive-modeling.html"><a href="predictive-modeling.html#ethical-considerations-in-predictive-modeling"><i class="fa fa-check"></i><b>7.7</b> Ethical Considerations in Predictive Modeling</a><ul>
<li class="chapter" data-level="7.7.1" data-path="predictive-modeling.html"><a href="predictive-modeling.html#assumptions-in-predictive-models"><i class="fa fa-check"></i><b>7.7.1</b> Assumptions in Predictive Models</a></li>
<li class="chapter" data-level="7.7.2" data-path="predictive-modeling.html"><a href="predictive-modeling.html#amazon-hiring-algorithm"><i class="fa fa-check"></i><b>7.7.2</b> Amazon Hiring Algorithm</a></li>
<li class="chapter" data-level="7.7.3" data-path="predictive-modeling.html"><a href="predictive-modeling.html#facial-recognition"><i class="fa fa-check"></i><b>7.7.3</b> Facial Recognition</a></li>
<li class="chapter" data-level="7.7.4" data-path="predictive-modeling.html"><a href="predictive-modeling.html#comments"><i class="fa fa-check"></i><b>7.7.4</b> Comments</a></li>
<li class="chapter" data-level="7.7.5" data-path="predictive-modeling.html"><a href="predictive-modeling.html#modeling-for-prediction-2"><i class="fa fa-check"></i><b>7.7.5</b> Modeling for Prediction</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html"><i class="fa fa-check"></i><b>8</b> Logistic Regression and Classification</a><ul>
<li class="chapter" data-level="8.1" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#logistic-regression"><i class="fa fa-check"></i><b>8.1</b> Logistic Regression</a><ul>
<li class="chapter" data-level="8.1.1" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#modeling-binary-response"><i class="fa fa-check"></i><b>8.1.1</b> Modeling Binary Response</a></li>
<li class="chapter" data-level="8.1.2" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#credit-card-dataset"><i class="fa fa-check"></i><b>8.1.2</b> Credit Card Dataset</a></li>
<li class="chapter" data-level="8.1.3" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#logistic-regression-model"><i class="fa fa-check"></i><b>8.1.3</b> Logistic Regression Model</a></li>
<li class="chapter" data-level="8.1.4" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#logistic-regression-model-for-default"><i class="fa fa-check"></i><b>8.1.4</b> Logistic Regression Model for Default</a></li>
<li class="chapter" data-level="8.1.5" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#where-do-the-bs-come-from"><i class="fa fa-check"></i><b>8.1.5</b> Where do the bâ€™s come from?</a></li>
<li class="chapter" data-level="8.1.6" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#odds-and-odds-ratio"><i class="fa fa-check"></i><b>8.1.6</b> Odds and Odds Ratio</a></li>
<li class="chapter" data-level="8.1.7" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#interpretation-of-beta_1"><i class="fa fa-check"></i><b>8.1.7</b> Interpretation of <span class="math inline">\(\beta_1\)</span></a></li>
<li class="chapter" data-level="8.1.8" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#hypothesis-tests-in-logistic-regression"><i class="fa fa-check"></i><b>8.1.8</b> Hypothesis Tests in Logistic Regression</a></li>
<li class="chapter" data-level="8.1.9" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#confidence-intervals-for-beta_1"><i class="fa fa-check"></i><b>8.1.9</b> Confidence Intervals for <span class="math inline">\(\beta_1\)</span></a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#multiple-logistic-regression"><i class="fa fa-check"></i><b>8.2</b> Multiple Logistic Regression</a><ul>
<li class="chapter" data-level="8.2.1" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#logistic-regression-models-with-multiple-explanatory-variables"><i class="fa fa-check"></i><b>8.2.1</b> Logistic Regression Models with Multiple Explanatory Variables</a></li>
<li class="chapter" data-level="8.2.2" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#multiple-logistic-regression-interpretations"><i class="fa fa-check"></i><b>8.2.2</b> Multiple Logistic Regression Interpretations</a></li>
<li class="chapter" data-level="8.2.3" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#hypothesis-tests-in-multiple-logistic-regression-model"><i class="fa fa-check"></i><b>8.2.3</b> Hypothesis Tests in Multiple Logistic Regression Model</a></li>
<li class="chapter" data-level="8.2.4" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#multiple-logistic-regression-model-with-interaction"><i class="fa fa-check"></i><b>8.2.4</b> Multiple Logistic Regression Model with Interaction</a></li>
<li class="chapter" data-level="8.2.5" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#interpretations-for-logistic-model-with-interaction"><i class="fa fa-check"></i><b>8.2.5</b> Interpretations for Logistic Model with Interaction</a></li>
<li class="chapter" data-level="8.2.6" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#logistic-regression-key-points"><i class="fa fa-check"></i><b>8.2.6</b> Logistic Regression Key Points</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#assessing-a-classifiers-performance"><i class="fa fa-check"></i><b>8.3</b> Assessing a Classifierâ€™s Performance</a><ul>
<li class="chapter" data-level="8.3.1" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#measuring-prediction-accuracy"><i class="fa fa-check"></i><b>8.3.1</b> Measuring Prediction Accuracy</a></li>
<li class="chapter" data-level="8.3.2" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#decision-tree-classifier"><i class="fa fa-check"></i><b>8.3.2</b> Decision Tree Classifier</a></li>
<li class="chapter" data-level="8.3.3" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#assessing-classifier-accuracy"><i class="fa fa-check"></i><b>8.3.3</b> Assessing Classifier Accuracy</a></li>
<li class="chapter" data-level="8.3.4" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#confusion-matrix"><i class="fa fa-check"></i><b>8.3.4</b> Confusion Matrix</a></li>
<li class="chapter" data-level="8.3.5" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#sensitivity-and-specificity"><i class="fa fa-check"></i><b>8.3.5</b> Sensitivity and Specificity</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#receiver-operating-characteristic-curve"><i class="fa fa-check"></i><b>8.4</b> Receiver Operating Characteristic Curve</a><ul>
<li class="chapter" data-level="8.4.1" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#separating-s-and--s"><i class="fa fa-check"></i><b>8.4.1</b> Separating +â€™s and -â€™s</a></li>
<li class="chapter" data-level="8.4.2" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#roc-curve"><i class="fa fa-check"></i><b>8.4.2</b> ROC Curve</a></li>
<li class="chapter" data-level="8.4.3" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#constructing-roc-curve"><i class="fa fa-check"></i><b>8.4.3</b> Constructing ROC Curve</a></li>
<li class="chapter" data-level="8.4.4" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#construct-roc-example"><i class="fa fa-check"></i><b>8.4.4</b> Construct ROC Example</a></li>
<li class="chapter" data-level="8.4.5" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#auc"><i class="fa fa-check"></i><b>8.4.5</b> AUC</a></li>
<li class="chapter" data-level="8.4.6" data-path="logistic-regression-and-classification.html"><a href="logistic-regression-and-classification.html#lr-and-tree-roc-curves"><i class="fa fa-check"></i><b>8.4.6</b> LR and Tree ROC Curves</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Stat 255: Statistics for Data Science Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="logistic-regression-and-classification" class="section level1 hasAnchor">
<h1><span class="header-section-number">Chapter 8</span> Logistic Regression and Classification<a href="logistic-regression-and-classification.html#logistic-regression-and-classification" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><strong>Learning Outcomes:</strong></p>
<ol style="list-style-type: decimal">
<li><p>Define and distinguish between probability, odds, and odds ratio.</p></li>
<li><p>Identify situations where it is appropriate to use logistic regression.<br />
</p></li>
<li><p>Estimate probabilities, odds, and odds ratios using logistic regression.<br />
</p></li>
<li><p>Interpret coefficients in a logistic regression model.</p></li>
<li><p>Explain how probability estimates are obtained from decision trees and random forests.</p></li>
<li><p>Construct and interpret a confusion matrix, given probability estimates and true results.</p></li>
<li><p>Define specificity and sensitivity, and calculate them for given data.<br />
</p></li>
<li><p>Explain the information contained in a receiver operating characteristic (ROC) curve.<br />
</p></li>
<li><p>Construct receiver operating curves for small sets of data.<br />
</p></li>
<li><p>Compare classifiers using misclassification rate, and AUC.</p></li>
</ol>
<div id="logistic-regression" class="section level2 hasAnchor">
<h2><span class="header-section-number">8.1</span> Logistic Regression<a href="logistic-regression-and-classification.html#logistic-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="modeling-binary-response" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.1</span> Modeling Binary Response<a href="logistic-regression-and-classification.html#modeling-binary-response" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>So far, we have modeled only quantitative response variables. The normal error regression model makes the assumption that the response variable is normally distributed, given the value(s) of the explanatory variables.</p>
<p>Now, weâ€™ll look at how to model a categorical response variable. Weâ€™ll consider only situations where the response is binary (i.e.Â has 2 categories). Problems with categorical response variables are sometimes called <strong>classification</strong> problems, while problems with numeric response variables are sometimes called <strong>regression</strong> problems.</p>
</div>
<div id="credit-card-dataset" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.2</span> Credit Card Dataset<a href="logistic-regression-and-classification.html#credit-card-dataset" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Weâ€™ll consider a dataset pertaining to 10,000 credit cards. The goal is to predict whether or not the user will default on the payment, using information on the credit card balance, userâ€™s annual income, and whether or not the user is a student. Data come from <a href="http://www-bcf.usc.edu/~gareth/ISL/data.html">Introduction to Statistical Learning</a> by James, Witten, Hastie, Tibshirani.</p>
<div class="sourceCode" id="cb801"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb801-1"><a href="logistic-regression-and-classification.html#cb801-1"></a><span class="kw">library</span>(ISLR)</span>
<span id="cb801-2"><a href="logistic-regression-and-classification.html#cb801-2"></a><span class="kw">data</span>(Default)</span>
<span id="cb801-3"><a href="logistic-regression-and-classification.html#cb801-3"></a><span class="kw">summary</span>(Default)</span></code></pre></div>
<pre><code>##  default    student       balance           income     
##  No :9667   No :7056   Min.   :   0.0   Min.   :  772  
##  Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  
##                        Median : 823.6   Median :34553  
##                        Mean   : 835.4   Mean   :33517  
##                        3rd Qu.:1166.3   3rd Qu.:43808  
##                        Max.   :2654.3   Max.   :73554</code></pre>
<p><strong>Default and Balance</strong></p>
<p>The plot displays each personâ€™s credit card balance on the x-axis, and whether or not they defaulted (a 0 or 1) on the y-axis.</p>
<div class="sourceCode" id="cb803"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb803-1"><a href="logistic-regression-and-classification.html#cb803-1"></a><span class="kw">ggplot</span>(<span class="dt">data=</span>Default, <span class="kw">aes</span>(<span class="dt">y=</span>default, <span class="dt">x=</span>balance)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">alpha=</span><span class="fl">0.2</span>) </span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-618-1.png" width="960" />
We see that defaults are rare when the balance is less than $1,000, and more common for balances above $2,000.</p>
<p>Weâ€™ll first try fitting a linear regression model to the data to try to estimate the probability of a person defaulting on a loan, using the size of their balance as the explanatory variable.</p>
<div class="sourceCode" id="cb804"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb804-1"><a href="logistic-regression-and-classification.html#cb804-1"></a><span class="co">#convert default from yes/no to 0/1</span></span>
<span id="cb804-2"><a href="logistic-regression-and-classification.html#cb804-2"></a>Default<span class="op">$</span>default &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(Default<span class="op">$</span>default<span class="op">==</span><span class="st">&quot;Yes&quot;</span>) </span></code></pre></div>
<div class="sourceCode" id="cb805"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb805-1"><a href="logistic-regression-and-classification.html#cb805-1"></a><span class="kw">ggplot</span>(<span class="dt">data=</span>Default, <span class="kw">aes</span>(<span class="dt">y=</span>default, <span class="dt">x=</span> balance)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">alpha=</span><span class="fl">0.2</span>)  <span class="op">+</span><span class="st"> </span><span class="kw">stat_smooth</span>(<span class="dt">method=</span><span class="st">&quot;lm&quot;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-620-1.png" width="768" /></p>
<p>There are a lot of problems with this model!</p>
<p>It allows the estimated probability of of default to be negative. It also assumes a linear trend that doesnâ€™t seem to fit the data very well.</p>
<p>A sigmoidal curve, like the one below, seems like a better model for default probabilities. This curve stays between 0 and 1, and its curved nature seems like a better fit for the data.</p>
<div class="sourceCode" id="cb806"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb806-1"><a href="logistic-regression-and-classification.html#cb806-1"></a><span class="kw">ggplot</span>(<span class="dt">data=</span>Default, <span class="kw">aes</span>(<span class="dt">y=</span>default, <span class="dt">x=</span> balance)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">alpha=</span><span class="fl">0.2</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb806-2"><a href="logistic-regression-and-classification.html#cb806-2"></a><span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method=</span><span class="st">&quot;glm&quot;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>, <span class="dt">method.args =</span> <span class="kw">list</span>(<span class="dt">family=</span>binomial)) </span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-621-1.png" width="768" /></p>
</div>
<div id="logistic-regression-model" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.3</span> Logistic Regression Model<a href="logistic-regression-and-classification.html#logistic-regression-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A logistic regression model uses a sigmoidal curve like the one we saw to model default probabilities, using balance as an explanatory variable.</p>
<p>The model makes use of the function</p>
<p><span class="math display">\[
f(x) = \frac{e^x}{1+x^x},
\]</span></p>
<p>whose graph is shown below. This function is called an <strong>inverse logit</strong> function.</p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-622-1.png" width="768" /></p>
<p>Starting with our linear model <span class="math inline">\(E(Y_i) = \beta_0+\beta_1x_{i1}\)</span>, we need to transform <span class="math inline">\(\beta_0+\beta_1x_{i1}\)</span> into (0,1).</p>
<ul>
<li><p>Let <span class="math inline">\(\pi_i = \frac{e^{\beta_0+\beta_1x_{i1} }}{1+e^{\beta_0+\beta_1x_{i1}}}\)</span>.</p></li>
<li><p>Then <span class="math inline">\(0 \leq \pi_i \leq 1\)</span>, and <span class="math inline">\(\pi_i\)</span> represents an estimate of <span class="math inline">\(P(Y_i=1)\)</span>.</p></li>
<li><p>This function maps the values of <span class="math inline">\(\beta_0+\beta_1x_{i1}\)</span> into the interval (0,1).</p></li>
</ul>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-623-1.png" width="768" /></p>
<p>The <strong>logistic regression model</strong> assumes that:<br />
* <span class="math inline">\(Y_i \in \{0,1\}\)</span><br />
* <span class="math inline">\(E(Y_i) = P(Y_i=1) = \pi_i=\frac{e^{\beta_0+\beta_1x_{i1} + \ldots \beta_px_{ip}}}{1+e^{\beta_0+\beta_1x_{i1} + \ldots \beta_px_{ip}}}\)</span></p>
<p>i.e.Â <span class="math inline">\(\beta_0+\beta_1x_{i1} + \ldots \beta_px_{ip}= \text{log}\left(\frac{\pi_i}{1-\pi_i}\right).\)</span> (This is called the logit function and can be written <span class="math inline">\(\text{logit}(\pi_i)\)</span>.</p>
<p>Instead of assuming that the expected response is a linear function of the explanatory variables, we are assuming that it is a function of a linear function of the explanatory variables.</p>
</div>
<div id="logistic-regression-model-for-default" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.4</span> Logistic Regression Model for Default<a href="logistic-regression-and-classification.html#logistic-regression-model-for-default" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb807"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb807-1"><a href="logistic-regression-and-classification.html#cb807-1"></a><span class="kw">ggplot</span>(<span class="dt">data=</span>Default, <span class="kw">aes</span>(<span class="dt">y=</span>default, <span class="dt">x=</span> balance)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">alpha=</span><span class="fl">0.2</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb807-2"><a href="logistic-regression-and-classification.html#cb807-2"></a><span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method=</span><span class="st">&quot;glm&quot;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>, <span class="dt">method.args =</span> <span class="kw">list</span>(<span class="dt">family=</span>binomial)) </span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-624-1.png" width="768" /></p>
<p>To fit the logistic regression model in R, we use the function <code>glm</code>, instead of <code>lm</code>. The function is specified the same way as before, and we add <code>family = binomial(link = "logit")</code>.</p>
<div class="sourceCode" id="cb808"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb808-1"><a href="logistic-regression-and-classification.html#cb808-1"></a>CCDefault_M &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="dt">data=</span>Default, default <span class="op">~</span><span class="st"> </span>balance, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</span>
<span id="cb808-2"><a href="logistic-regression-and-classification.html#cb808-2"></a><span class="kw">summary</span>(CCDefault_M)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = default ~ balance, family = binomial(link = &quot;logit&quot;), 
##     data = Default)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.2697  -0.1465  -0.0589  -0.0221   3.7589  
## 
## Coefficients:
##                Estimate  Std. Error z value            Pr(&gt;|z|)    
## (Intercept) -10.6513306   0.3611574  -29.49 &lt;0.0000000000000002 ***
## balance       0.0054989   0.0002204   24.95 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 2920.6  on 9999  degrees of freedom
## Residual deviance: 1596.5  on 9998  degrees of freedom
## AIC: 1600.5
## 
## Number of Fisher Scoring iterations: 8</code></pre>
<p>The regression equation is:</p>
<p><span class="math display">\[
P(\text{Default}) = \hat{\pi}_i =  \frac{e^{-10.65+0.0055\times\text{balance}}}{1+e^{-10.65+0.0055\times\text{balance}}}
\]</span></p>
<p><strong>Predictions</strong></p>
<ul>
<li><p>For a $1,000 balance, the estimated default probability is <span class="math inline">\(\frac{e^{-10.65+0.0055(1000) }}{1+e^{-10.65+0.0055(1000)}} \approx 0.006\)</span></p></li>
<li><p>For a $1,500 balance, the estimated default probability is <span class="math inline">\(\frac{e^{-10.65+0.0055(1500) }}{1+e^{-10.65+0.0055(1500)}} \approx 0.08\)</span></p></li>
<li><p>For a $2,000 balance, the estimated default probability is <span class="math inline">\(\frac{e^{-10.65+0.0055(2000) }}{1+e^{-10.65+0.0055(2000)}} \approx 0.59\)</span></p></li>
</ul>
<p>We confirm these, using the <code>predict</code> command in R.</p>
<div class="sourceCode" id="cb810"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb810-1"><a href="logistic-regression-and-classification.html#cb810-1"></a><span class="kw">predict</span>(CCDefault_M, <span class="dt">newdata=</span><span class="kw">data.frame</span>((<span class="dt">balance=</span><span class="dv">1000</span>)), <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>##           1 
## 0.005752145</code></pre>
<div class="sourceCode" id="cb812"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb812-1"><a href="logistic-regression-and-classification.html#cb812-1"></a><span class="kw">predict</span>(CCDefault_M, <span class="dt">newdata=</span><span class="kw">data.frame</span>((<span class="dt">balance=</span><span class="dv">1500</span>)), <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>##          1 
## 0.08294762</code></pre>
<div class="sourceCode" id="cb814"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb814-1"><a href="logistic-regression-and-classification.html#cb814-1"></a><span class="kw">predict</span>(CCDefault_M, <span class="dt">newdata=</span><span class="kw">data.frame</span>((<span class="dt">balance=</span><span class="dv">2000</span>)), <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>##         1 
## 0.5857694</code></pre>
</div>
<div id="where-do-the-bs-come-from" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.5</span> Where do the bâ€™s come from?<a href="logistic-regression-and-classification.html#where-do-the-bs-come-from" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Recall that for a quantitative response variable, the values of <span class="math inline">\(b_1, b_2, \ldots, b_p\)</span> are chosen in a way that minimizes <span class="math inline">\(\displaystyle\sum_{i=1}^n \left(y_i-(\beta_0+\beta_1x_{i1}+\ldots+\beta_px_{ip})^2\right)\)</span>.</p></li>
<li><p>Least squares does not work well in this generalized setting. Instead, the bâ€™s are calculated using a more advanced technique, known as <strong>maximum likelihood estimation</strong>.</p></li>
</ul>
</div>
<div id="odds-and-odds-ratio" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.6</span> Odds and Odds Ratio<a href="logistic-regression-and-classification.html#odds-and-odds-ratio" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For an event with probability <span class="math inline">\(p\)</span>, the <strong>odds</strong> of the event occurring are <span class="math inline">\(\frac{p}{1-p}\)</span>.</p>
<p>Examples:
1. The odds of a fair coin landing heads are <span class="math inline">\(\frac{0.5}{1-0.5}=1\)</span>, sometimes written 1:1.</p>
<ol start="2" style="list-style-type: decimal">
<li>The odds of a fair 6-sided die landing on a 1 are <span class="math inline">\(\frac{1/6}{1-1/6}=\frac{1}{5}\)</span>, sometimes written 1:5.</li>
</ol>
<p>In the credit card example, the odds of default are:</p>
<ul>
<li><p>For a $1,000 balance - odds of default are <span class="math inline">\(\frac{0.005752145}{1-0.005752145} \approx 1:173.\)</span></p></li>
<li><p>For a $1,500 balance - odds of default are <span class="math inline">\(\frac{0.08294762 }{1-0.08294762 } \approx 1:11.\)</span></p></li>
<li><p>For a $2,000 balance - odds of default are <span class="math inline">\(\frac{0.5857694}{1-0.5857694} \approx 1.414:1.\)</span></p></li>
</ul>
<p>The quantity <span class="math inline">\(\frac{\frac{\pi_i}{1-\pi_i}}{\frac{\pi_j}{1-\pi_j}}\)</span> is called the <strong>odds ratio</strong> and represents the odds ratio of a default for user <span class="math inline">\(i\)</span>, compared to user <span class="math inline">\(j\)</span>.</p>
<p>Example:</p>
<p>The default odds ratio for a $1,000 payment, compared to a $2,000 payment is</p>
<p>The odds ratio is <span class="math inline">\(\frac{\frac{1}{173}}{\frac{1.414}{1}}\approx 1:244.\)</span></p>
<p>The odds of a default are about 244 times larger for a $2,000 payment than a $1,000 payment.</p>
</div>
<div id="interpretation-of-beta_1" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.7</span> Interpretation of <span class="math inline">\(\beta_1\)</span><a href="logistic-regression-and-classification.html#interpretation-of-beta_1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider the odds ratio for a case <span class="math inline">\(j\)</span> with explanatory variable <span class="math inline">\(x + 1\)</span>, compared to case <span class="math inline">\(i\)</span> with explanatory variable <span class="math inline">\(x\)</span>.</p>
<p>That is <span class="math inline">\(\text{log}\left(\frac{\pi_i}{1-\pi_i}\right) = \beta_0+\beta_1x\)</span>, and
<span class="math inline">\(\text{log}\left(\frac{\pi_j}{1-\pi_j}\right) = \beta_0+\beta_1(x+1)\)</span>.</p>
<p><span class="math inline">\(\text{log}\left(\frac{\frac{\pi_j}{1-\pi_j}}{\frac{\pi_i}{1-\pi_i}}\right)=\text{log}\left(\frac{\pi_j}{1-\pi_j}\right)-\text{log}\left(\frac{\pi_i}{1-\pi_i}\right)=\beta_0+\beta_1(x+1)-(\beta_0+\beta_1(x))=\beta_1.\)</span></p>
<p>For every 1-unit increase in <span class="math inline">\(x\)</span> we expect the log odds of â€œsuccessâ€ to multiply by a factor of <span class="math inline">\(\beta_1\)</span>.</p>
<p>For every 1-unit increase in <span class="math inline">\(x\)</span> we expect the odds of â€œsuccessâ€ to multiply by a factor of <span class="math inline">\(e^{\beta_1}\)</span>.</p>
<p><strong>Interpretation in Credit Card Example</strong></p>
<p><span class="math inline">\(b_1=0.0055\)</span></p>
<p>For each 1-dollar increase in balance on the credit card., the odds of default are estimated to multiply by <span class="math inline">\(e^{0.0055}\approx1.0055\)</span>.</p>
<p>That is, for each additional dollar on the card balance, the odds of default are estimated to increase by 0.55%</p>
<p>For each increase of <span class="math inline">\(d\)</span> dollars in credit card balance, odds of default are estimated to multiply by a factor of <span class="math inline">\(e^{0.0055d}\)</span>.</p>
<p>For every $1,000 increase in balance, the odds of default are expected to multiply by a factor of <span class="math inline">\(e^{0.0055\times 1000}\approx 244\)</span>.</p>
<p>Thus, the odds of default for a balance of $2,000 are estimated to be <span class="math inline">\(e^{0.0055\times 1000}\approx 244\)</span> times as great as the odds of default for a $1,000 balance. This matches our result when we actually calculated out the probabilities and odds.</p>
</div>
<div id="hypothesis-tests-in-logistic-regression" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.8</span> Hypothesis Tests in Logistic Regression<a href="logistic-regression-and-classification.html#hypothesis-tests-in-logistic-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The p-value on the â€œbalanceâ€ line of the regression output is associated with the null hypothesis <span class="math inline">\(\beta_1=0\)</span>, that is that there is no relationship between balance and the odds of defaulting on the payment.</p>
<p>The fact that the p-value is so small tells us that there is strong evidence of a relationship between balance and odds of default.</p>
</div>
<div id="confidence-intervals-for-beta_1" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.1.9</span> Confidence Intervals for <span class="math inline">\(\beta_1\)</span><a href="logistic-regression-and-classification.html#confidence-intervals-for-beta_1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb816"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb816-1"><a href="logistic-regression-and-classification.html#cb816-1"></a><span class="kw">confint</span>(CCDefault_M, <span class="dt">level =</span> <span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>##                     2.5 %       97.5 %
## (Intercept) -11.383288936 -9.966565064
## balance       0.005078926  0.005943365</code></pre>
<p>We are 95% confident that for each 1 dollar increase in credit card balance, the odds of default are expected to multiply by a factor between <span class="math inline">\(e^{0.00508}\approx 1.0051\)</span> and <span class="math inline">\(e^{0.00594}\approx 1.0060\)</span>.</p>
<p>This is a profile-likelihood interval, which you can read more about <a href="https://rpubs.com/FJRubio/PLCIN">here</a>.</p>
</div>
</div>
<div id="multiple-logistic-regression" class="section level2 hasAnchor">
<h2><span class="header-section-number">8.2</span> Multiple Logistic Regression<a href="logistic-regression-and-classification.html#multiple-logistic-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="logistic-regression-models-with-multiple-explanatory-variables" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.2.1</span> Logistic Regression Models with Multiple Explanatory Variables<a href="logistic-regression-and-classification.html#logistic-regression-models-with-multiple-explanatory-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can also perform logistic regression in situations where there are multiple explanatory variables. Weâ€™ll estimate probability of default, using both balance and whether or not the person is a student (a categorical variable) as explanatory variables.</p>
<div class="sourceCode" id="cb818"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb818-1"><a href="logistic-regression-and-classification.html#cb818-1"></a>CCDefault_M2 &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="dt">data=</span>Default, default <span class="op">~</span><span class="st"> </span>balance <span class="op">+</span><span class="st"> </span>student, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</span>
<span id="cb818-2"><a href="logistic-regression-and-classification.html#cb818-2"></a><span class="kw">summary</span>(CCDefault_M2)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = default ~ balance + student, family = binomial(link = &quot;logit&quot;), 
##     data = Default)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.4578  -0.1422  -0.0559  -0.0203   3.7435  
## 
## Coefficients:
##                Estimate  Std. Error z value             Pr(&gt;|z|)    
## (Intercept) -10.7494959   0.3691914 -29.116 &lt; 0.0000000000000002 ***
## balance       0.0057381   0.0002318  24.750 &lt; 0.0000000000000002 ***
## studentYes   -0.7148776   0.1475190  -4.846           0.00000126 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 2920.6  on 9999  degrees of freedom
## Residual deviance: 1571.7  on 9997  degrees of freedom
## AIC: 1577.7
## 
## Number of Fisher Scoring iterations: 8</code></pre>
<p>The following graph gives an illustration of the model.</p>
<div class="sourceCode" id="cb820"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb820-1"><a href="logistic-regression-and-classification.html#cb820-1"></a><span class="kw">ggplot</span>(<span class="dt">data=</span>Default, <span class="kw">aes</span>(<span class="dt">y=</span>default, <span class="dt">x=</span> balance, <span class="dt">color=</span>student)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">alpha=</span><span class="fl">0.2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">stat_smooth</span>(<span class="dt">method=</span><span class="st">&quot;glm&quot;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>, <span class="dt">method.args =</span> <span class="kw">list</span>(<span class="dt">family=</span>binomial)) </span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-631-1.png" width="672" /></p>
</div>
<div id="multiple-logistic-regression-interpretations" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.2.2</span> Multiple Logistic Regression Interpretations<a href="logistic-regression-and-classification.html#multiple-logistic-regression-interpretations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The regression equation is:</p>
<p><span class="math display">\[
P(\text{Default}) = \hat{\pi}_i =  \frac{e^{-10.75+0.005738\times\text{balance}-0.7149\times\text{I}_{\text{student}}}}{1+e^{-10.75+0.005738\times\text{balance}-0.7149\times\text{I}_{\text{student}}}}
\]</span></p>
<ul>
<li><p>For each 1 dollar increase in balance, the odds of default are estimated to multiply by a factor <span class="math inline">\(e^{0.005738}\approx 1.00575\)</span>, assuming whether or not the person is a student is held constant. Thus, the estimated odds of default increase by about 0.5%, for each 1-dollar increase in balance..</p></li>
<li><p>For every $100 increase in balance, the odds of default are estimated to multiply by <span class="math inline">\(e^{0.005738\times100}\approx 1.775\)</span>, assuming whether or not the person is a student is held constant. Thus, the estimated odds of default increase by about 77.5%.</p></li>
<li><p>The odds of default for students are estimated to be <span class="math inline">\(e^{-0.7149} \approx 0.49\)</span> as high for students as non-students, assuming balance amount is held constant.</p></li>
</ul>
</div>
<div id="hypothesis-tests-in-multiple-logistic-regression-model" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.2.3</span> Hypothesis Tests in Multiple Logistic Regression Model<a href="logistic-regression-and-classification.html#hypothesis-tests-in-multiple-logistic-regression-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>There is strong evidence of a relationship between balance and odds of default, after accounting for whether or not the person is a student.</p></li>
<li><p>There is evidence that students are less likely to default than nonstudents, provided the balance on the card is the same.</p></li>
</ul>
</div>
<div id="multiple-logistic-regression-model-with-interaction" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.2.4</span> Multiple Logistic Regression Model with Interaction<a href="logistic-regression-and-classification.html#multiple-logistic-regression-model-with-interaction" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The previous model assumes the effect of balance on default probability is the same for students as for nonstudents. If we suspect that the effect of having a larger balance might be different for students than for nonstudents, then we could use a model with interaction between the balance and student variables.</p>
<div class="sourceCode" id="cb821"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb821-1"><a href="logistic-regression-and-classification.html#cb821-1"></a>CCDefault_M_Int &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="dt">data=</span>Default, default <span class="op">~</span><span class="st"> </span>balance <span class="op">*</span><span class="st"> </span>student, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</span>
<span id="cb821-2"><a href="logistic-regression-and-classification.html#cb821-2"></a><span class="kw">summary</span>(CCDefault_M_Int)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = default ~ balance * student, family = binomial(link = &quot;logit&quot;), 
##     data = Default)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.4839  -0.1415  -0.0553  -0.0202   3.7628  
## 
## Coefficients:
##                       Estimate  Std. Error z value            Pr(&gt;|z|)    
## (Intercept)        -10.8746818   0.4639679 -23.438 &lt;0.0000000000000002 ***
## balance              0.0058188   0.0002937  19.812 &lt;0.0000000000000002 ***
## studentYes          -0.3512310   0.8037333  -0.437               0.662    
## balance:studentYes  -0.0002196   0.0004781  -0.459               0.646    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 2920.6  on 9999  degrees of freedom
## Residual deviance: 1571.5  on 9996  degrees of freedom
## AIC: 1579.5
## 
## Number of Fisher Scoring iterations: 8</code></pre>
</div>
<div id="interpretations-for-logistic-model-with-interaction" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.2.5</span> Interpretations for Logistic Model with Interaction<a href="logistic-regression-and-classification.html#interpretations-for-logistic-model-with-interaction" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>The regression equation is:</li>
</ul>
<p><span class="math display">\[
P(\text{Default}) = \hat{\pi}_i =  \frac{e^{-10.87+0.0058\times\text{balance}-0.35\times\text{I}_{\text{student}}-0.0002\times\text{balance}\times{\text{I}_{\text{student}}}}}{1+e^{-10.87+0.0058\times\text{balance}-0.35\times\text{I}_{\text{student}}-0.0002\times\text{balance}\times{\text{I}_{\text{student}}}}}
\]</span></p>
<p><strong>Equation for Students</strong></p>
<p><span class="math display">\[
P(\text{Default}) = \hat{\pi}_i =  \frac{e^{-10.52+0.0056\times\text{balance}}}{1+e^{-10.52+0.0056\times\text{balance}}}
\]</span></p>
<p>Assuming a person is a student, for every $100 increase in balance, the odds of default are expected to multiply by a factor of <span class="math inline">\(e^{0.0056\times 100}=1.75\)</span>, a 75% increase.</p>
<p><strong>Equation for Non-Students</strong></p>
<p><span class="math display">\[
P(\text{Default}) = \hat{\pi}_i =  \frac{e^{-10.87+0.0058\times\text{balance}}}{1+e^{-10.87+0.0058\times\text{balance}}}
\]</span></p>
<p>Assuming a person is a student, for every $100 increase in balance, the odds of default are expected to multiply by a factor of <span class="math inline">\(e^{0.0058\times 100}=1.786\)</span>, a 78.6% increase.</p>
<ul>
<li>Since estimate of the interaction effect is so small and the p-value on this estimate is large, it is plausible that there is no interaction at all. Thus, the simpler non-interaction model is preferable.</li>
</ul>
</div>
<div id="logistic-regression-key-points" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.2.6</span> Logistic Regression Key Points<a href="logistic-regression-and-classification.html#logistic-regression-key-points" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><span class="math inline">\(Y\)</span> is a binary response variable.</p></li>
<li><p><span class="math inline">\(\pi_i\)</span> is a function of explanatory variables <span class="math inline">\(x_{i1}, \ldots x_{ip}\)</span>.</p></li>
<li><p><span class="math inline">\(E(Y_i) = \pi_i = \frac{e^{\beta_0+\beta_1x_i + \ldots\beta_px_{ip}}}{1+e^{\beta_0+\beta_1x_i + \ldots\beta_px_{ip}}}\)</span></p></li>
<li><p><span class="math inline">\(\beta_0+\beta_1x_i + \ldots\beta_px_{ip} = \text{log}\left(\frac{\pi_i}{1-\pi_i}\right)\)</span></p></li>
<li><p>For quantitative <span class="math inline">\(x_j\)</span>, when all other explanatory variables are held constant, the odds of â€œsuccessâ€ multiply be a factor of <span class="math inline">\(e^{\beta_j}\)</span> for each 1 unit increase in <span class="math inline">\(x_j\)</span></p></li>
<li><p>For categorical <span class="math inline">\(x_j\)</span>, when all other explanatory variables are held constant, the odds of â€œsuccessâ€ are <span class="math inline">\(e^{\beta_j}\)</span> times higher for category <span class="math inline">\(j\)</span> than for the â€œbaseline category.â€</p></li>
<li><p>For models with interaction, we can only interpret <span class="math inline">\(\beta_j\)</span> when the values of all other explanatory variables are given (since the effect of <span class="math inline">\(x_j\)</span> depends on the other variables.)</p></li>
</ul>
</div>
</div>
<div id="assessing-a-classifiers-performance" class="section level2 hasAnchor">
<h2><span class="header-section-number">8.3</span> Assessing a Classifierâ€™s Performance<a href="logistic-regression-and-classification.html#assessing-a-classifiers-performance" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="measuring-prediction-accuracy" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.3.1</span> Measuring Prediction Accuracy<a href="logistic-regression-and-classification.html#measuring-prediction-accuracy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Just as weâ€™ve done for models with quantitative variables, weâ€™ll want to compare and assess the performance of models for predicting categorical responses. This might involve comparing llogistic regression models with different explanatory variables, or comparing a regression model to another technique such as a decision tree.</p>
<p>Just as we did before, weâ€™ll divide the data so that we can evaluate predictions on a subset of the data that was not used to fit the model.</p>
<p>Weâ€™ll divide the credit card dataset into a set of 9,000 observations, on which weâ€™ll fit our models and assess predictions on the remaining 1,000.</p>
<div class="sourceCode" id="cb823"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb823-1"><a href="logistic-regression-and-classification.html#cb823-1"></a><span class="kw">set.seed</span>(<span class="dv">08172022</span>)</span>
<span id="cb823-2"><a href="logistic-regression-and-classification.html#cb823-2"></a>samp &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(Default), <span class="dv">1000</span>)</span>
<span id="cb823-3"><a href="logistic-regression-and-classification.html#cb823-3"></a>Default_Test &lt;-<span class="st"> </span>Default[samp, ]</span>
<span id="cb823-4"><a href="logistic-regression-and-classification.html#cb823-4"></a>Default_Train &lt;-<span class="st"> </span>Default[<span class="op">-</span>samp, ]</span></code></pre></div>
<p>We fit the model with interaction to the training data:</p>
<div class="sourceCode" id="cb824"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb824-1"><a href="logistic-regression-and-classification.html#cb824-1"></a>LR_Default_M_Int &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="dt">data=</span>Default_Train, default <span class="op">~</span><span class="st"> </span>balance <span class="op">*</span><span class="st"> </span>student, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>))</span>
<span id="cb824-2"><a href="logistic-regression-and-classification.html#cb824-2"></a><span class="kw">summary</span>(LR_Default_M_Int)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = default ~ balance * student, family = binomial(link = &quot;logit&quot;), 
##     data = Default_Train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.5610  -0.1373  -0.0515  -0.0180   3.8242  
## 
## Coefficients:
##                       Estimate  Std. Error z value            Pr(&gt;|z|)    
## (Intercept)        -11.2714061   0.5188284 -21.725 &lt;0.0000000000000002 ***
## balance              0.0060696   0.0003273  18.547 &lt;0.0000000000000002 ***
## studentYes           0.0924588   0.8606304   0.107               0.914    
## balance:studentYes  -0.0004749   0.0005142  -0.924               0.356    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 2617.1  on 8999  degrees of freedom
## Residual deviance: 1385.5  on 8996  degrees of freedom
## AIC: 1393.5
## 
## Number of Fisher Scoring iterations: 8</code></pre>
<p>We then use the model to estimate the probability of a person defaulting on their credit card payment.</p>
<p>Information about 10 different credit card users, as well as the logistic regression estimate of their probability of default are shown below. The table also shows whether or not the user really defaulted on their payment.</p>
<div class="sourceCode" id="cb826"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb826-1"><a href="logistic-regression-and-classification.html#cb826-1"></a>LR_Prob &lt;-<span class="st"> </span><span class="kw">predict</span>(LR_Default_M_Int, <span class="dt">newdata=</span>Default_Test, <span class="dt">type=</span><span class="st">&quot;response&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">2</span>)</span>
<span id="cb826-2"><a href="logistic-regression-and-classification.html#cb826-2"></a>Actual_Default &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">ifelse</span>(Default_Test<span class="op">$</span>default<span class="op">==</span><span class="dv">1</span>, <span class="st">&quot;Yes&quot;</span>, <span class="st">&quot;No&quot;</span>))</span>
<span id="cb826-3"><a href="logistic-regression-and-classification.html#cb826-3"></a>student &lt;-<span class="st"> </span>Default_Test<span class="op">$</span>student</span>
<span id="cb826-4"><a href="logistic-regression-and-classification.html#cb826-4"></a>balance &lt;-<span class="st"> </span>Default_Test<span class="op">$</span>balance</span>
<span id="cb826-5"><a href="logistic-regression-and-classification.html#cb826-5"></a>LR_Res_df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(student, balance, LR_Prob, Actual_Default)</span>
<span id="cb826-6"><a href="logistic-regression-and-classification.html#cb826-6"></a><span class="kw">kable</span>(<span class="kw">head</span>(LR_Res_df, <span class="dv">50</span>)<span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(LR_Prob)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>(<span class="dv">10</span>))</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">student</th>
<th align="right">balance</th>
<th align="right">LR_Prob</th>
<th align="left">Actual_Default</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">2465</td>
<td align="left">Yes</td>
<td align="right">2026.864</td>
<td align="right">0.54</td>
<td align="left">No</td>
</tr>
<tr class="even">
<td align="left">1228</td>
<td align="left">No</td>
<td align="right">1682.201</td>
<td align="right">0.26</td>
<td align="left">No</td>
</tr>
<tr class="odd">
<td align="left">6656</td>
<td align="left">No</td>
<td align="right">1551.028</td>
<td align="right">0.14</td>
<td align="left">No</td>
</tr>
<tr class="even">
<td align="left">1185</td>
<td align="left">No</td>
<td align="right">1541.813</td>
<td align="right">0.13</td>
<td align="left">No</td>
</tr>
<tr class="odd">
<td align="left">9963</td>
<td align="left">Yes</td>
<td align="right">1635.175</td>
<td align="right">0.12</td>
<td align="left">No</td>
</tr>
<tr class="even">
<td align="left">6635</td>
<td align="left">No</td>
<td align="right">1434.128</td>
<td align="right">0.07</td>
<td align="left">Yes</td>
</tr>
<tr class="odd">
<td align="left">9691</td>
<td align="left">No</td>
<td align="right">1391.318</td>
<td align="right">0.06</td>
<td align="left">No</td>
</tr>
<tr class="even">
<td align="left">5921</td>
<td align="left">Yes</td>
<td align="right">1513.542</td>
<td align="right">0.06</td>
<td align="left">No</td>
</tr>
<tr class="odd">
<td align="left">9755</td>
<td align="left">No</td>
<td align="right">1233.619</td>
<td align="right">0.02</td>
<td align="left">No</td>
</tr>
<tr class="even">
<td align="left">7569</td>
<td align="left">Yes</td>
<td align="right">1294.286</td>
<td align="right">0.02</td>
<td align="left">No</td>
</tr>
</tbody>
</table>
</div>
<div id="decision-tree-classifier" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.3.2</span> Decision Tree Classifier<a href="logistic-regression-and-classification.html#decision-tree-classifier" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For comparison, letâ€™s use a decision tree to predict whether a person will default.</p>
<p>In a binary classification problem, we can treat a default as <span class="math inline">\(y=1\)</span> and non-default as <span class="math inline">\(y=0\)</span>, and grow the tree as we would in regression.</p>
<p>The mean response in a node <span class="math inline">\(\bar{Y}\)</span>, which is equivalent to the proportion of people in the node who defaulted, can be interpreted as the probability of default.</p>
<p>The first few splits of the tree are shown.</p>
<div class="sourceCode" id="cb827"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb827-1"><a href="logistic-regression-and-classification.html#cb827-1"></a><span class="kw">library</span>(rpart)</span>
<span id="cb827-2"><a href="logistic-regression-and-classification.html#cb827-2"></a><span class="kw">library</span>(rpart.plot)</span>
<span id="cb827-3"><a href="logistic-regression-and-classification.html#cb827-3"></a><span class="co"># grow shorter tree for illustration</span></span>
<span id="cb827-4"><a href="logistic-regression-and-classification.html#cb827-4"></a>tree &lt;-<span class="st"> </span><span class="kw">rpart</span>(<span class="dt">data=</span>Default_Train, default<span class="op">~</span>balance <span class="op">+</span><span class="st"> </span>student, <span class="dt">cp=</span><span class="fl">0.005</span>)</span>
<span id="cb827-5"><a href="logistic-regression-and-classification.html#cb827-5"></a><span class="kw">rpart.plot</span>(tree, <span class="dt">box.palette=</span><span class="st">&quot;RdBu&quot;</span>, <span class="dt">shadow.col=</span><span class="st">&quot;gray&quot;</span>, <span class="dt">nn=</span><span class="ot">TRUE</span>, <span class="dt">cex=</span><span class="dv">1</span>, <span class="dt">extra=</span><span class="dv">1</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-636-1.png" width="672" /></p>
<div class="sourceCode" id="cb828"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb828-1"><a href="logistic-regression-and-classification.html#cb828-1"></a><span class="co"># grow full tree</span></span>
<span id="cb828-2"><a href="logistic-regression-and-classification.html#cb828-2"></a>tree &lt;-<span class="st"> </span><span class="kw">rpart</span>(<span class="dt">data=</span>Default_Train, default<span class="op">~</span>balance <span class="op">+</span><span class="st"> </span>student)</span></code></pre></div>
<div class="sourceCode" id="cb829"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb829-1"><a href="logistic-regression-and-classification.html#cb829-1"></a>Tree_Prob &lt;-<span class="st"> </span><span class="kw">predict</span>(tree, <span class="dt">newdata =</span> Default_Test) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">2</span>)</span></code></pre></div>
<p>We add the decision tree probabilities to the table seen previously.</p>
<div class="sourceCode" id="cb830"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb830-1"><a href="logistic-regression-and-classification.html#cb830-1"></a>LR_Res_df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(student, balance, LR_Prob, Tree_Prob, Actual_Default)</span>
<span id="cb830-2"><a href="logistic-regression-and-classification.html#cb830-2"></a><span class="kw">kable</span>(<span class="kw">head</span>(LR_Res_df, <span class="dv">50</span>)<span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(LR_Prob)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>(<span class="dv">10</span>))</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">student</th>
<th align="right">balance</th>
<th align="right">LR_Prob</th>
<th align="right">Tree_Prob</th>
<th align="left">Actual_Default</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">2465</td>
<td align="left">Yes</td>
<td align="right">2026.864</td>
<td align="right">0.54</td>
<td align="right">0.77</td>
<td align="left">No</td>
</tr>
<tr class="even">
<td align="left">1228</td>
<td align="left">No</td>
<td align="right">1682.201</td>
<td align="right">0.26</td>
<td align="right">0.16</td>
<td align="left">No</td>
</tr>
<tr class="odd">
<td align="left">6656</td>
<td align="left">No</td>
<td align="right">1551.028</td>
<td align="right">0.14</td>
<td align="right">0.16</td>
<td align="left">No</td>
</tr>
<tr class="even">
<td align="left">1185</td>
<td align="left">No</td>
<td align="right">1541.813</td>
<td align="right">0.13</td>
<td align="right">0.16</td>
<td align="left">No</td>
</tr>
<tr class="odd">
<td align="left">9963</td>
<td align="left">Yes</td>
<td align="right">1635.175</td>
<td align="right">0.12</td>
<td align="right">0.16</td>
<td align="left">No</td>
</tr>
<tr class="even">
<td align="left">6635</td>
<td align="left">No</td>
<td align="right">1434.128</td>
<td align="right">0.07</td>
<td align="right">0.01</td>
<td align="left">Yes</td>
</tr>
<tr class="odd">
<td align="left">9691</td>
<td align="left">No</td>
<td align="right">1391.318</td>
<td align="right">0.06</td>
<td align="right">0.01</td>
<td align="left">No</td>
</tr>
<tr class="even">
<td align="left">5921</td>
<td align="left">Yes</td>
<td align="right">1513.542</td>
<td align="right">0.06</td>
<td align="right">0.16</td>
<td align="left">No</td>
</tr>
<tr class="odd">
<td align="left">9755</td>
<td align="left">No</td>
<td align="right">1233.619</td>
<td align="right">0.02</td>
<td align="right">0.01</td>
<td align="left">No</td>
</tr>
<tr class="even">
<td align="left">7569</td>
<td align="left">Yes</td>
<td align="right">1294.286</td>
<td align="right">0.02</td>
<td align="right">0.01</td>
<td align="left">No</td>
</tr>
</tbody>
</table>
<p>We see that the tree estimates that the first person has a 0.77 probability of defaulting on the payment, compared to an estimate of 0.54, given by the logistic regression model. On the other hand, the tree estimates only a 0.16 probability of the second person defaulting, compared to 0.26 for the logistic regression model.</p>
</div>
<div id="assessing-classifier-accuracy" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.3.3</span> Assessing Classifier Accuracy<a href="logistic-regression-and-classification.html#assessing-classifier-accuracy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Weâ€™ve seen <span class="math inline">\(\text{RMSPE} = \sqrt{\displaystyle\sum_{i=1}^{n}{(\hat{y}_i-y_i)^2}}\)</span> used as a measure of predictive accuracy in a regression problem.</p>
<p>Since our outcome is not numeric, this is not a good measure of predictive accuracy in a classification problem. Weâ€™ll examine some alternatives we can use instead.</p>
<p><strong>Classification Accuracy</strong></p>
<p>One simple approach is calculate the proportion of credit card users classified correctly. If a person has model estimates a predicted probability of default greater than 0.5, the person is predicted to default, while if the probability estimate is less than 0.5, the person is predicted to not default.</p>
<p>The table shows the prediction for each of the 10 users, using both logistic regression and the decision tree.</p>
<div class="sourceCode" id="cb831"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb831-1"><a href="logistic-regression-and-classification.html#cb831-1"></a>LR_Pred &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">ifelse</span>(LR_Prob <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.5</span>, <span class="st">&quot;Yes&quot;</span>, <span class="st">&quot;No&quot;</span>))</span>
<span id="cb831-2"><a href="logistic-regression-and-classification.html#cb831-2"></a>Tree_Pred &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">ifelse</span>(Tree_Prob <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.5</span>, <span class="st">&quot;Yes&quot;</span>, <span class="st">&quot;No&quot;</span>))</span>
<span id="cb831-3"><a href="logistic-regression-and-classification.html#cb831-3"></a>LR_Res_df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(student, balance, LR_Prob, Tree_Prob, LR_Pred,Tree_Pred, Actual_Default)</span>
<span id="cb831-4"><a href="logistic-regression-and-classification.html#cb831-4"></a><span class="kw">kable</span>(<span class="kw">head</span>(LR_Res_df, <span class="dv">50</span>)<span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(LR_Prob)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>(<span class="dv">10</span>))</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">student</th>
<th align="right">balance</th>
<th align="right">LR_Prob</th>
<th align="right">Tree_Prob</th>
<th align="left">LR_Pred</th>
<th align="left">Tree_Pred</th>
<th align="left">Actual_Default</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">2465</td>
<td align="left">Yes</td>
<td align="right">2026.864</td>
<td align="right">0.54</td>
<td align="right">0.77</td>
<td align="left">Yes</td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
<tr class="even">
<td align="left">1228</td>
<td align="left">No</td>
<td align="right">1682.201</td>
<td align="right">0.26</td>
<td align="right">0.16</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="left">No</td>
</tr>
<tr class="odd">
<td align="left">6656</td>
<td align="left">No</td>
<td align="right">1551.028</td>
<td align="right">0.14</td>
<td align="right">0.16</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="left">No</td>
</tr>
<tr class="even">
<td align="left">1185</td>
<td align="left">No</td>
<td align="right">1541.813</td>
<td align="right">0.13</td>
<td align="right">0.16</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="left">No</td>
</tr>
<tr class="odd">
<td align="left">9963</td>
<td align="left">Yes</td>
<td align="right">1635.175</td>
<td align="right">0.12</td>
<td align="right">0.16</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="left">No</td>
</tr>
<tr class="even">
<td align="left">6635</td>
<td align="left">No</td>
<td align="right">1434.128</td>
<td align="right">0.07</td>
<td align="right">0.01</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="left">Yes</td>
</tr>
<tr class="odd">
<td align="left">9691</td>
<td align="left">No</td>
<td align="right">1391.318</td>
<td align="right">0.06</td>
<td align="right">0.01</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="left">No</td>
</tr>
<tr class="even">
<td align="left">5921</td>
<td align="left">Yes</td>
<td align="right">1513.542</td>
<td align="right">0.06</td>
<td align="right">0.16</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="left">No</td>
</tr>
<tr class="odd">
<td align="left">9755</td>
<td align="left">No</td>
<td align="right">1233.619</td>
<td align="right">0.02</td>
<td align="right">0.01</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="left">No</td>
</tr>
<tr class="even">
<td align="left">7569</td>
<td align="left">Yes</td>
<td align="right">1294.286</td>
<td align="right">0.02</td>
<td align="right">0.01</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="left">No</td>
</tr>
</tbody>
</table>
<p>Notice that although the probabilities differ, the logistic regression model and classification tree give the same predictions for these ten cases. Both correctly predict 8 out of the 10 cases, but mistakenly predict the first person to default, when they didnâ€™t, and mistakenly predict that the sixth person would not default when they did.</p>
<p>Weâ€™ll check the classification accuracy for the model and the tree.</p>
<div class="sourceCode" id="cb832"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb832-1"><a href="logistic-regression-and-classification.html#cb832-1"></a><span class="kw">sum</span>(LR_Pred <span class="op">==</span><span class="st"> </span>Actual_Default)<span class="op">/</span><span class="dv">1000</span></span></code></pre></div>
<pre><code>## [1] 0.972</code></pre>
<div class="sourceCode" id="cb834"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb834-1"><a href="logistic-regression-and-classification.html#cb834-1"></a><span class="kw">sum</span>(Tree_Pred <span class="op">==</span><span class="st"> </span>Actual_Default)<span class="op">/</span><span class="dv">1000</span></span></code></pre></div>
<pre><code>## [1] 0.971</code></pre>
<p>We see that the two techniques are each right approximately 97% of the time.</p>
<p>This may not really be as good as it sounds. Can you think of a very simple classification strategy that would achieve a similarly impressive predictive accuracy on these data?</p>
</div>
<div id="confusion-matrix" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.3.4</span> Confusion Matrix<a href="logistic-regression-and-classification.html#confusion-matrix" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In addition to assessing overall accuracy, it is sometimes helpful to assess how well models are able to predict outcomes in each class. For example, how accurately can a model detect people who do actually default on their payments?</p>
<p>A <strong>confusion matrix</strong> is a two-by-two table displaying the number of cases predicted in each category as columns, and the number of cases actually in each category as rows</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Actually Negative</th>
<th>Actually Positive</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Predicted Negative</td>
<td># True Negative</td>
<td># False Negative</td>
</tr>
<tr class="even">
<td>Predicted Positive</td>
<td># False Positive</td>
<td># True Positive</td>
</tr>
</tbody>
</table>
<p>The <code>confusionMatrix</code> matrix command in R returns the confusion matrix for all 1,000 test cases.</p>
<p>Letâ€™s look at the confusion matrix for all 1,000 test cases. The <code>data</code> argument is the predicted outcome, and the <code>reference</code> argument is the true outcome. The <code>positive</code> argument is the category that weâ€™ll classify as a positive.</p>
<p><strong>Logistic Regression Confusion Matrix</strong></p>
<div class="sourceCode" id="cb836"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb836-1"><a href="logistic-regression-and-classification.html#cb836-1"></a><span class="kw">confusionMatrix</span>(<span class="dt">data=</span>LR_Pred, <span class="dt">reference=</span><span class="kw">factor</span>(Actual_Default) , <span class="dt">positive=</span><span class="st">&quot;Yes&quot;</span>)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  No Yes
##        No  957  20
##        Yes   8  15
##                                           
##                Accuracy : 0.972           
##                  95% CI : (0.9598, 0.9813)
##     No Information Rate : 0.965           
##     P-Value [Acc &gt; NIR] : 0.12988         
##                                           
##                   Kappa : 0.5035          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.03764         
##                                           
##             Sensitivity : 0.4286          
##             Specificity : 0.9917          
##          Pos Pred Value : 0.6522          
##          Neg Pred Value : 0.9795          
##              Prevalence : 0.0350          
##          Detection Rate : 0.0150          
##    Detection Prevalence : 0.0230          
##       Balanced Accuracy : 0.7101          
##                                           
##        &#39;Positive&#39; Class : Yes             
## </code></pre>
<p>Out of 965 people who did not default, the logistic regression model correctly predicted 957 of them.</p>
<p>Out of 35 people that did default, the model correctly predicted 15 of them.</p>
<p><strong>Tree Confusion Matrix</strong></p>
<div class="sourceCode" id="cb838"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb838-1"><a href="logistic-regression-and-classification.html#cb838-1"></a><span class="co"># data is predicted class</span></span>
<span id="cb838-2"><a href="logistic-regression-and-classification.html#cb838-2"></a><span class="co"># reference is actual class</span></span>
<span id="cb838-3"><a href="logistic-regression-and-classification.html#cb838-3"></a><span class="kw">confusionMatrix</span>( <span class="dt">data =</span> Tree_Pred , <span class="dt">reference=</span> Actual_Default, <span class="st">&quot;Yes&quot;</span>)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  No Yes
##        No  960  24
##        Yes   5  11
##                                           
##                Accuracy : 0.971           
##                  95% CI : (0.9586, 0.9805)
##     No Information Rate : 0.965           
##     P-Value [Acc &gt; NIR] : 0.1724819       
##                                           
##                   Kappa : 0.4186          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.0008302       
##                                           
##             Sensitivity : 0.3143          
##             Specificity : 0.9948          
##          Pos Pred Value : 0.6875          
##          Neg Pred Value : 0.9756          
##              Prevalence : 0.0350          
##          Detection Rate : 0.0110          
##    Detection Prevalence : 0.0160          
##       Balanced Accuracy : 0.6546          
##                                           
##        &#39;Positive&#39; Class : Yes             
## </code></pre>
<p>Out of 965 people who did not default, the logistic regression model correctly predicted 960 of them.</p>
<p>Out of 35 people that did default, the model correctly predicted 11 of them.</p>
<p>Notice that the tree was less likely to predict a person to default in general, returning only 16 positive predictions, compared to 23 for the logistic regression model.</p>
</div>
<div id="sensitivity-and-specificity" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.3.5</span> Sensitivity and Specificity<a href="logistic-regression-and-classification.html#sensitivity-and-specificity" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <strong>sensitivity</strong> of a classifier is the proportion of all positive cases that the model correctly identifies as positive. (i.e.Â probability model says â€œpositiveâ€ given actually is positive.)</p>
<p><span class="math display">\[
\text{Sensitivity} = \frac{\text{True Positive}}{\text{True Positive} + \text{False Negative}} = \frac{\text{Correctly Predicted Positives}}{\text{Total Number of Actual Positives}}
\]</span></p>
<p><strong>LR Sensitivity</strong></p>
<p><span class="math display">\[
\frac{15}{15+20} \approx 0.4286
\]</span></p>
<p><strong>Tree Sensitivity</strong></p>
<p><span class="math display">\[
\frac{11}{11+24} \approx 0.3143
\]</span></p>
<p>The <strong>specificity</strong> of a classifier is the proportion of all negative cases that the model correctly identifies as negative (i.e probabiltiy model says â€œnegativeâ€ given truly is negative.)</p>
<p><span class="math display">\[
\text{Specificity} = \frac{\text{True Negative}}{\text{True Negative} + \text{False Positive}}= \frac{\text{Correctly Predicted Negatives}}{\text{Total Number of Actual Negatives}}
\]</span></p>
<p><strong>LR Specificity</strong></p>
<p><span class="math display">\[
\frac{957}{957+8} \approx 0.9917
\]</span></p>
<p><strong>Tree Specificity</strong></p>
<p><span class="math display">\[
\frac{960}{960+5} \approx 0.9948
\]</span></p>
<p>In a given situation, we should think about the cost of a false negative vs a false positive when determining whether to place more weight on sensitivity or specificity. For example, â€œis it worse to tell a patient they tested positive for a disease when they really donâ€™t have it, or to not tell them they tested positive when they really do have it?â€</p>
</div>
</div>
<div id="receiver-operating-characteristic-curve" class="section level2 hasAnchor">
<h2><span class="header-section-number">8.4</span> Receiver Operating Characteristic Curve<a href="logistic-regression-and-classification.html#receiver-operating-characteristic-curve" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="separating-s-and--s" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.4.1</span> Separating +â€™s and -â€™s<a href="logistic-regression-and-classification.html#separating-s-and--s" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The prediction accuracy, sensitivity, and specificity measures, seen in the previous section are based only on the predicted outcome, without considering the probability estimates themselves. These techniques treat a 0.49 estimated probability of default the same as a 0.01 estimated probability.</p>
<p>We would hope to see more defaults among people with high estimated default probabilities than low ones. To assess this, we can list the people in order from highest to lowest probability estimates and see where the true defaults lie.</p>
<p>For example, consider the following fictional probability estimates produced by two different classifiers (models) for eight credit card users:</p>
<p><strong>Classifier 1</strong></p>
<pre><code>##   Classifier1_Probability_Estimate True_Outcome
## 1                             0.90          Yes
## 2                             0.75          Yes
## 3                             0.60           No
## 4                             0.40          Yes
## 5                             0.30           No
## 6                             0.15           No
## 7                             0.05           No
## 8                             0.01           No</code></pre>
<p><strong>Classifier 2</strong></p>
<pre><code>##   Classifier2_Probability_Estimate True_Outcome
## 1                             0.80          Yes
## 2                             0.70           No
## 3                             0.55           No
## 4                             0.40          Yes
## 5                             0.35           No
## 6                             0.15           No
## 7                             0.10          Yes
## 8                             0.02           No</code></pre>
<p>Classifier 1 is better able to separate the â€œYesâ€™sâ€ from â€œNoâ€™sâ€ as the three true â€œYesâ€™sâ€ are among the four highest probabilities. Classifier 2 is less able to separate the true â€œYesâ€™sâ€ from true â€œNoâ€™s.â€</p>
</div>
<div id="roc-curve" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.4.2</span> ROC Curve<a href="logistic-regression-and-classification.html#roc-curve" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A receiver operating characteristic (ROC) curve tells us how well a predictor is able to separate positive cases from negative cases.</p>
<p>The blog (Toward Data Science) [<a href="https://towardsdatascience.com/applications-of-different-parts-of-an-roc-curve-b534b1aafb68" class="uri">https://towardsdatascience.com/applications-of-different-parts-of-an-roc-curve-b534b1aafb68</a>] writes</p>
<p>â€œReceiver Operating Characteristic (ROC) curve is one of the most common graphical tools to diagnose the ability of a binary classifier, independent of the inherent classification algorithm. The ROC analysis has been used in many fields including medicine, radiology, biometrics, natural hazards forecasting, meteorology, model performance assessment, and other areas for many decades and is increasingly used in machine learning and data mining research [1]. If you are a Data Scientist, you might be using it on a daily basis.â€</p>
<p>The ROC curve plots the true positive (or hit) rate against the false positive rate (false alarm) rate, as the cutoff for a positive classification varies.</p>
<p><img src="Roc_curve.png" width="75%" /></p>
<p>The higher the curve, the better the predictor is able to separate positive cases from negative ones.</p>
<p>Predictions made totally at random would be expected to yield a diagonal ROC curve.</p>
</div>
<div id="constructing-roc-curve" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.4.3</span> Constructing ROC Curve<a href="logistic-regression-and-classification.html#constructing-roc-curve" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li>Order the probabilities from highest to lowest.<br />
</li>
<li>Assume only the case with the highest probability is predicted as a positive.<br />
</li>
<li>Calculate the true positive rate (hit rate) <span class="math inline">\(\frac{\text{# True Positives}}{\text{# Actual Positives}}\)</span> and false positive (false alarm) <span class="math inline">\(\frac{\text{# False Positives}}{\text{# Actual Negatives}}\)</span>rate.</li>
<li>Plot the point <span class="math inline">\(\left( \frac{\text{# False Positives}}{\text{# Actual Negatives}}, \frac{\text{# True Positives}}{\text{# Actual Positives}} \right)\)</span> in the coordinate plane.<br />
</li>
<li>Now assume the cases with the two highest probabilities are predicted as positives, and repeat steps 3-4.<br />
</li>
<li>Continue, by classifiying one more case as positive in each step.</li>
</ol>
</div>
<div id="construct-roc-example" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.4.4</span> Construct ROC Example<a href="logistic-regression-and-classification.html#construct-roc-example" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Letâ€™s practice constructing an ROC curve for a small set of probability estimates.</p>
<div class="sourceCode" id="cb842"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb842-1"><a href="logistic-regression-and-classification.html#cb842-1"></a>prob &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.9</span>, <span class="fl">0.8</span>, <span class="fl">0.7</span>, <span class="fl">0.65</span>, <span class="fl">0.45</span>, <span class="fl">0.3</span>, <span class="fl">0.2</span>, <span class="fl">0.15</span>, <span class="fl">0.1</span>, <span class="fl">0.05</span>)</span>
<span id="cb842-2"><a href="logistic-regression-and-classification.html#cb842-2"></a>Actual &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;+&quot;</span>, <span class="st">&quot;-&quot;</span>, <span class="st">&quot;+&quot;</span>, <span class="st">&quot;+&quot;</span>, <span class="st">&quot;-&quot;</span>, <span class="st">&quot;-&quot;</span>, <span class="st">&quot;-&quot;</span>, <span class="st">&quot;-&quot;</span>, <span class="st">&quot;+&quot;</span>, <span class="st">&quot;-&quot;</span>)</span>
<span id="cb842-3"><a href="logistic-regression-and-classification.html#cb842-3"></a>Hit_Rate &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;1/4&quot;</span>, <span class="st">&quot;1/4&quot;</span>, <span class="st">&quot;2/4&quot;</span>, <span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>)</span>
<span id="cb842-4"><a href="logistic-regression-and-classification.html#cb842-4"></a>FA_Rate &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;0/6&quot;</span>, <span class="st">&quot;1/6&quot;</span>, <span class="st">&quot;1/6&quot;</span>, <span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>)</span>
<span id="cb842-5"><a href="logistic-regression-and-classification.html#cb842-5"></a><span class="kw">kable</span>(<span class="kw">data.frame</span>(prob, Actual, Hit_Rate, FA_Rate))</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">prob</th>
<th align="left">Actual</th>
<th align="left">Hit_Rate</th>
<th align="left">FA_Rate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.90</td>
<td align="left">+</td>
<td align="left">1/4</td>
<td align="left">0/6</td>
</tr>
<tr class="even">
<td align="right">0.80</td>
<td align="left">-</td>
<td align="left">1/4</td>
<td align="left">1/6</td>
</tr>
<tr class="odd">
<td align="right">0.70</td>
<td align="left">+</td>
<td align="left">2/4</td>
<td align="left">1/6</td>
</tr>
<tr class="even">
<td align="right">0.65</td>
<td align="left">+</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="right">0.45</td>
<td align="left">-</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="right">0.30</td>
<td align="left">-</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="right">0.20</td>
<td align="left">-</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="right">0.15</td>
<td align="left">-</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="right">0.10</td>
<td align="left">+</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="right">0.05</td>
<td align="left">-</td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody>
</table>
<p>Finish filling in the table and sketch a graph of the resulting ROC curve.</p>
<p><strong>Question:</strong> If the probability estimate of 0.45 were instead 0.5 or 0.55, would this change the ROC curve? Why or why not?</p>
</div>
<div id="auc" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.4.5</span> AUC<a href="logistic-regression-and-classification.html#auc" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The area under the ROC curve, (AUC) provides a measure of the modelâ€™s predictive strength.</p>
<p>While there is no standard for what constitutes a <code>good" AUC, higher is better, and</code>AUC" is useful for comparing models.</p>
<p>A model that can perfectly separate successes from failures will have an AUC of 1.</p>
<p>A model that assigns probabilities at random is expected to have an AUC of 0.5.</p>
</div>
<div id="lr-and-tree-roc-curves" class="section level3 hasAnchor">
<h3><span class="header-section-number">8.4.6</span> LR and Tree ROC Curves<a href="logistic-regression-and-classification.html#lr-and-tree-roc-curves" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb843"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb843-1"><a href="logistic-regression-and-classification.html#cb843-1"></a><span class="kw">library</span>(pROC)</span>
<span id="cb843-2"><a href="logistic-regression-and-classification.html#cb843-2"></a><span class="kw">library</span>(verification)</span>
<span id="cb843-3"><a href="logistic-regression-and-classification.html#cb843-3"></a><span class="kw">roc.plot</span>(<span class="dt">x=</span>Default_Test<span class="op">$</span>default, <span class="dt">pred =</span> LR_Prob)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-649-1.png" width="672" /></p>
<div class="sourceCode" id="cb844"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb844-1"><a href="logistic-regression-and-classification.html#cb844-1"></a><span class="kw">auc</span>(<span class="dt">response=</span>Default_Test<span class="op">$</span>default, <span class="dt">predictor =</span> LR_Prob)</span></code></pre></div>
<pre><code>## Area under the curve: 0.8953</code></pre>
<div class="sourceCode" id="cb846"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb846-1"><a href="logistic-regression-and-classification.html#cb846-1"></a><span class="kw">roc.plot</span>(<span class="dt">x=</span>Default_Test<span class="op">$</span>default, <span class="dt">pred =</span> Tree_Prob)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-651-1.png" width="672" /></p>
<div class="sourceCode" id="cb847"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb847-1"><a href="logistic-regression-and-classification.html#cb847-1"></a><span class="kw">auc</span>(<span class="dt">response=</span>Default_Test<span class="op">$</span>default, <span class="dt">predictor =</span> Tree_Prob)</span></code></pre></div>
<pre><code>## Area under the curve: 0.8176</code></pre>
<div class="sourceCode" id="cb849"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb849-1"><a href="logistic-regression-and-classification.html#cb849-1"></a>RandProb &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">1000</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span></code></pre></div>
<div class="sourceCode" id="cb850"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb850-1"><a href="logistic-regression-and-classification.html#cb850-1"></a><span class="kw">roc.plot</span>(<span class="dt">x=</span>Default_Test<span class="op">$</span>default, <span class="dt">pred =</span> RandProb)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-654-1.png" width="672" /></p>
<div class="sourceCode" id="cb851"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb851-1"><a href="logistic-regression-and-classification.html#cb851-1"></a><span class="kw">auc</span>(<span class="dt">response=</span>Default_Test<span class="op">$</span>default, <span class="dt">predictor =</span> RandProb)</span></code></pre></div>
<pre><code>## Area under the curve: 0.563</code></pre>
<p>Even though a model that assigns predictions randomly, with 97% predicted as negatives will have a high accuracy rate, it will yield a poor ROC curve indicating an inability to separate positive cases from negative ones.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="predictive-modeling.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/Stat255-LU/Notes/edit/master/08-Logistic_Regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/Stat255-LU/Notes/blob/master/08-Logistic_Regression.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
