<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Normal Error Regression Model | Stat 255: Statistics for Data Science Notes</title>
  <meta name="description" content="Chapter 5 Normal Error Regression Model | Stat 255: Statistics for Data Science Notes" />
  <meta name="generator" content="bookdown 0.31 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Normal Error Regression Model | Stat 255: Statistics for Data Science Notes" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Normal Error Regression Model | Stat 255: Statistics for Data Science Notes" />
  
  
  

<meta name="author" content="Andrew Sage - Lawrence University" />


<meta name="date" content="2023-10-05" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="bootstrap-interval-estimation.html"/>
<link rel="next" href="model-building.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">STAT 255 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html"><i class="fa fa-check"></i><b>1</b> Exploratory Data Analysis</a>
<ul>
<li class="chapter" data-level="1.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#getting-started-in-r"><i class="fa fa-check"></i><b>1.1</b> Getting Started in R</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#previewing-the-data"><i class="fa fa-check"></i><b>1.1.1</b> Previewing the Data</a></li>
<li class="chapter" data-level="1.1.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#modifying-the-data"><i class="fa fa-check"></i><b>1.1.2</b> Modifying the Data</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#data-visualization"><i class="fa fa-check"></i><b>1.2</b> Data Visualization</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#histogram"><i class="fa fa-check"></i><b>1.2.1</b> Histogram</a></li>
<li class="chapter" data-level="1.2.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#density-plot"><i class="fa fa-check"></i><b>1.2.2</b> Density Plot</a></li>
<li class="chapter" data-level="1.2.3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boxplot"><i class="fa fa-check"></i><b>1.2.3</b> Boxplot</a></li>
<li class="chapter" data-level="1.2.4" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#violin-plot"><i class="fa fa-check"></i><b>1.2.4</b> Violin Plot</a></li>
<li class="chapter" data-level="1.2.5" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#scatterplot"><i class="fa fa-check"></i><b>1.2.5</b> Scatterplot</a></li>
<li class="chapter" data-level="1.2.6" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#bar-graph"><i class="fa fa-check"></i><b>1.2.6</b> Bar Graph</a></li>
<li class="chapter" data-level="1.2.7" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#stacked-and-side-by-side-bar-graphs"><i class="fa fa-check"></i><b>1.2.7</b> Stacked and Side-by-Side Bar Graphs</a></li>
<li class="chapter" data-level="1.2.8" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#correlation-plot"><i class="fa fa-check"></i><b>1.2.8</b> Correlation Plot</a></li>
<li class="chapter" data-level="1.2.9" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#scatterplot-matrix"><i class="fa fa-check"></i><b>1.2.9</b> Scatterplot Matrix</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#summary-tables"><i class="fa fa-check"></i><b>1.3</b> Summary Tables</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#calculating-summary-statistics"><i class="fa fa-check"></i><b>1.3.1</b> Calculating Summary Statistics</a></li>
<li class="chapter" data-level="1.3.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#grouped-summaries"><i class="fa fa-check"></i><b>1.3.2</b> Grouped Summaries</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html"><i class="fa fa-check"></i><b>2</b> Introduction to Statistical Models</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#fitting-models-to-data"><i class="fa fa-check"></i><b>2.1</b> Fitting Models to Data</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#terminology"><i class="fa fa-check"></i><b>2.1.1</b> Terminology</a></li>
<li class="chapter" data-level="2.1.2" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#model-with-quantitative-explanatory-variable"><i class="fa fa-check"></i><b>2.1.2</b> Model with Quantitative Explanatory Variable</a></li>
<li class="chapter" data-level="2.1.3" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#model-with-categorical-variable"><i class="fa fa-check"></i><b>2.1.3</b> Model with Categorical Variable</a></li>
<li class="chapter" data-level="2.1.4" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#model-with-multiple-explanatory-variables"><i class="fa fa-check"></i><b>2.1.4</b> Model with Multiple Explanatory Variables</a></li>
<li class="chapter" data-level="2.1.5" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#model-with-no-explanatory-variable"><i class="fa fa-check"></i><b>2.1.5</b> Model with No Explanatory Variable</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#variability-explained-by-a-model"><i class="fa fa-check"></i><b>2.2</b> Variability Explained by a Model</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#quantifying-variability"><i class="fa fa-check"></i><b>2.2.1</b> Quantifying Variability</a></li>
<li class="chapter" data-level="2.2.2" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#total-variability"><i class="fa fa-check"></i><b>2.2.2</b> Total Variability</a></li>
<li class="chapter" data-level="2.2.3" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#residuals"><i class="fa fa-check"></i><b>2.2.3</b> Residuals</a></li>
<li class="chapter" data-level="2.2.4" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#variability-explained-by-sq.-ft.-model"><i class="fa fa-check"></i><b>2.2.4</b> Variability Explained by Sq. Ft. Model</a></li>
<li class="chapter" data-level="2.2.5" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#linear-correlation-coefficient"><i class="fa fa-check"></i><b>2.2.5</b> Linear Correlation Coefficient</a></li>
<li class="chapter" data-level="2.2.6" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#variability-explained-by-waterfront-model"><i class="fa fa-check"></i><b>2.2.6</b> Variability Explained by Waterfront Model</a></li>
<li class="chapter" data-level="2.2.7" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#variability-explained-by-multiple-regression-model"><i class="fa fa-check"></i><b>2.2.7</b> Variability Explained by Multiple Regression Model</a></li>
<li class="chapter" data-level="2.2.8" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#summary-sst-ssr-ssm-r2"><i class="fa fa-check"></i><b>2.2.8</b> Summary: SST, SSR, SSM, <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="2.2.9" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#r2-visually"><i class="fa fa-check"></i><b>2.2.9</b> <span class="math inline">\(R^2\)</span> Visually</a></li>
<li class="chapter" data-level="2.2.10" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#model-comparison-summary"><i class="fa fa-check"></i><b>2.2.10</b> Model Comparison Summary</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#models-with-interaction"><i class="fa fa-check"></i><b>2.3</b> Models with Interaction</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#definition-of-interaction"><i class="fa fa-check"></i><b>2.3.1</b> Definition of Interaction</a></li>
<li class="chapter" data-level="2.3.2" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#interaction-term"><i class="fa fa-check"></i><b>2.3.2</b> Interaction Term</a></li>
<li class="chapter" data-level="2.3.3" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#interaction-models-in-r"><i class="fa fa-check"></i><b>2.3.3</b> Interaction Models in R</a></li>
<li class="chapter" data-level="2.3.4" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#r2-for-interaction-model"><i class="fa fa-check"></i><b>2.3.4</b> <span class="math inline">\(R^2\)</span> for Interaction Model</a></li>
<li class="chapter" data-level="2.3.5" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#considerations-for-using-interactions"><i class="fa fa-check"></i><b>2.3.5</b> Considerations for Using Interactions</a></li>
<li class="chapter" data-level="2.3.6" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#interaction-vs-correlation"><i class="fa fa-check"></i><b>2.3.6</b> Interaction vs Correlation</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#least-squares-estimation-lse"><i class="fa fa-check"></i><b>2.4</b> Least Squares Estimation (LSE)</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#estimating-regression-coefficients"><i class="fa fa-check"></i><b>2.4.1</b> Estimating Regression Coefficients</a></li>
<li class="chapter" data-level="2.4.2" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#mathematics-of-lse-for-slr"><i class="fa fa-check"></i><b>2.4.2</b> Mathematics of LSE for SLR</a></li>
<li class="chapter" data-level="2.4.3" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#lse-for-categorical-variable"><i class="fa fa-check"></i><b>2.4.3</b> LSE for Categorical Variable</a></li>
<li class="chapter" data-level="2.4.4" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#lse-more-generally"><i class="fa fa-check"></i><b>2.4.4</b> LSE More Generally</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#analysis-of-variance"><i class="fa fa-check"></i><b>2.5</b> ANalysis Of VAriance</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#submodels"><i class="fa fa-check"></i><b>2.5.1</b> Submodels</a></li>
<li class="chapter" data-level="2.5.2" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#f-statistics"><i class="fa fa-check"></i><b>2.5.2</b> F-Statistics</a></li>
<li class="chapter" data-level="2.5.3" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#comparing-3-or-more-categories"><i class="fa fa-check"></i><b>2.5.3</b> Comparing 3 or More Categories</a></li>
<li class="chapter" data-level="2.5.4" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#f-statistic-illustration"><i class="fa fa-check"></i><b>2.5.4</b> F-Statistic Illustration</a></li>
<li class="chapter" data-level="2.5.5" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#alternative-f-statistic-formula"><i class="fa fa-check"></i><b>2.5.5</b> Alternative F-Statistic Formula</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html"><i class="fa fa-check"></i><b>3</b> Hypothesis Testing via Permutation</a>
<ul>
<li class="chapter" data-level="3.1" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#test-for-difference-in-means"><i class="fa fa-check"></i><b>3.1</b> Test for Difference in Means</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#mercury-levels-in-florida-lakes"><i class="fa fa-check"></i><b>3.1.1</b> Mercury Levels in Florida Lakes</a></li>
<li class="chapter" data-level="3.1.2" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#model-for-mercury-level"><i class="fa fa-check"></i><b>3.1.2</b> Model for Mercury Level</a></li>
<li class="chapter" data-level="3.1.3" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#hypotheses-and-key-question"><i class="fa fa-check"></i><b>3.1.3</b> Hypotheses and Key Question</a></li>
<li class="chapter" data-level="3.1.4" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#permutation-test-for-difference-in-means"><i class="fa fa-check"></i><b>3.1.4</b> Permutation Test for Difference in Means</a></li>
<li class="chapter" data-level="3.1.5" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#five-permutations-in-r"><i class="fa fa-check"></i><b>3.1.5</b> Five Permutations in R</a></li>
<li class="chapter" data-level="3.1.6" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#r-code-for-permutation-test"><i class="fa fa-check"></i><b>3.1.6</b> R Code for Permutation Test</a></li>
<li class="chapter" data-level="3.1.7" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#p-values"><i class="fa fa-check"></i><b>3.1.7</b> p-values</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#general-permutation-tests"><i class="fa fa-check"></i><b>3.2</b> General Permutation Tests</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#other-test-statistics"><i class="fa fa-check"></i><b>3.2.1</b> Other Test Statistics</a></li>
<li class="chapter" data-level="3.2.2" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#general-permutation-test-procedure"><i class="fa fa-check"></i><b>3.2.2</b> General Permutation Test Procedure</a></li>
<li class="chapter" data-level="3.2.3" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#difference-in-standard-deviation"><i class="fa fa-check"></i><b>3.2.3</b> Difference in Standard Deviation</a></li>
<li class="chapter" data-level="3.2.4" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#permutation-test-for-slope"><i class="fa fa-check"></i><b>3.2.4</b> Permutation Test for Slope</a></li>
<li class="chapter" data-level="3.2.5" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#f-statistic"><i class="fa fa-check"></i><b>3.2.5</b> F-Statistic</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#responsible-hypothesis-testing"><i class="fa fa-check"></i><b>3.3</b> Responsible Hypothesis Testing</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html"><i class="fa fa-check"></i><b>4</b> Bootstrap Interval Estimation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#sampling-distributions"><i class="fa fa-check"></i><b>4.1</b> Sampling Distributions</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#sampling-from-a-population"><i class="fa fa-check"></i><b>4.1.1</b> Sampling From a Population</a></li>
<li class="chapter" data-level="4.1.2" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#confidence-intervals"><i class="fa fa-check"></i><b>4.1.2</b> Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrapping"><i class="fa fa-check"></i><b>4.2</b> Bootstrapping</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#mercury-levels-in-florida-lakes-1"><i class="fa fa-check"></i><b>4.2.1</b> Mercury Levels in Florida Lakes</a></li>
<li class="chapter" data-level="4.2.2" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrap-sampling"><i class="fa fa-check"></i><b>4.2.2</b> Bootstrap Sampling</a></li>
<li class="chapter" data-level="4.2.3" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrap-samples-of-lakes"><i class="fa fa-check"></i><b>4.2.3</b> Bootstrap Samples of Lakes</a></li>
<li class="chapter" data-level="4.2.4" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrap-distribution"><i class="fa fa-check"></i><b>4.2.4</b> Bootstrap Distribution</a></li>
<li class="chapter" data-level="4.2.5" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrap-se-confidence-interval"><i class="fa fa-check"></i><b>4.2.5</b> Bootstrap SE Confidence Interval</a></li>
<li class="chapter" data-level="4.2.6" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrap-distribution-vs-sampling-distribution"><i class="fa fa-check"></i><b>4.2.6</b> Bootstrap Distribution vs Sampling Distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrap-confidence-interval-example"><i class="fa fa-check"></i><b>4.3</b> Bootstrap Confidence Interval Example</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrapping-other-statistics"><i class="fa fa-check"></i><b>4.3.1</b> Bootstrapping Other Statistics</a></li>
<li class="chapter" data-level="4.3.2" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#ci-for-mean"><i class="fa fa-check"></i><b>4.3.2</b> CI for Mean</a></li>
<li class="chapter" data-level="4.3.3" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#ci-for-standard-deviation"><i class="fa fa-check"></i><b>4.3.3</b> CI for Standard Deviation</a></li>
<li class="chapter" data-level="4.3.4" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#ci-for-median"><i class="fa fa-check"></i><b>4.3.4</b> CI for Median</a></li>
<li class="chapter" data-level="4.3.5" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#ci-for-difference-in-means"><i class="fa fa-check"></i><b>4.3.5</b> CI for Difference in Means</a></li>
<li class="chapter" data-level="4.3.6" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#ci-for-regression-slope"><i class="fa fa-check"></i><b>4.3.6</b> CI for Regression Slope</a></li>
<li class="chapter" data-level="4.3.7" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#ci-for-regression-response"><i class="fa fa-check"></i><b>4.3.7</b> CI for Regression Response</a></li>
<li class="chapter" data-level="4.3.8" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#more-cis-in-regression"><i class="fa fa-check"></i><b>4.3.8</b> More CI’s in Regression</a></li>
<li class="chapter" data-level="4.3.9" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrapping-cautions"><i class="fa fa-check"></i><b>4.3.9</b> Bootstrapping Cautions</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#estimating-standard-error"><i class="fa fa-check"></i><b>4.4</b> Estimating Standard Error</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#standard-error-vs-standard-deviation"><i class="fa fa-check"></i><b>4.4.1</b> Standard Error vs Standard Deviation</a></li>
<li class="chapter" data-level="4.4.2" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#sample-size-and-standard-error"><i class="fa fa-check"></i><b>4.4.2</b> Sample Size and Standard Error</a></li>
<li class="chapter" data-level="4.4.3" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#standard-error-formulas"><i class="fa fa-check"></i><b>4.4.3</b> Standard Error Formulas</a></li>
<li class="chapter" data-level="4.4.4" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#one-sample-mean-example"><i class="fa fa-check"></i><b>4.4.4</b> One-Sample Mean Example</a></li>
<li class="chapter" data-level="4.4.5" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#difference-in-means-example"><i class="fa fa-check"></i><b>4.4.5</b> Difference in Means Example</a></li>
<li class="chapter" data-level="4.4.6" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#regression-example"><i class="fa fa-check"></i><b>4.4.6</b> Regression Example</a></li>
<li class="chapter" data-level="4.4.7" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#theory-based-confidence-intervals"><i class="fa fa-check"></i><b>4.4.7</b> Theory-Based Confidence Intervals</a></li>
<li class="chapter" data-level="4.4.8" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#ci-method-comparison"><i class="fa fa-check"></i><b>4.4.8</b> CI Method Comparison</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html"><i class="fa fa-check"></i><b>5</b> Normal Error Regression Model</a>
<ul>
<li class="chapter" data-level="5.1" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#the-normal-error-regression-model"><i class="fa fa-check"></i><b>5.1</b> The Normal Error Regression Model</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#example-ice-cream-dispensor"><i class="fa fa-check"></i><b>5.1.1</b> Example: Ice Cream Dispensor</a></li>
<li class="chapter" data-level="5.1.2" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#signal-and-noise"><i class="fa fa-check"></i><b>5.1.2</b> Signal and Noise</a></li>
<li class="chapter" data-level="5.1.3" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#normal-distribution"><i class="fa fa-check"></i><b>5.1.3</b> Normal Distribution</a></li>
<li class="chapter" data-level="5.1.4" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#signal-and-noise-in-icecream-example"><i class="fa fa-check"></i><b>5.1.4</b> Signal and Noise in Icecream Example</a></li>
<li class="chapter" data-level="5.1.5" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#normal-error-regression-model-1"><i class="fa fa-check"></i><b>5.1.5</b> Normal Error Regression Model</a></li>
<li class="chapter" data-level="5.1.6" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#examples-of-normal-error-regression-model"><i class="fa fa-check"></i><b>5.1.6</b> Examples of Normal Error Regression Model</a></li>
<li class="chapter" data-level="5.1.7" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#implications-of-normal-error-regresison-model"><i class="fa fa-check"></i><b>5.1.7</b> Implications of Normal Error Regresison Model</a></li>
<li class="chapter" data-level="5.1.8" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#philosophical-question"><i class="fa fa-check"></i><b>5.1.8</b> Philosophical Question</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="model-building.html"><a href="model-building.html"><i class="fa fa-check"></i><b>6</b> Model Building</a></li>
<li class="chapter" data-level="7" data-path="classification-and-logistic-regression.html"><a href="classification-and-logistic-regression.html"><i class="fa fa-check"></i><b>7</b> Classification and Logistic Regression</a></li>
<li class="chapter" data-level="8" data-path="predictive-modeling.html"><a href="predictive-modeling.html"><i class="fa fa-check"></i><b>8</b> Predictive Modeling</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Stat 255: Statistics for Data Science Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="normal-error-regression-model" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Normal Error Regression Model<a href="normal-error-regression-model.html#normal-error-regression-model" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><strong>Learning Outcomes:</strong></p>
<ol style="list-style-type: decimal">
<li><p>Explain when it is appropriate to use “theory-based” standard error formulas.<br />
</p></li>
<li><p>Interpret estimates, standard errors, test statistics, and p-values resulting from linear model output in R.<br />
</p></li>
<li><p>List the assumptions made in the normal error regression model.<br />
</p></li>
<li><p>Calculate p-values corresponding to t-statistics and F-statistics in R.<br />
</p></li>
<li><p>Interpret confidence intervals for an expected response, and prediction intervals, and distinguish between these two types of intervals.<br />
</p></li>
<li><p>Assess the whether linear model assumptions are reasonably satisfied, using residual plots, histograms, and normal QQ plots.<br />
</p></li>
<li><p>Explain when we should or should not expect p-values and confidence intervals obtained via “theory-based” approaches to agree with those obtained via simulation.</p></li>
<li><p>Identify situations where a log transformation of the response variable is appropriate.<br />
</p></li>
<li><p>Calculate predicted values for models involving a log transformation of the response variable.<br />
</p></li>
<li><p>Interpret regression coefficients in models involving a log transformation of the response variable.<br />
</p></li>
<li><p>Explain the regression effect.</p></li>
</ol>
<div id="the-normal-error-regression-model" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> The Normal Error Regression Model<a href="normal-error-regression-model.html#the-normal-error-regression-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>You’ve probably noticed that many (though not all) of the distributions of statistics associated with permutation-based hypothesis tests in Chapter 3 and bootstrap confidence intervals in Chapter 4 were symmetric and bell-shaped in nature. We also saw in Section 4.4 that certain statistics, such as differences in means, and regression coefficients have known standard error formulas, allowing us to approximate their standard errors without performing simulation.</p>
<p>When working with statistics that have symmetric and bell-shaped distributions and know standard error formulas, it is possible to use well-known probability facts to obtain confidence intervals and perform hypothesis tests without actually performing the simulation seen in Chapters 3 and 4. In order to be able to use these facts, however, we must know that the sampling distribution of our statistic is in fact symmetric and bell-shaped. One way to know that would be to actually perform the simulations and check the shape of the distribution. This, of course, would defeat the purpose of bypassing the simulations, however.</p>
<p>In this chapter, we’ll examine ways to check whether a statistic such as a mean, regression slope, or expected response will follow a symmetric and bell-shaped sampling distribution, without actually having to perform a simulation. For situations where the statistic does follow such a distribution, we’ll examine methods for obtaining confidence intervals and p-values, based on probability theory, rather than simulation.</p>
<div id="example-ice-cream-dispensor" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Example: Ice Cream Dispensor<a href="normal-error-regression-model.html#example-ice-cream-dispensor" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="Ice_Cream.png" width="50%" /></p>
<p>Suppose an ice cream machine is manufactured to dispense 2 oz. of ice cream per second, on average. If 15 people used the ice cream machine, holding the dispensor for different amounts of time, and each person got exactly 2 oz. per second, the relationship between time holding the dispensor and amount dispensed would look like this:</p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-354-1.png" width="672" /></p>
<p>In reality, however, the actual amount dispensed each time it is used will vary due to unknown factors like:</p>
<ul>
<li>force applied to dispensor<br />
</li>
<li>temperature<br />
</li>
<li>build-up of ice cream<br />
</li>
<li>other unknown factors</li>
</ul>
<p>Thus, if 15 real people held the dispenser and recorded the amount of ice cream they got, the scatter plot we would see would look something like this:</p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-355-1.png" width="672" /></p>
</div>
<div id="signal-and-noise" class="section level3 hasAnchor" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Signal and Noise<a href="normal-error-regression-model.html#signal-and-noise" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can think of the amount of ice cream a person receives as being a result of two separate components, often referred to as <strong>signal</strong> and <strong>noise</strong>.</p>
<p>Signal represents the average amount of ice cream a person is expected to receive based on the amount of time holding the dispenser. In this case, signal is given by the function <span class="math inline">\(\text{Expected Amount} = 2\times\text{Time}\)</span>. Everyone who holds the dispenser for <span class="math inline">\(t\)</span> seconds is expected to receive <span class="math inline">\(2t\)</span> ounces of ice cream.</p>
<p>Noise represents how much each person’s actual amount of ice cream deviates from their expected amount. For example, a person who holds the dispenser for 1.5 seconds and receives 3.58 oz. of ice cream will have received 0.58 ounces more than expected due to noise (i.e. factors beyond time holding the dispenser).</p>
<p>In a statistical model, we assume that the response value of a response variable we observe is the sum of the signal, or expected response, which is a function of the explanatory variables in the model, and noise, which results from deviations due to factos beyond those accounted for in the model.</p>
</div>
<div id="normal-distribution" class="section level3 hasAnchor" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> Normal Distribution<a href="normal-error-regression-model.html#normal-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>It is common to model noise using a symmetric, bell-shaped distribution, known as a <strong>normal distribution</strong>.</p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-356-1.png" width="576" /></p>
<p>We can think of the error term as a random draw from somewhere in the area below the bell-curve. For example, in the above illustration, most of the area under the curve lies between <span class="math inline">\(-1\leq x\leq 1\)</span>. If this curve represented the noise term in the ice cream example, it would mean that most people’s actual amount of ice cream dispensed would be within <span class="math inline">\(\pm 1\)</span> ounce of their expected amount (or signal). Notice that the normal distribution is centered at 0, indicating that on average, a person would be expected to get an amount exactly equal to their signal, but that they might deviate above or below this amount by unexplained factors, which can be modeled by random chance.</p>
<p>A normal distribution is defined by two parameters:<br />
- <span class="math inline">\(\mu\)</span> representing the center of the distribution<br />
- <span class="math inline">\(\sigma\)</span> representing the standard deviation</p>
<p>This distribution is denoted <span class="math inline">\(\mathcal{N}(\mu, \sigma)\)</span>.</p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-358-1.png" width="576" /></p>
<p>When the standard deviation is small, such as for the blue curve, noise tends to be close to 0, meaning the observed values will be close to their expectation. On the other hand, the green curve, which has higher standard deviation, would often produce noise values as extreme as <span class="math inline">\(\pm 2\)</span> or more.</p>
<p>Note that the square of the standard deviation <span class="math inline">\(\sigma^2\)</span> is called the variance. Some books denote the normal distribution as <span class="math inline">\(\mathcal{N}(\mu, \sigma^2)\)</span>, instead of <span class="math inline">\(\mathcal{N}(\mu,\sigma)\)</span>. We will use the <span class="math inline">\(\mathcal{N}(\mu,\sigma)\)</span> here, which is consistent with R.</p>
</div>
<div id="signal-and-noise-in-icecream-example" class="section level3 hasAnchor" number="5.1.4">
<h3><span class="header-section-number">5.1.4</span> Signal and Noise in Icecream Example<a href="normal-error-regression-model.html#signal-and-noise-in-icecream-example" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In this example, we’ll simulate the amount of ice cream dispensed for each person by adding a random number from a normal distribution with mean 0 and standard deviation 0.5 to the expected amount dispensed, which is given by <span class="math inline">\(2x\)</span>, where <span class="math inline">\(x\)</span> represents time pressing the dispenser. We’ll let <span class="math inline">\(\epsilon_i\)</span> represent the random noise term for the <span class="math inline">\(i\)</span> person.</p>
<p>Thus, amount dispensed (<span class="math inline">\(Y_i\)</span>) for person <span class="math inline">\(i\)</span> is given by</p>
<p><span class="math display">\[Y_i = 2x_i+\epsilon_i, \text{ where } \epsilon_i\sim\mathcal{N}(0, 0.5)
\]</span></p>
<p>We simulate the amount dispensed for a sample of 15 people below.</p>
<div class="sourceCode" id="cb493"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb493-1"><a href="normal-error-regression-model.html#cb493-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10082020</span>)</span>
<span id="cb493-2"><a href="normal-error-regression-model.html#cb493-2" aria-hidden="true" tabindex="-1"></a><span class="co"># set times </span></span>
<span id="cb493-3"><a href="normal-error-regression-model.html#cb493-3" aria-hidden="true" tabindex="-1"></a>time <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="fl">1.2</span>, <span class="fl">1.5</span>, <span class="fl">1.8</span>, <span class="fl">2.1</span>, <span class="fl">2.1</span>, <span class="fl">2.3</span>, <span class="fl">2.5</span>, <span class="fl">2.6</span>, <span class="fl">2.8</span>, <span class="fl">2.9</span>, <span class="fl">2.9</span>, <span class="fl">3.1</span>, <span class="fl">3.2</span>, <span class="fl">3.6</span>)</span>
<span id="cb493-4"><a href="normal-error-regression-model.html#cb493-4" aria-hidden="true" tabindex="-1"></a>expected <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">*</span>time  <span class="co"># expected amount</span></span>
<span id="cb493-5"><a href="normal-error-regression-model.html#cb493-5" aria-hidden="true" tabindex="-1"></a>noise <span class="ot">&lt;-</span><span class="fu">rnorm</span>(<span class="dv">15</span>, <span class="dv">0</span>, <span class="fl">0.5</span>) <span class="sc">%&gt;%</span> <span class="fu">round</span>(<span class="dv">2</span>)  <span class="co">#generate noise from normal distribution</span></span>
<span id="cb493-6"><a href="normal-error-regression-model.html#cb493-6" aria-hidden="true" tabindex="-1"></a>amount <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">*</span>time <span class="sc">+</span> noise  <span class="co"># calculate observed amounts</span></span>
<span id="cb493-7"><a href="normal-error-regression-model.html#cb493-7" aria-hidden="true" tabindex="-1"></a>Icecream <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(time, signal, noise, amount) <span class="co"># set up data table</span></span>
<span id="cb493-8"><a href="normal-error-regression-model.html#cb493-8" aria-hidden="true" tabindex="-1"></a><span class="fu">kable</span>((Icecream)) <span class="co">#display table</span></span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">time</th>
<th align="right">signal</th>
<th align="right">noise</th>
<th align="right">amount</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1.0</td>
<td align="right">2.0</td>
<td align="right">0.23</td>
<td align="right">2.23</td>
</tr>
<tr class="even">
<td align="right">1.2</td>
<td align="right">2.4</td>
<td align="right">-0.49</td>
<td align="right">1.91</td>
</tr>
<tr class="odd">
<td align="right">1.5</td>
<td align="right">3.0</td>
<td align="right">0.58</td>
<td align="right">3.58</td>
</tr>
<tr class="even">
<td align="right">1.8</td>
<td align="right">3.6</td>
<td align="right">-0.03</td>
<td align="right">3.57</td>
</tr>
<tr class="odd">
<td align="right">2.1</td>
<td align="right">4.2</td>
<td align="right">0.17</td>
<td align="right">4.37</td>
</tr>
<tr class="even">
<td align="right">2.1</td>
<td align="right">4.2</td>
<td align="right">-0.93</td>
<td align="right">3.27</td>
</tr>
<tr class="odd">
<td align="right">2.3</td>
<td align="right">4.6</td>
<td align="right">0.05</td>
<td align="right">4.65</td>
</tr>
<tr class="even">
<td align="right">2.5</td>
<td align="right">5.0</td>
<td align="right">-0.37</td>
<td align="right">4.63</td>
</tr>
<tr class="odd">
<td align="right">2.6</td>
<td align="right">5.2</td>
<td align="right">-0.46</td>
<td align="right">4.74</td>
</tr>
<tr class="even">
<td align="right">2.8</td>
<td align="right">5.6</td>
<td align="right">0.17</td>
<td align="right">5.77</td>
</tr>
<tr class="odd">
<td align="right">2.9</td>
<td align="right">5.8</td>
<td align="right">-0.59</td>
<td align="right">5.21</td>
</tr>
<tr class="even">
<td align="right">2.9</td>
<td align="right">5.8</td>
<td align="right">0.12</td>
<td align="right">5.92</td>
</tr>
<tr class="odd">
<td align="right">3.1</td>
<td align="right">6.2</td>
<td align="right">0.00</td>
<td align="right">6.20</td>
</tr>
<tr class="even">
<td align="right">3.2</td>
<td align="right">6.4</td>
<td align="right">0.67</td>
<td align="right">7.07</td>
</tr>
<tr class="odd">
<td align="right">3.6</td>
<td align="right">7.2</td>
<td align="right">0.05</td>
<td align="right">7.25</td>
</tr>
</tbody>
</table>
<p>The scatterplot displays the amount dispensed, compared to the time pressing the dispenser. The red line indicates the line <span class="math inline">\(y=2x\)</span>. If there was no random noise, then each person’s amount dispensed would lie exactly on this line.</p>
<div class="sourceCode" id="cb494"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb494-1"><a href="normal-error-regression-model.html#cb494-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>Icecream1, <span class="fu">aes</span>(<span class="at">x=</span>time, <span class="at">y=</span>amount)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Icecream Dispensed&quot;</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Time Pressing Dispensor&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Amount Dispensed&quot;</span>) <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="at">slope=</span><span class="dv">2</span>, <span class="at">intercept=</span><span class="dv">0</span>, <span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">+</span> </span>
<span id="cb494-2"><a href="normal-error-regression-model.html#cb494-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="at">label=</span><span class="st">&quot;y=2x&quot;</span>, <span class="at">x=</span> <span class="fl">3.5</span>, <span class="at">y=</span><span class="fl">6.5</span>, <span class="at">size=</span><span class="dv">10</span>, <span class="at">color=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-360-1.png" width="672" /></p>
<p>In a real situation, we would not see the signal and noise columns in the table or the red line on the graph. We would only see the time and amount, and points on the scatter plot. From these, we would need to estimate the location of the red line by fitting a least squares regression line to the data, as we’ve done before.</p>
<p>The blue line represents the location of the least squares regression line fit to the time and amounts observed.</p>
<div class="sourceCode" id="cb495"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb495-1"><a href="normal-error-regression-model.html#cb495-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>Icecream1, <span class="fu">aes</span>(<span class="at">x=</span>time, <span class="at">y=</span>amount)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Icecream Dispensed&quot;</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Time Pressing Dispensor&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Amount Dispensed&quot;</span>) <span class="sc">+</span> <span class="fu">stat_smooth</span>(<span class="at">method=</span><span class="st">&quot;lm&quot;</span>, <span class="at">se=</span><span class="cn">FALSE</span>) <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="at">slope=</span><span class="dv">2</span>, <span class="at">intercept=</span><span class="dv">0</span>, <span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">+</span> </span>
<span id="cb495-2"><a href="normal-error-regression-model.html#cb495-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="at">label=</span><span class="st">&quot;y=2x&quot;</span>, <span class="at">x=</span> <span class="fl">3.5</span>, <span class="at">y=</span><span class="fl">6.5</span>, <span class="at">size=</span><span class="dv">10</span>, <span class="at">color=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-361-1.png" width="672" />
The blue line is close, but not identical to the red line, representing the true (usually unknown) signal.</p>
<p>The slope and intercept of the blue line are given by:</p>
<div class="sourceCode" id="cb496"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb496-1"><a href="normal-error-regression-model.html#cb496-1" aria-hidden="true" tabindex="-1"></a>IC_Model <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>Icecream1, <span class="fu">lm</span>(amount<span class="sc">~</span>time))</span>
<span id="cb496-2"><a href="normal-error-regression-model.html#cb496-2" aria-hidden="true" tabindex="-1"></a>IC_Model</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = lm(amount ~ time), data = Icecream1)
## 
## Coefficients:
## (Intercept)         time  
##     -0.1299       2.0312</code></pre>
<p>Notice that these estimates are close, but not identical to the intercept and slope of the red line, which are 0 and 2, respectively.</p>
<p>The equation of the red line is given by:</p>
<p><span class="math inline">\(Y_i = \beta_0 + \beta_1X_{i} + \epsilon_i\)</span>, where <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0,\sigma)\)</span>,</p>
<p>where <span class="math inline">\(Y_i\)</span> represents amount dispensed, and <span class="math inline">\(X_i\)</span> represents time. <span class="math inline">\(\beta_0, \beta_1,\)</span>, and <span class="math inline">\(\sigma\)</span> are the unknown model parameters associated with the ice cream machine’s process.</p>
<p>Using the values of <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> obtained by fitting a model to our observed data as estimates of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, our estimated regression equation is</p>
<p><span class="math display">\[Y_i = b_0 + b_1X_i + \epsilon_i = -0.1299087 + 2.0312489X_i + \epsilon_i
\]</span></p>
<p>where <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0,\sigma)\)</span>.</p>
<p>An estimate for <span class="math inline">\(\sigma\)</span> is given by</p>
<p><span class="math inline">\(s =\sqrt{\frac{\text{SSR}}{n-(p+1)}} = \sqrt{\frac{\displaystyle\sum_{i=1}^n(y_i-\hat{y}_i)^2}{(n-(p+1))}}\)</span>.</p>
<p>We calculate this estimate of <span class="math inline">\(\hat{\sigma}\)</span>, using R.</p>
<div class="sourceCode" id="cb498"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb498-1"><a href="normal-error-regression-model.html#cb498-1" aria-hidden="true" tabindex="-1"></a>s <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>(IC_Model<span class="sc">$</span>residuals<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>(<span class="dv">15-2</span>))</span>
<span id="cb498-2"><a href="normal-error-regression-model.html#cb498-2" aria-hidden="true" tabindex="-1"></a>s</span></code></pre></div>
<pre><code>## [1] 0.4527185</code></pre>
<p>The estimates of <span class="math inline">\(b_0 = -0.1299087\)</span>, <span class="math inline">\(b_1=2.0312489\)</span>, and <span class="math inline">\(s = 0.4527185\)</span> are resonably close estimates to the values <span class="math inline">\(\beta_0=0, \beta_1=2\)</span>, and <span class="math inline">\(\sigma = 0.5\)</span>, that we used to generate the data.</p>
<p>In a real situation, we’ll have only statistics <span class="math inline">\(b_0\)</span>, <span class="math inline">\(b_1\)</span>, and <span class="math inline">\(s\)</span>, and we’ll need to use them to draw conclusions about parameters <span class="math inline">\(\beta_0=0, \beta_1=2\)</span>, and <span class="math inline">\(\sigma = 0.5\)</span>.</p>
</div>
<div id="normal-error-regression-model-1" class="section level3 hasAnchor" number="5.1.5">
<h3><span class="header-section-number">5.1.5</span> Normal Error Regression Model<a href="normal-error-regression-model.html#normal-error-regression-model-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the ice cream example, the relationship between expected amount and time holding the dispenser was given by a linear equation involving a single numeric explanatory variable. We can generalize this to situations with multiple explanatory variables, which might be numeric or categorical.</p>
<p>Individual observations are then assumed to vary from their expectation in accordance with a normal distribution, representing random noise (or error).</p>
<p>The mathematical form of a normal error linear regression model is</p>
<p><span class="math inline">\(Y_i = \beta_0 + \beta_1X_{i1}+ \ldots + \beta_pX_{ip} + \epsilon_i\)</span>, with <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0,\sigma)\)</span>.</p>
<p>Note that in place of <span class="math inline">\(X_{ip}\)</span>, we could have indicators for categories, or functions of <span class="math inline">\(X_{ip}\)</span>, such as <span class="math inline">\(X_{ip}^2\)</span>, <span class="math inline">\(\text{log}(X_{ip})\)</span>, or <span class="math inline">\(\text{sin}(X_{ip})\)</span>.</p>
<ul>
<li><p>The quantities <span class="math inline">\(\beta_0, \beta_1, \ldots, \beta_p\)</span> are parameters, pertaining to the true but unknown data generating mechanism.</p></li>
<li><p>The estimates <span class="math inline">\(b_0, b_1, \ldots, b_p\)</span>, are statistics, calculated from our observed data.<br />
</p></li>
<li><p>We use confidence intervals and hypothesis tests to make statements about parameters, based on information provided by statistics.</p></li>
</ul>
</div>
<div id="examples-of-normal-error-regression-model" class="section level3 hasAnchor" number="5.1.6">
<h3><span class="header-section-number">5.1.6</span> Examples of Normal Error Regression Model<a href="normal-error-regression-model.html#examples-of-normal-error-regression-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can formulate all of the examples we’ve worked with so far in terms of the normal error regression model.</p>
<p>In the house price example, consider the following models:</p>
<p><strong>Model 1:</strong>
<span class="math inline">\(\text{Price}_i = \beta_0 + \beta_1\text{Sq.Ft.}_{i} + \epsilon_i\)</span>, where <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0,\sigma)\)</span>.
If we use this model, we’re saying that we believe the expected price of a house is a linear function of its size, and that for any given size, the distribution of actual prices are normally distributed around their expected value of <span class="math inline">\(\beta_0 + \beta_1\text{Sq.Ft.}_{i}\)</span>.</p>
<p><strong>Model 2:</strong></p>
<p><span class="math inline">\(\text{Price}_i = \beta_0 + \beta_2\text{Waterfront}_{i}+ \epsilon_i\)</span>, where <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0,\sigma)\)</span>.</p>
<p>If we use this model, we’re saying that we believe the expected price of a house depends only on whether or not it is on the waterfront, and that prices of both waterfront and non-waterfront houses follow normal distributions, though these distributions may have different means (<span class="math inline">\(\beta_0\)</span> for non-waterfront houses, and <span class="math inline">\(\beta_1\)</span> for waterfront houses).</p>
<p><strong>Model 3:</strong></p>
<p><span class="math inline">\(\text{Price}_i = \beta_0 + \beta_1\text{Sq.Ft.}_{i}+ \beta_2\text{Waterfront}_{i}+ \beta_3\times\text{Sq.Ft.}_i\times\text{Waterfront}_{i} + \epsilon_i\)</span>, where <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0,\sigma)\)</span>.</p>
<p>and</p>
<p><strong>Model 4:</strong>
<span class="math inline">\(\text{Price}_i = \beta_0 + \beta_1\text{Sq.Ft.}_{i}+ \beta_2\text{Waterfront}_{i}+ \beta_3\times\text{Sq.Ft.}_i\times\text{Waterfront}_{i} + \epsilon_i\)</span>, where <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0,\sigma)\)</span>.</p>
<p>Both models assume that actual prices of houses with the same size and waterfront status are normally distributed, and that the mean of the normal distribution is a linear function of its size. Model 3 allows for the intercept of the lines to differ between waterfront and non-waterfront houses, while Model 4 allows both the intercept and slope to differ.</p>
</div>
<div id="implications-of-normal-error-regresison-model" class="section level3 hasAnchor" number="5.1.7">
<h3><span class="header-section-number">5.1.7</span> Implications of Normal Error Regresison Model<a href="normal-error-regression-model.html#implications-of-normal-error-regresison-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If we really believe that data come about as the normal error regression model describes, then probability theory tells us that regression coefficients <span class="math inline">\(b_j\)</span>’s, representing differences between categories for categorical variables and rates of change for quantitative variables, follow symmetric and bell-shaped distributions. We can use this fact, along with the standard error formulas in Section 4.4 to create confidence intervals and perform hypothesis tests, without needing to perform simulation. This is, in fact what R does in it’s model summary output.</p>
<p>These methods are only valid, however, if data can reasonably be thought of as having come the normal error regression model process. Thus, if we don’t believe that our observed data can be reasonably thought of terms representing underlying signal as a linear function of explanatory variables, and a normally distributed random error (or noise) term, then the confidence intervals and p-values produced by R, and other places that rely on probability-based methods will not be reliable.</p>
</div>
<div id="philosophical-question" class="section level3 hasAnchor" number="5.1.8">
<h3><span class="header-section-number">5.1.8</span> Philosophical Question<a href="normal-error-regression-model.html#philosophical-question" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We close the section with a philosophical question:</p>
<p>Do data really come about from processes like the normal error regression model? That is, do you think it is reasonable to believe that data we see in the real world (perhaps the amount of ice cream dispensed by an ice cream machine) is a combination of some true, but unknown equation involving the explanatory and response variables, and some unexplained noise, coming from a normal distribution?</p>
<p>We won’t attempt to answer that question here, but it is worth thinking about. After all, it is an assumption on which many frequently employed methods of statistical inference depends.</p>
<!---

## Inference in LLSR Model 

### `lm` `summary` Output 

Recall our linear model for mercury levels of lakes in Northern Florida, compared to Southern Florida. 

The equation of the model is:

\[
\widehat{\text{Mercury}} = \beta_0+\beta_1\times\text{South}
\]

We fit the model in R and display its summary output below.  


```r
summary(Lakes_M)
```

```
## 
## Call:
## lm(formula = Mercury ~ Location, data = FloridaLakes)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.65650 -0.23455 -0.08455  0.24350  0.67545 
## 
## Coefficients:
##             Estimate Std. Error t value       Pr(>|t|)    
## (Intercept)  0.42455    0.05519   7.692 0.000000000441 ***
## LocationS    0.27195    0.08985   3.027        0.00387 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.3171 on 51 degrees of freedom
## Multiple R-squared:  0.1523, Adjusted R-squared:  0.1357 
## F-statistic: 9.162 on 1 and 51 DF,  p-value: 0.003868
```

The estimated regression equation is 

\[
\widehat{\text{Mercury}} = 0.42455+0.27195\times\text{South}
\]

We've seen how to obtain the first two columns of the summary table, labeled "Estimate" and "Std. Error". 

The last column, labeled "Pr(>|t|)" is, in fact a p-value associated with associated with the null hypothesis that the regression parameter on that line is zero. (i.e. $\beta_j=0$).    

**Columns in Linear Model `summary()` Output**

* **Estimate** gives the least-squares estimates $b_0, b_1, \ldots, b_p$     

* **Standard Error** gives estimates of the standard deviation in the sampling distribution for estimate. (i.e. how much uncertainty is there about the estimate?) These are computed using the formulas in Section 4.7.   

* **t value** is the estimate divided by its standard error.     

* **Pr(>|t|)** is a p-value for the hypothesis test of whether quantity represented $b_j$ could plausibly be 0.   

### Example: Florida Lakes Hypothesis

**Hypothesis Test for line (intercept)**

**Null Hypothesis:** The average mercury level among all lakes in North Florida is 0 ($\beta_0=0$).   

**Alternative Hypothesis:** The average mercury level among all lakes in Northern Florida is not 0 ($\beta_0\neq 0$).  

We already know the average mercury level among all lakes in North Florida is not 0, so this is a silly test. 

**Hypothesis Test for line LocationS**

**Null Hypothesis:** There is no difference in average mercury levels between Northern and Southern Florida ($\beta_1=0$).   

**Alternative Hypothesis:** There is a difference in average mercury levels in Northern and Southern Florida ($\beta_1\neq 0$).  

This test is relevant to us.  

R does not obtain these p-values through simulation, but rather by using the  symmetric and bell-shaped t-distribution to approximate the distribution of these statistics. This is appropriate when the sampling distribution for our test statistic is reasonably symmetric and bell-shaped. 

You've probably noticed that the sampling distributions in our permutation-based hypothesis tests, and our bootstrap distributions for regression coefficients have been roughly symmetric and bell-shaped. When this happens, we can use a symmetric and bell-shaped distribution to model the distribution of a test statistic when the null hypothesis is true, bypassing the need to use simulation. 

There is statistical theory which shows that if data really do come from the normal error regression model process, like the ice cream dispenser in the previous section, then the ratio of regression coefficients (means, differences in means, slopes) divided by their standard error, will follow a symmetric bell-shaped distribution called a t-distribution.   

### t-distribution

A t-distribution is a symmetric, bell-shaped curve, with thicker tails (hence more variability), than a $\mathcal{N}(0,1)$ distribution.   





<img src="bookdownproj_files/figure-html/unnamed-chunk-367-1.png" width="768" />

### t-test

For data that come from a normal error regression model, we can use a t-distribution to approximate the sampling distribution used in our hypothesis tests, when the null hypothesis is assumed to be true. 

**Important Fact:** If $Y_i = \beta_0 + \beta_1X_{i1}+ \ldots + \beta_pX_{ip} + \epsilon_i$, with $\epsilon_i\sim\mathcal{N}(0,\sigma)$,  then   

\[
t= \frac{{b_j}}{\text{SE}(b_j)}  
\]

follows a t-distribution.

The $t=\frac{{b_j}}{\text{SE}(b_j)}$ is called a **t-statistic**.   

We'll use this t-statistic as the test statistic in our hypothesis test.  


###  t-test for N vs S Lakes

Recall the hypothesis test we performed to investigate whether there is a difference in average mercury level between lakes in Northern Florida and Southern Florida.   

**Null Hypothesis:** There is no difference in average mercury levels between Northern and Southern Florida ($\beta_1=0$).   

**Alternative Hypothesis:** There is a difference in average mercury levels in Northern and Southern Florida ($\beta_1\neq 0$).  

**Test Statistic**: $t=\frac{{b_j}}{\text{SE}(b_j)} = \frac{0.27195}{0.08985} = 3.027$ 

**Key Question:** What is the probability of getting a t-statistic as extreme as 3.027 if $\beta_1=0$ (i.e. there is no difference in mercury levels between northern and southern lakes).  

We plot the t-statistic of 3.027 that we observed in our data and observe where it lies on a t-distribution.  


```r
ts=3.027
gf_dist("t", df=51, geom = "area", fill = ~ (abs(x)< abs(ts)), show.legend=FALSE) + geom_vline(xintercept=c(ts, -ts), color="red")  + xlab("t")
```

<img src="bookdownproj_files/figure-html/unnamed-chunk-368-1.png" width="768" />




```r
2*pt(-abs(ts), df=51)
```

```
## [1] 0.003866374
```

The low p-value gives us strong evidence of a difference in average mercury levels between lakes in Northern and Southern Florida.  

### Comparison to Simulation

Let's compare these results to those given by the permutation test and bootstrap confidence interval.


**Permutation Test**


```r
NSLakes_SimulationResultsPlot
```

<img src="bookdownproj_files/figure-html/unnamed-chunk-370-1.png" width="672" />

p-value:


```r
b1 <- Lakes_M$coef[2] ## record value of b1 from actual data

mean(abs(NSLakes_SimulationResults$b1Sim) > abs(b1))
```

```
## [1] 0.0039
```


--->

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="bootstrap-interval-estimation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="model-building.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/Stat255-LU/Notes/edit/master/05-Normal_Error_Regression_Model.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/Stat255-LU/Notes/blob/master/05-Normal_Error_Regression_Model.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
