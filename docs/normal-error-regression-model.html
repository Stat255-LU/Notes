<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Normal Error Regression Model | Stat 255: Statistics for Data Science Notes</title>
  <meta name="description" content="Chapter 5 Normal Error Regression Model | Stat 255: Statistics for Data Science Notes" />
  <meta name="generator" content="bookdown 0.31 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Normal Error Regression Model | Stat 255: Statistics for Data Science Notes" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Normal Error Regression Model | Stat 255: Statistics for Data Science Notes" />
  
  
  

<meta name="author" content="Andrew Sage - Lawrence University" />


<meta name="date" content="2023-10-31" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="bootstrap-interval-estimation.html"/>
<link rel="next" href="building-models-for-interpretation.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">STAT 255 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html"><i class="fa fa-check"></i><b>1</b> Exploratory Data Analysis</a>
<ul>
<li class="chapter" data-level="1.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#getting-started-in-r"><i class="fa fa-check"></i><b>1.1</b> Getting Started in R</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#previewing-the-data"><i class="fa fa-check"></i><b>1.1.1</b> Previewing the Data</a></li>
<li class="chapter" data-level="1.1.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#modifying-the-data"><i class="fa fa-check"></i><b>1.1.2</b> Modifying the Data</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#data-visualization"><i class="fa fa-check"></i><b>1.2</b> Data Visualization</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#histogram"><i class="fa fa-check"></i><b>1.2.1</b> Histogram</a></li>
<li class="chapter" data-level="1.2.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#density-plot"><i class="fa fa-check"></i><b>1.2.2</b> Density Plot</a></li>
<li class="chapter" data-level="1.2.3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#boxplot"><i class="fa fa-check"></i><b>1.2.3</b> Boxplot</a></li>
<li class="chapter" data-level="1.2.4" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#violin-plot"><i class="fa fa-check"></i><b>1.2.4</b> Violin Plot</a></li>
<li class="chapter" data-level="1.2.5" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#scatterplot"><i class="fa fa-check"></i><b>1.2.5</b> Scatterplot</a></li>
<li class="chapter" data-level="1.2.6" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#bar-graph"><i class="fa fa-check"></i><b>1.2.6</b> Bar Graph</a></li>
<li class="chapter" data-level="1.2.7" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#stacked-and-side-by-side-bar-graphs"><i class="fa fa-check"></i><b>1.2.7</b> Stacked and Side-by-Side Bar Graphs</a></li>
<li class="chapter" data-level="1.2.8" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#correlation-plot"><i class="fa fa-check"></i><b>1.2.8</b> Correlation Plot</a></li>
<li class="chapter" data-level="1.2.9" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#scatterplot-matrix"><i class="fa fa-check"></i><b>1.2.9</b> Scatterplot Matrix</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#summary-tables"><i class="fa fa-check"></i><b>1.3</b> Summary Tables</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#calculating-summary-statistics"><i class="fa fa-check"></i><b>1.3.1</b> Calculating Summary Statistics</a></li>
<li class="chapter" data-level="1.3.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#grouped-summaries"><i class="fa fa-check"></i><b>1.3.2</b> Grouped Summaries</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html"><i class="fa fa-check"></i><b>2</b> Introduction to Statistical Models</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#fitting-models-to-data"><i class="fa fa-check"></i><b>2.1</b> Fitting Models to Data</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#terminology"><i class="fa fa-check"></i><b>2.1.1</b> Terminology</a></li>
<li class="chapter" data-level="2.1.2" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#model-with-quantitative-explanatory-variable"><i class="fa fa-check"></i><b>2.1.2</b> Model with Quantitative Explanatory Variable</a></li>
<li class="chapter" data-level="2.1.3" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#model-with-categorical-variable"><i class="fa fa-check"></i><b>2.1.3</b> Model with Categorical Variable</a></li>
<li class="chapter" data-level="2.1.4" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#model-with-multiple-explanatory-variables"><i class="fa fa-check"></i><b>2.1.4</b> Model with Multiple Explanatory Variables</a></li>
<li class="chapter" data-level="2.1.5" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#model-with-no-explanatory-variable"><i class="fa fa-check"></i><b>2.1.5</b> Model with No Explanatory Variable</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#variability-explained-by-a-model"><i class="fa fa-check"></i><b>2.2</b> Variability Explained by a Model</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#quantifying-variability"><i class="fa fa-check"></i><b>2.2.1</b> Quantifying Variability</a></li>
<li class="chapter" data-level="2.2.2" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#total-variability"><i class="fa fa-check"></i><b>2.2.2</b> Total Variability</a></li>
<li class="chapter" data-level="2.2.3" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#residuals"><i class="fa fa-check"></i><b>2.2.3</b> Residuals</a></li>
<li class="chapter" data-level="2.2.4" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#variability-explained-by-sq.-ft.-model"><i class="fa fa-check"></i><b>2.2.4</b> Variability Explained by Sq. Ft. Model</a></li>
<li class="chapter" data-level="2.2.5" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#linear-correlation-coefficient"><i class="fa fa-check"></i><b>2.2.5</b> Linear Correlation Coefficient</a></li>
<li class="chapter" data-level="2.2.6" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#variability-explained-by-waterfront-model"><i class="fa fa-check"></i><b>2.2.6</b> Variability Explained by Waterfront Model</a></li>
<li class="chapter" data-level="2.2.7" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#variability-explained-by-multiple-regression-model"><i class="fa fa-check"></i><b>2.2.7</b> Variability Explained by Multiple Regression Model</a></li>
<li class="chapter" data-level="2.2.8" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#summary-sst-ssr-ssm-r2"><i class="fa fa-check"></i><b>2.2.8</b> Summary: SST, SSR, SSM, <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="2.2.9" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#r2-visually"><i class="fa fa-check"></i><b>2.2.9</b> <span class="math inline">\(R^2\)</span> Visually</a></li>
<li class="chapter" data-level="2.2.10" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#model-comparison-summary"><i class="fa fa-check"></i><b>2.2.10</b> Model Comparison Summary</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#models-with-interaction"><i class="fa fa-check"></i><b>2.3</b> Models with Interaction</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#definition-of-interaction"><i class="fa fa-check"></i><b>2.3.1</b> Definition of Interaction</a></li>
<li class="chapter" data-level="2.3.2" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#interaction-term"><i class="fa fa-check"></i><b>2.3.2</b> Interaction Term</a></li>
<li class="chapter" data-level="2.3.3" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#interaction-models-in-r"><i class="fa fa-check"></i><b>2.3.3</b> Interaction Models in R</a></li>
<li class="chapter" data-level="2.3.4" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#r2-for-interaction-model"><i class="fa fa-check"></i><b>2.3.4</b> <span class="math inline">\(R^2\)</span> for Interaction Model</a></li>
<li class="chapter" data-level="2.3.5" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#considerations-for-using-interactions"><i class="fa fa-check"></i><b>2.3.5</b> Considerations for Using Interactions</a></li>
<li class="chapter" data-level="2.3.6" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#interaction-vs-correlation"><i class="fa fa-check"></i><b>2.3.6</b> Interaction vs Correlation</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#least-squares-estimation-lse"><i class="fa fa-check"></i><b>2.4</b> Least Squares Estimation (LSE)</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#estimating-regression-coefficients"><i class="fa fa-check"></i><b>2.4.1</b> Estimating Regression Coefficients</a></li>
<li class="chapter" data-level="2.4.2" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#mathematics-of-lse-for-slr"><i class="fa fa-check"></i><b>2.4.2</b> Mathematics of LSE for SLR</a></li>
<li class="chapter" data-level="2.4.3" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#lse-for-categorical-variable"><i class="fa fa-check"></i><b>2.4.3</b> LSE for Categorical Variable</a></li>
<li class="chapter" data-level="2.4.4" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#lse-more-generally"><i class="fa fa-check"></i><b>2.4.4</b> LSE More Generally</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#analysis-of-variance"><i class="fa fa-check"></i><b>2.5</b> ANalysis Of VAriance</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#submodels"><i class="fa fa-check"></i><b>2.5.1</b> Submodels</a></li>
<li class="chapter" data-level="2.5.2" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#f-statistics"><i class="fa fa-check"></i><b>2.5.2</b> F-Statistics</a></li>
<li class="chapter" data-level="2.5.3" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#comparing-3-or-more-categories"><i class="fa fa-check"></i><b>2.5.3</b> Comparing 3 or More Categories</a></li>
<li class="chapter" data-level="2.5.4" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#f-statistic-illustration"><i class="fa fa-check"></i><b>2.5.4</b> F-Statistic Illustration</a></li>
<li class="chapter" data-level="2.5.5" data-path="introduction-to-statistical-models.html"><a href="introduction-to-statistical-models.html#alternative-f-statistic-formula"><i class="fa fa-check"></i><b>2.5.5</b> Alternative F-Statistic Formula</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html"><i class="fa fa-check"></i><b>3</b> Hypothesis Testing via Permutation</a>
<ul>
<li class="chapter" data-level="3.1" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#test-for-difference-in-means"><i class="fa fa-check"></i><b>3.1</b> Test for Difference in Means</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#mercury-levels-in-florida-lakes"><i class="fa fa-check"></i><b>3.1.1</b> Mercury Levels in Florida Lakes</a></li>
<li class="chapter" data-level="3.1.2" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#model-for-mercury-level"><i class="fa fa-check"></i><b>3.1.2</b> Model for Mercury Level</a></li>
<li class="chapter" data-level="3.1.3" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#hypotheses-and-key-question"><i class="fa fa-check"></i><b>3.1.3</b> Hypotheses and Key Question</a></li>
<li class="chapter" data-level="3.1.4" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#permutation-test-for-difference-in-means"><i class="fa fa-check"></i><b>3.1.4</b> Permutation Test for Difference in Means</a></li>
<li class="chapter" data-level="3.1.5" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#five-permutations-in-r"><i class="fa fa-check"></i><b>3.1.5</b> Five Permutations in R</a></li>
<li class="chapter" data-level="3.1.6" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#r-code-for-permutation-test"><i class="fa fa-check"></i><b>3.1.6</b> R Code for Permutation Test</a></li>
<li class="chapter" data-level="3.1.7" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#p-values"><i class="fa fa-check"></i><b>3.1.7</b> p-values</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#general-permutation-tests"><i class="fa fa-check"></i><b>3.2</b> General Permutation Tests</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#other-test-statistics"><i class="fa fa-check"></i><b>3.2.1</b> Other Test Statistics</a></li>
<li class="chapter" data-level="3.2.2" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#general-permutation-test-procedure"><i class="fa fa-check"></i><b>3.2.2</b> General Permutation Test Procedure</a></li>
<li class="chapter" data-level="3.2.3" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#difference-in-standard-deviation"><i class="fa fa-check"></i><b>3.2.3</b> Difference in Standard Deviation</a></li>
<li class="chapter" data-level="3.2.4" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#permutation-test-for-slope"><i class="fa fa-check"></i><b>3.2.4</b> Permutation Test for Slope</a></li>
<li class="chapter" data-level="3.2.5" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#f-statistic"><i class="fa fa-check"></i><b>3.2.5</b> F-Statistic</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="hypothesis-testing-via-permutation.html"><a href="hypothesis-testing-via-permutation.html#responsible-hypothesis-testing"><i class="fa fa-check"></i><b>3.3</b> Responsible Hypothesis Testing</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html"><i class="fa fa-check"></i><b>4</b> Bootstrap Interval Estimation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#sampling-distributions"><i class="fa fa-check"></i><b>4.1</b> Sampling Distributions</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#sampling-from-a-population"><i class="fa fa-check"></i><b>4.1.1</b> Sampling From a Population</a></li>
<li class="chapter" data-level="4.1.2" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#confidence-intervals"><i class="fa fa-check"></i><b>4.1.2</b> Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrapping"><i class="fa fa-check"></i><b>4.2</b> Bootstrapping</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#mercury-levels-in-florida-lakes-1"><i class="fa fa-check"></i><b>4.2.1</b> Mercury Levels in Florida Lakes</a></li>
<li class="chapter" data-level="4.2.2" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrap-sampling"><i class="fa fa-check"></i><b>4.2.2</b> Bootstrap Sampling</a></li>
<li class="chapter" data-level="4.2.3" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrap-samples-of-lakes"><i class="fa fa-check"></i><b>4.2.3</b> Bootstrap Samples of Lakes</a></li>
<li class="chapter" data-level="4.2.4" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrap-distribution"><i class="fa fa-check"></i><b>4.2.4</b> Bootstrap Distribution</a></li>
<li class="chapter" data-level="4.2.5" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrap-se-confidence-interval"><i class="fa fa-check"></i><b>4.2.5</b> Bootstrap SE Confidence Interval</a></li>
<li class="chapter" data-level="4.2.6" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrap-distribution-vs-sampling-distribution"><i class="fa fa-check"></i><b>4.2.6</b> Bootstrap Distribution vs Sampling Distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrap-confidence-interval-example"><i class="fa fa-check"></i><b>4.3</b> Bootstrap Confidence Interval Example</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrapping-other-statistics"><i class="fa fa-check"></i><b>4.3.1</b> Bootstrapping Other Statistics</a></li>
<li class="chapter" data-level="4.3.2" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#ci-for-mean"><i class="fa fa-check"></i><b>4.3.2</b> CI for Mean</a></li>
<li class="chapter" data-level="4.3.3" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#ci-for-standard-deviation"><i class="fa fa-check"></i><b>4.3.3</b> CI for Standard Deviation</a></li>
<li class="chapter" data-level="4.3.4" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#ci-for-median"><i class="fa fa-check"></i><b>4.3.4</b> CI for Median</a></li>
<li class="chapter" data-level="4.3.5" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#ci-for-difference-in-means"><i class="fa fa-check"></i><b>4.3.5</b> CI for Difference in Means</a></li>
<li class="chapter" data-level="4.3.6" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#ci-for-regression-slope"><i class="fa fa-check"></i><b>4.3.6</b> CI for Regression Slope</a></li>
<li class="chapter" data-level="4.3.7" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#ci-for-regression-response"><i class="fa fa-check"></i><b>4.3.7</b> CI for Regression Response</a></li>
<li class="chapter" data-level="4.3.8" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#more-cis-in-regression"><i class="fa fa-check"></i><b>4.3.8</b> More CI’s in Regression</a></li>
<li class="chapter" data-level="4.3.9" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#bootstrapping-cautions"><i class="fa fa-check"></i><b>4.3.9</b> Bootstrapping Cautions</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#estimating-standard-error"><i class="fa fa-check"></i><b>4.4</b> Estimating Standard Error</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#standard-error-vs-standard-deviation"><i class="fa fa-check"></i><b>4.4.1</b> Standard Error vs Standard Deviation</a></li>
<li class="chapter" data-level="4.4.2" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#sample-size-and-standard-error"><i class="fa fa-check"></i><b>4.4.2</b> Sample Size and Standard Error</a></li>
<li class="chapter" data-level="4.4.3" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#standard-error-formulas"><i class="fa fa-check"></i><b>4.4.3</b> Standard Error Formulas</a></li>
<li class="chapter" data-level="4.4.4" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#one-sample-mean-example"><i class="fa fa-check"></i><b>4.4.4</b> One-Sample Mean Example</a></li>
<li class="chapter" data-level="4.4.5" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#difference-in-means-example"><i class="fa fa-check"></i><b>4.4.5</b> Difference in Means Example</a></li>
<li class="chapter" data-level="4.4.6" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#regression-example"><i class="fa fa-check"></i><b>4.4.6</b> Regression Example</a></li>
<li class="chapter" data-level="4.4.7" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#theory-based-confidence-intervals"><i class="fa fa-check"></i><b>4.4.7</b> Theory-Based Confidence Intervals</a></li>
<li class="chapter" data-level="4.4.8" data-path="bootstrap-interval-estimation.html"><a href="bootstrap-interval-estimation.html#ci-method-comparison"><i class="fa fa-check"></i><b>4.4.8</b> CI Method Comparison</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html"><i class="fa fa-check"></i><b>5</b> Normal Error Regression Model</a>
<ul>
<li class="chapter" data-level="5.1" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#the-normal-error-regression-model"><i class="fa fa-check"></i><b>5.1</b> The Normal Error Regression Model</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#example-ice-cream-dispenser"><i class="fa fa-check"></i><b>5.1.1</b> Example: Ice Cream dispenser</a></li>
<li class="chapter" data-level="5.1.2" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#signal-and-noise"><i class="fa fa-check"></i><b>5.1.2</b> Signal and Noise</a></li>
<li class="chapter" data-level="5.1.3" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#normal-distribution"><i class="fa fa-check"></i><b>5.1.3</b> Normal Distribution</a></li>
<li class="chapter" data-level="5.1.4" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#signal-and-noise-in-icecream-example"><i class="fa fa-check"></i><b>5.1.4</b> Signal and Noise in Icecream Example</a></li>
<li class="chapter" data-level="5.1.5" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#normal-error-regression-model-1"><i class="fa fa-check"></i><b>5.1.5</b> Normal Error Regression Model</a></li>
<li class="chapter" data-level="5.1.6" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#examples-of-normal-error-regression-model"><i class="fa fa-check"></i><b>5.1.6</b> Examples of Normal Error Regression Model</a></li>
<li class="chapter" data-level="5.1.7" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#implications-of-normal-error-regression-model"><i class="fa fa-check"></i><b>5.1.7</b> Implications of Normal Error Regression Model</a></li>
<li class="chapter" data-level="5.1.8" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#philosophical-question"><i class="fa fa-check"></i><b>5.1.8</b> Philosophical Question</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#inference-in-normal-error-regression-model"><i class="fa fa-check"></i><b>5.2</b> Inference in Normal Error Regression Model</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#lm-summary-output"><i class="fa fa-check"></i><b>5.2.1</b> <code>lm</code> <code>summary</code> Output</a></li>
<li class="chapter" data-level="5.2.2" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#t-distribution"><i class="fa fa-check"></i><b>5.2.2</b> t-distribution</a></li>
<li class="chapter" data-level="5.2.3" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#difference-in-means-example-1"><i class="fa fa-check"></i><b>5.2.3</b> Difference in Means Example</a></li>
<li class="chapter" data-level="5.2.4" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#simple-linear-regression-example"><i class="fa fa-check"></i><b>5.2.4</b> Simple Linear Regression Example</a></li>
<li class="chapter" data-level="5.2.5" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#multiple-regression-example"><i class="fa fa-check"></i><b>5.2.5</b> Multiple Regression Example</a></li>
<li class="chapter" data-level="5.2.6" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#mr-with-interaction-example"><i class="fa fa-check"></i><b>5.2.6</b> MR with Interaction Example</a></li>
<li class="chapter" data-level="5.2.7" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#limitations"><i class="fa fa-check"></i><b>5.2.7</b> Limitations</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#f-distributions"><i class="fa fa-check"></i><b>5.3</b> F-Distributions</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#f-distribution"><i class="fa fa-check"></i><b>5.3.1</b> F-Distribution</a></li>
<li class="chapter" data-level="5.3.2" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#house-condition-example"><i class="fa fa-check"></i><b>5.3.2</b> House Condition Example</a></li>
<li class="chapter" data-level="5.3.3" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#interaction-example"><i class="fa fa-check"></i><b>5.3.3</b> Interaction Example</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#regression-model-assumptions"><i class="fa fa-check"></i><b>5.4</b> Regression Model Assumptions</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#regression-assumptions"><i class="fa fa-check"></i><b>5.4.1</b> Regression Assumptions</a></li>
<li class="chapter" data-level="5.4.2" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#checking-model-assumptions"><i class="fa fa-check"></i><b>5.4.2</b> Checking Model Assumptions</a></li>
<li class="chapter" data-level="5.4.3" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#summary-of-checks-for-model-assumptions"><i class="fa fa-check"></i><b>5.4.3</b> Summary of Checks for Model Assumptions</a></li>
<li class="chapter" data-level="5.4.4" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#example-n-v-s-lakes"><i class="fa fa-check"></i><b>5.4.4</b> Example: N v S Lakes</a></li>
<li class="chapter" data-level="5.4.5" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#example-ph-model"><i class="fa fa-check"></i><b>5.4.5</b> Example: pH Model</a></li>
<li class="chapter" data-level="5.4.6" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#example-house-prices"><i class="fa fa-check"></i><b>5.4.6</b> Example: House Prices</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#intervals-for-expected-response"><i class="fa fa-check"></i><b>5.5</b> Intervals for Expected Response</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#parameter-values-and-expected-responses"><i class="fa fa-check"></i><b>5.5.1</b> Parameter Values and Expected Responses</a></li>
<li class="chapter" data-level="5.5.2" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#estimation-and-prediction"><i class="fa fa-check"></i><b>5.5.2</b> Estimation and Prediction</a></li>
<li class="chapter" data-level="5.5.3" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#estimation-and-prediction-in-slr"><i class="fa fa-check"></i><b>5.5.3</b> Estimation and Prediction in SLR</a></li>
<li class="chapter" data-level="5.5.4" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#intervals-in-r"><i class="fa fa-check"></i><b>5.5.4</b> Intervals in R</a></li>
<li class="chapter" data-level="5.5.5" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#slr-calculations-optional"><i class="fa fa-check"></i><b>5.5.5</b> SLR Calculations (Optional)</a></li>
<li class="chapter" data-level="5.5.6" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#car-price-and-acceleration-time"><i class="fa fa-check"></i><b>5.5.6</b> Car Price and Acceleration Time</a></li>
<li class="chapter" data-level="5.5.7" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#florida-lakes-est.-and-pred."><i class="fa fa-check"></i><b>5.5.7</b> Florida Lakes Est. and Pred.</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#transformations"><i class="fa fa-check"></i><b>5.6</b> Transformations</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#cars-assumptions-check"><i class="fa fa-check"></i><b>5.6.1</b> Cars Assumptions Check</a></li>
<li class="chapter" data-level="5.6.2" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#log-transformation"><i class="fa fa-check"></i><b>5.6.2</b> Log Transformation</a></li>
<li class="chapter" data-level="5.6.3" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#log-transform-for-car-prices"><i class="fa fa-check"></i><b>5.6.3</b> Log Transform for Car Prices</a></li>
<li class="chapter" data-level="5.6.4" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#log-model-predictions"><i class="fa fa-check"></i><b>5.6.4</b> Log Model Predictions</a></li>
<li class="chapter" data-level="5.6.5" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#log-model-interpretations"><i class="fa fa-check"></i><b>5.6.5</b> Log Model Interpretations</a></li>
<li class="chapter" data-level="5.6.6" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#log-model-ci-for-beta_0-beta_1"><i class="fa fa-check"></i><b>5.6.6</b> Log Model CI for <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span></a></li>
<li class="chapter" data-level="5.6.7" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#log-model-ci-for-expected-response"><i class="fa fa-check"></i><b>5.6.7</b> Log Model CI for Expected Response</a></li>
<li class="chapter" data-level="5.6.8" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#log-model-prediction-interval"><i class="fa fa-check"></i><b>5.6.8</b> Log Model Prediction Interval</a></li>
<li class="chapter" data-level="5.6.9" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#confidence-interval-comparison"><i class="fa fa-check"></i><b>5.6.9</b> Confidence Interval Comparison</a></li>
<li class="chapter" data-level="5.6.10" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#prediction-interval-comparison"><i class="fa fa-check"></i><b>5.6.10</b> Prediction Interval Comparison</a></li>
<li class="chapter" data-level="5.6.11" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#log-model-visualization"><i class="fa fa-check"></i><b>5.6.11</b> Log Model Visualization</a></li>
<li class="chapter" data-level="5.6.12" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#comments-on-transformations"><i class="fa fa-check"></i><b>5.6.12</b> Comments on Transformations</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#case-studies"><i class="fa fa-check"></i><b>5.7</b> Case Studies</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#flights-from-ny-to-chi"><i class="fa fa-check"></i><b>5.7.1</b> Flights from NY to CHI</a></li>
<li class="chapter" data-level="5.7.2" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#smoking-during-pregnancy"><i class="fa fa-check"></i><b>5.7.2</b> Smoking During Pregnancy</a></li>
<li class="chapter" data-level="5.7.3" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#smoking-during-pregnancy-cont"><i class="fa fa-check"></i><b>5.7.3</b> Smoking During Pregnancy (cont)</a></li>
<li class="chapter" data-level="5.7.4" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#exam-scores"><i class="fa fa-check"></i><b>5.7.4</b> Exam Scores</a></li>
<li class="chapter" data-level="5.7.5" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#simulating-the-regression-effect"><i class="fa fa-check"></i><b>5.7.5</b> Simulating the Regression Effect</a></li>
<li class="chapter" data-level="5.7.6" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#nfl-wins"><i class="fa fa-check"></i><b>5.7.6</b> NFL Wins</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="normal-error-regression-model.html"><a href="normal-error-regression-model.html#impact-of-model-assumption-violations"><i class="fa fa-check"></i><b>5.8</b> Impact of Model Assumption Violations</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html"><i class="fa fa-check"></i><b>6</b> Building Models for Interpretation</a>
<ul>
<li class="chapter" data-level="6.1" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#model-building---sat-scores"><i class="fa fa-check"></i><b>6.1</b> Model Building - SAT Scores</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#modeling-for-interpretation"><i class="fa fa-check"></i><b>6.1.1</b> Modeling for Interpretation</a></li>
<li class="chapter" data-level="6.1.2" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#sat-scores-dataset"><i class="fa fa-check"></i><b>6.1.2</b> SAT Scores Dataset</a></li>
<li class="chapter" data-level="6.1.3" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#research-question"><i class="fa fa-check"></i><b>6.1.3</b> Research Question</a></li>
<li class="chapter" data-level="6.1.4" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#teacher-salary-and-sat-score"><i class="fa fa-check"></i><b>6.1.4</b> Teacher Salary and SAT score</a></li>
<li class="chapter" data-level="6.1.5" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#a-deeper-investigation"><i class="fa fa-check"></i><b>6.1.5</b> A Deeper Investigation</a></li>
<li class="chapter" data-level="6.1.6" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#student-to-teacher-ratio"><i class="fa fa-check"></i><b>6.1.6</b> Student-to-Teacher Ratio</a></li>
<li class="chapter" data-level="6.1.7" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#multicollinearity"><i class="fa fa-check"></i><b>6.1.7</b> Multicollinearity</a></li>
<li class="chapter" data-level="6.1.8" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#check-model-assumptions"><i class="fa fa-check"></i><b>6.1.8</b> Check Model Assumptions</a></li>
<li class="chapter" data-level="6.1.9" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#quadratic-term"><i class="fa fa-check"></i><b>6.1.9</b> Quadratic Term</a></li>
<li class="chapter" data-level="6.1.10" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#account-for-region"><i class="fa fa-check"></i><b>6.1.10</b> Account for Region?</a></li>
<li class="chapter" data-level="6.1.11" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#predictions-and-intervals"><i class="fa fa-check"></i><b>6.1.11</b> Predictions and Intervals</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#modeling-car-price"><i class="fa fa-check"></i><b>6.2</b> Modeling Car Price</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#model-for-price-of-2015-cars"><i class="fa fa-check"></i><b>6.2.1</b> Model for Price of 2015 Cars</a></li>
<li class="chapter" data-level="6.2.2" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#acc.-and-qrt.-mile-time"><i class="fa fa-check"></i><b>6.2.2</b> Acc. and Qrt. Mile Time</a></li>
<li class="chapter" data-level="6.2.3" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#adding-weight-to-model"><i class="fa fa-check"></i><b>6.2.3</b> Adding Weight to Model</a></li>
<li class="chapter" data-level="6.2.4" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#adding-more-variables"><i class="fa fa-check"></i><b>6.2.4</b> Adding More Variables</a></li>
<li class="chapter" data-level="6.2.5" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#check-of-model-assumptions"><i class="fa fa-check"></i><b>6.2.5</b> Check of Model Assumptions</a></li>
<li class="chapter" data-level="6.2.6" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#coefficients-and-exponentiation"><i class="fa fa-check"></i><b>6.2.6</b> Coefficients and Exponentiation</a></li>
<li class="chapter" data-level="6.2.7" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#confidence-and-prediction-intevals"><i class="fa fa-check"></i><b>6.2.7</b> Confidence and Prediction Intevals</a></li>
<li class="chapter" data-level="6.2.8" data-path="building-models-for-interpretation.html"><a href="building-models-for-interpretation.html#model-building-summary"><i class="fa fa-check"></i><b>6.2.8</b> Model Building Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="predictive-modeling.html"><a href="predictive-modeling.html"><i class="fa fa-check"></i><b>7</b> Predictive Modeling</a>
<ul>
<li class="chapter" data-level="7.1" data-path="predictive-modeling.html"><a href="predictive-modeling.html#modeling-for-prediction"><i class="fa fa-check"></i><b>7.1</b> Modeling for Prediction</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="predictive-modeling.html"><a href="predictive-modeling.html#overview"><i class="fa fa-check"></i><b>7.1.1</b> Overview</a></li>
<li class="chapter" data-level="7.1.2" data-path="predictive-modeling.html"><a href="predictive-modeling.html#illustration-of-predictive-modeling"><i class="fa fa-check"></i><b>7.1.2</b> Illustration of Predictive Modeling</a></li>
<li class="chapter" data-level="7.1.3" data-path="predictive-modeling.html"><a href="predictive-modeling.html#predicting-new-data"><i class="fa fa-check"></i><b>7.1.3</b> Predicting New Data</a></li>
<li class="chapter" data-level="7.1.4" data-path="predictive-modeling.html"><a href="predictive-modeling.html#evaluating-predictions---rmspe"><i class="fa fa-check"></i><b>7.1.4</b> Evaluating Predictions - RMSPE</a></li>
<li class="chapter" data-level="7.1.5" data-path="predictive-modeling.html"><a href="predictive-modeling.html#training-data-error"><i class="fa fa-check"></i><b>7.1.5</b> Training Data Error</a></li>
<li class="chapter" data-level="7.1.6" data-path="predictive-modeling.html"><a href="predictive-modeling.html#graph-of-rmspe"><i class="fa fa-check"></i><b>7.1.6</b> Graph of RMSPE</a></li>
<li class="chapter" data-level="7.1.7" data-path="predictive-modeling.html"><a href="predictive-modeling.html#best-model"><i class="fa fa-check"></i><b>7.1.7</b> Best Model</a></li>
<li class="chapter" data-level="7.1.8" data-path="predictive-modeling.html"><a href="predictive-modeling.html#model-complexity-training-error-and-test-error"><i class="fa fa-check"></i><b>7.1.8</b> Model Complexity, Training Error, and Test Error</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="predictive-modeling.html"><a href="predictive-modeling.html#variance-bias-tradeoff"><i class="fa fa-check"></i><b>7.2</b> Variance-Bias Tradeoff</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="predictive-modeling.html"><a href="predictive-modeling.html#what-contributes-to-prediction-error"><i class="fa fa-check"></i><b>7.2.1</b> What Contributes to Prediction Error?</a></li>
<li class="chapter" data-level="7.2.2" data-path="predictive-modeling.html"><a href="predictive-modeling.html#variance-and-bias"><i class="fa fa-check"></i><b>7.2.2</b> Variance and Bias</a></li>
<li class="chapter" data-level="7.2.3" data-path="predictive-modeling.html"><a href="predictive-modeling.html#variance-bias-tradeoff-1"><i class="fa fa-check"></i><b>7.2.3</b> Variance-Bias Tradeoff</a></li>
<li class="chapter" data-level="7.2.4" data-path="predictive-modeling.html"><a href="predictive-modeling.html#modeling-for-prediction-1"><i class="fa fa-check"></i><b>7.2.4</b> Modeling for Prediction</a></li>
<li class="chapter" data-level="7.2.5" data-path="predictive-modeling.html"><a href="predictive-modeling.html#cross-validation"><i class="fa fa-check"></i><b>7.2.5</b> Cross-Validation</a></li>
<li class="chapter" data-level="7.2.6" data-path="predictive-modeling.html"><a href="predictive-modeling.html#cross-validation-illustration"><i class="fa fa-check"></i><b>7.2.6</b> Cross-Validation Illustration</a></li>
<li class="chapter" data-level="7.2.7" data-path="predictive-modeling.html"><a href="predictive-modeling.html#cv-in-r"><i class="fa fa-check"></i><b>7.2.7</b> CV in R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="classification-and-logistic-regression.html"><a href="classification-and-logistic-regression.html"><i class="fa fa-check"></i><b>8</b> Classification and Logistic Regression</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Stat 255: Statistics for Data Science Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="normal-error-regression-model" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Normal Error Regression Model<a href="normal-error-regression-model.html#normal-error-regression-model" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><strong>Learning Outcomes:</strong></p>
<ol style="list-style-type: decimal">
<li><p>Explain when it is appropriate to use “theory-based” standard error formulas.<br />
</p></li>
<li><p>Interpret estimates, standard errors, test statistics, and p-values resulting from linear model output in R.<br />
</p></li>
<li><p>List the assumptions made in the normal error regression model.<br />
</p></li>
<li><p>Calculate p-values corresponding to t-statistics and F-statistics in R.<br />
</p></li>
<li><p>Interpret confidence intervals for an expected response, and prediction intervals, and distinguish between these two types of intervals.<br />
</p></li>
<li><p>Assess the whether linear model assumptions are reasonably satisfied, using residual plots, histograms, and normal QQ plots.<br />
</p></li>
<li><p>Explain when we should or should not expect p-values and confidence intervals obtained via “theory-based” approaches to agree with those obtained via simulation.</p></li>
<li><p>Identify situations where a log transformation of the response variable is appropriate.<br />
</p></li>
<li><p>Calculate predicted values for models involving a log transformation of the response variable.<br />
</p></li>
<li><p>Interpret regression coefficients in models involving a log transformation of the response variable.<br />
</p></li>
<li><p>Explain the regression effect.</p></li>
</ol>
<div id="the-normal-error-regression-model" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> The Normal Error Regression Model<a href="normal-error-regression-model.html#the-normal-error-regression-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>You’ve probably noticed that many (though not all) of the distributions of statistics associated with permutation-based hypothesis tests in Chapter 3 and bootstrap confidence intervals in Chapter 4 were symmetric and bell-shaped in nature. We also saw in Section 4.4 that certain statistics, such as differences in means, and regression coefficients have known standard error formulas, allowing us to approximate their standard errors without performing simulation.</p>
<p>When working with statistics that have symmetric and bell-shaped distributions and know standard error formulas, it is possible to use well-known probability facts to obtain confidence intervals and perform hypothesis tests without actually performing the simulation seen in Chapters 3 and 4. In order to be able to use these facts, however, we must know that the sampling distribution of our statistic is in fact symmetric and bell-shaped. One way to know that would be to actually perform the simulations and check the shape of the distribution. This, of course, would defeat the purpose of bypassing the simulations, however.</p>
<p>In this chapter, we’ll examine ways to check whether a statistic such as a mean, regression slope, or expected response will follow a symmetric and bell-shaped sampling distribution, without actually having to perform a simulation. For situations where the statistic does follow such a distribution, we’ll examine methods for obtaining confidence intervals and p-values, based on probability theory, rather than simulation.</p>
<div id="example-ice-cream-dispenser" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Example: Ice Cream dispenser<a href="normal-error-regression-model.html#example-ice-cream-dispenser" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="Ice_Cream.png" width="50%" /></p>
<p>Suppose an ice cream machine is manufactured to dispense 2 oz. of ice cream per second, on average. If 15 people used the ice cream machine, holding the dispenser for different amounts of time, and each person got exactly 2 oz. per second, the relationship between time holding the dispenser and amount dispensed would look like this:</p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-354-1.png" width="672" /></p>
<p>In reality, however, the actual amount dispensed each time it is used will vary due to unknown factors like:</p>
<ul>
<li>force applied to dispenser<br />
</li>
<li>temperature<br />
</li>
<li>build-up of ice cream<br />
</li>
<li>other unknown factors</li>
</ul>
<p>Thus, if 15 real people held the dispenser and recorded the amount of ice cream they got, the scatter plot we would see would look something like this:</p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-355-1.png" width="672" /></p>
</div>
<div id="signal-and-noise" class="section level3 hasAnchor" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Signal and Noise<a href="normal-error-regression-model.html#signal-and-noise" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can think of the amount of ice cream a person receives as being a result of two separate components, often referred to as <strong>signal</strong> and <strong>noise</strong>.</p>
<p>Signal represents the average amount of ice cream a person is expected to receive based on the amount of time holding the dispenser. In this case, signal is given by the function <span class="math inline">\(\text{Expected Amount} = 2\times\text{Time}\)</span>. Everyone who holds the dispenser for <span class="math inline">\(t\)</span> seconds is expected to receive <span class="math inline">\(2t\)</span> ounces of ice cream.</p>
<p>Noise represents how much each person’s actual amount of ice cream deviates from their expected amount. For example, a person who holds the dispenser for 1.5 seconds and receives 3.58 oz. of ice cream will have received 0.58 ounces more than expected due to noise (i.e. factors beyond time holding the dispenser).</p>
<p>In a statistical model, we assume that the response value of a response variable we observe is the sum of the signal, or expected response, which is a function of the explanatory variables in the model, and noise, which results from deviations due to factos beyond those accounted for in the model.</p>
</div>
<div id="normal-distribution" class="section level3 hasAnchor" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> Normal Distribution<a href="normal-error-regression-model.html#normal-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>It is common to model noise using a symmetric, bell-shaped distribution, known as a <strong>normal distribution</strong>.</p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-356-1.png" width="576" /></p>
<p>We can think of the error term as a random draw from somewhere in the area below the bell-curve. For example, in the above illustration, most of the area under the curve lies between <span class="math inline">\(-1\leq x\leq 1\)</span>. If this curve represented the noise term in the ice cream example, it would mean that most people’s actual amount of ice cream dispensed would be within <span class="math inline">\(\pm 1\)</span> ounce of their expected amount (or signal). Notice that the normal distribution is centered at 0, indicating that on average, a person would be expected to get an amount exactly equal to their signal, but that they might deviate above or below this amount by unexplained factors, which can be modeled by random chance.</p>
<p>A normal distribution is defined by two parameters:<br />
- <span class="math inline">\(\mu\)</span> representing the center of the distribution<br />
- <span class="math inline">\(\sigma\)</span> representing the standard deviation</p>
<p>This distribution is denoted <span class="math inline">\(\mathcal{N}(\mu, \sigma)\)</span>.</p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-358-1.png" width="576" /></p>
<p>When the standard deviation is small, such as for the blue curve, noise tends to be close to 0, meaning the observed values will be close to their expectation. On the other hand, the green curve, which has higher standard deviation, would often produce noise values as extreme as <span class="math inline">\(\pm 2\)</span> or more.</p>
<p>Note that the square of the standard deviation <span class="math inline">\(\sigma^2\)</span> is called the variance. Some books denote the normal distribution as <span class="math inline">\(\mathcal{N}(\mu, \sigma^2)\)</span>, instead of <span class="math inline">\(\mathcal{N}(\mu,\sigma)\)</span>. We will use the <span class="math inline">\(\mathcal{N}(\mu,\sigma)\)</span> here, which is consistent with R.</p>
</div>
<div id="signal-and-noise-in-icecream-example" class="section level3 hasAnchor" number="5.1.4">
<h3><span class="header-section-number">5.1.4</span> Signal and Noise in Icecream Example<a href="normal-error-regression-model.html#signal-and-noise-in-icecream-example" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In this example, we’ll simulate the amount of ice cream dispensed for each person by adding a random number from a normal distribution with mean 0 and standard deviation 0.5 to the expected amount dispensed, which is given by <span class="math inline">\(2x\)</span>, where <span class="math inline">\(x\)</span> represents time pressing the dispenser. We’ll let <span class="math inline">\(\epsilon_i\)</span> represent the random noise term for the <span class="math inline">\(i\)</span> person.</p>
<p>Thus, amount dispensed (<span class="math inline">\(Y_i\)</span>) for person <span class="math inline">\(i\)</span> is given by</p>
<p><span class="math display">\[Y_i = 2x_i+\epsilon_i, \text{ where } \epsilon_i\sim\mathcal{N}(0, 0.5)
\]</span></p>
<p>We simulate the amount dispensed for a sample of 15 people below.</p>
<div class="sourceCode" id="cb493"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb493-1"><a href="normal-error-regression-model.html#cb493-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10082020</span>)</span>
<span id="cb493-2"><a href="normal-error-regression-model.html#cb493-2" aria-hidden="true" tabindex="-1"></a><span class="co"># set times </span></span>
<span id="cb493-3"><a href="normal-error-regression-model.html#cb493-3" aria-hidden="true" tabindex="-1"></a>time <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="fl">1.2</span>, <span class="fl">1.5</span>, <span class="fl">1.8</span>, <span class="fl">2.1</span>, <span class="fl">2.1</span>, <span class="fl">2.3</span>, <span class="fl">2.5</span>, <span class="fl">2.6</span>, <span class="fl">2.8</span>, <span class="fl">2.9</span>, <span class="fl">2.9</span>, <span class="fl">3.1</span>, <span class="fl">3.2</span>, <span class="fl">3.6</span>)</span>
<span id="cb493-4"><a href="normal-error-regression-model.html#cb493-4" aria-hidden="true" tabindex="-1"></a>expected <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">*</span>time  <span class="co"># expected amount</span></span>
<span id="cb493-5"><a href="normal-error-regression-model.html#cb493-5" aria-hidden="true" tabindex="-1"></a>noise <span class="ot">&lt;-</span><span class="fu">rnorm</span>(<span class="dv">15</span>, <span class="dv">0</span>, <span class="fl">0.5</span>) <span class="sc">%&gt;%</span> <span class="fu">round</span>(<span class="dv">2</span>)  <span class="co">#generate noise from normal distribution</span></span>
<span id="cb493-6"><a href="normal-error-regression-model.html#cb493-6" aria-hidden="true" tabindex="-1"></a>amount <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">*</span>time <span class="sc">+</span> noise  <span class="co"># calculate observed amounts</span></span>
<span id="cb493-7"><a href="normal-error-regression-model.html#cb493-7" aria-hidden="true" tabindex="-1"></a>Icecream <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(time, signal, noise, amount) <span class="co"># set up data table</span></span>
<span id="cb493-8"><a href="normal-error-regression-model.html#cb493-8" aria-hidden="true" tabindex="-1"></a><span class="fu">kable</span>((Icecream)) <span class="co">#display table</span></span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">time</th>
<th align="right">signal</th>
<th align="right">noise</th>
<th align="right">amount</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1.0</td>
<td align="right">2.0</td>
<td align="right">0.23</td>
<td align="right">2.23</td>
</tr>
<tr class="even">
<td align="right">1.2</td>
<td align="right">2.4</td>
<td align="right">-0.49</td>
<td align="right">1.91</td>
</tr>
<tr class="odd">
<td align="right">1.5</td>
<td align="right">3.0</td>
<td align="right">0.58</td>
<td align="right">3.58</td>
</tr>
<tr class="even">
<td align="right">1.8</td>
<td align="right">3.6</td>
<td align="right">-0.03</td>
<td align="right">3.57</td>
</tr>
<tr class="odd">
<td align="right">2.1</td>
<td align="right">4.2</td>
<td align="right">0.17</td>
<td align="right">4.37</td>
</tr>
<tr class="even">
<td align="right">2.1</td>
<td align="right">4.2</td>
<td align="right">-0.93</td>
<td align="right">3.27</td>
</tr>
<tr class="odd">
<td align="right">2.3</td>
<td align="right">4.6</td>
<td align="right">0.05</td>
<td align="right">4.65</td>
</tr>
<tr class="even">
<td align="right">2.5</td>
<td align="right">5.0</td>
<td align="right">-0.37</td>
<td align="right">4.63</td>
</tr>
<tr class="odd">
<td align="right">2.6</td>
<td align="right">5.2</td>
<td align="right">-0.46</td>
<td align="right">4.74</td>
</tr>
<tr class="even">
<td align="right">2.8</td>
<td align="right">5.6</td>
<td align="right">0.17</td>
<td align="right">5.77</td>
</tr>
<tr class="odd">
<td align="right">2.9</td>
<td align="right">5.8</td>
<td align="right">-0.59</td>
<td align="right">5.21</td>
</tr>
<tr class="even">
<td align="right">2.9</td>
<td align="right">5.8</td>
<td align="right">0.12</td>
<td align="right">5.92</td>
</tr>
<tr class="odd">
<td align="right">3.1</td>
<td align="right">6.2</td>
<td align="right">0.00</td>
<td align="right">6.20</td>
</tr>
<tr class="even">
<td align="right">3.2</td>
<td align="right">6.4</td>
<td align="right">0.67</td>
<td align="right">7.07</td>
</tr>
<tr class="odd">
<td align="right">3.6</td>
<td align="right">7.2</td>
<td align="right">0.05</td>
<td align="right">7.25</td>
</tr>
</tbody>
</table>
<p>The scatterplot displays the amount dispensed, compared to the time pressing the dispenser. The red line indicates the line <span class="math inline">\(y=2x\)</span>. If there was no random noise, then each person’s amount dispensed would lie exactly on this line.</p>
<div class="sourceCode" id="cb494"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb494-1"><a href="normal-error-regression-model.html#cb494-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>Icecream1, <span class="fu">aes</span>(<span class="at">x=</span>time, <span class="at">y=</span>amount)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Icecream Dispensed&quot;</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Time Pressing dispenser&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Amount Dispensed&quot;</span>) <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="at">slope=</span><span class="dv">2</span>, <span class="at">intercept=</span><span class="dv">0</span>, <span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">+</span> </span>
<span id="cb494-2"><a href="normal-error-regression-model.html#cb494-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="at">label=</span><span class="st">&quot;y=2x&quot;</span>, <span class="at">x=</span> <span class="fl">3.5</span>, <span class="at">y=</span><span class="fl">6.5</span>, <span class="at">size=</span><span class="dv">10</span>, <span class="at">color=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-360-1.png" width="672" /></p>
<p>In a real situation, we would not see the signal and noise columns in the table or the red line on the graph. We would only see the time and amount, and points on the scatter plot. From these, we would need to estimate the location of the red line by fitting a least squares regression line to the data, as we’ve done before.</p>
<p>The blue line represents the location of the least squares regression line fit to the time and amounts observed.</p>
<div class="sourceCode" id="cb495"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb495-1"><a href="normal-error-regression-model.html#cb495-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>Icecream1, <span class="fu">aes</span>(<span class="at">x=</span>time, <span class="at">y=</span>amount)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Icecream Dispensed&quot;</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Time Pressing dispenser&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Amount Dispensed&quot;</span>) <span class="sc">+</span> <span class="fu">stat_smooth</span>(<span class="at">method=</span><span class="st">&quot;lm&quot;</span>, <span class="at">se=</span><span class="cn">FALSE</span>) <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="at">slope=</span><span class="dv">2</span>, <span class="at">intercept=</span><span class="dv">0</span>, <span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">+</span> </span>
<span id="cb495-2"><a href="normal-error-regression-model.html#cb495-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="at">label=</span><span class="st">&quot;y=2x&quot;</span>, <span class="at">x=</span> <span class="fl">3.5</span>, <span class="at">y=</span><span class="fl">6.5</span>, <span class="at">size=</span><span class="dv">10</span>, <span class="at">color=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-361-1.png" width="672" />
The blue line is close, but not identical to the red line, representing the true (usually unknown) signal.</p>
<p>The slope and intercept of the blue line are given by:</p>
<div class="sourceCode" id="cb496"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb496-1"><a href="normal-error-regression-model.html#cb496-1" aria-hidden="true" tabindex="-1"></a>IC_Model <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>Icecream1, <span class="fu">lm</span>(amount<span class="sc">~</span>time))</span>
<span id="cb496-2"><a href="normal-error-regression-model.html#cb496-2" aria-hidden="true" tabindex="-1"></a>IC_Model</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = lm(amount ~ time), data = Icecream1)
## 
## Coefficients:
## (Intercept)         time  
##     -0.1299       2.0312</code></pre>
<p>Notice that these estimates are close, but not identical to the intercept and slope of the red line, which are 0 and 2, respectively.</p>
<p>The equation of the red line is given by:</p>
<p><span class="math inline">\(Y_i = \beta_0 + \beta_1X_{i} + \epsilon_i\)</span>, where <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0,\sigma)\)</span>,</p>
<p>where <span class="math inline">\(Y_i\)</span> represents amount dispensed, and <span class="math inline">\(X_i\)</span> represents time. <span class="math inline">\(\beta_0, \beta_1,\)</span>, and <span class="math inline">\(\sigma\)</span> are the unknown model parameters associated with the ice cream machine’s process.</p>
<p>Using the values of <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> obtained by fitting a model to our observed data as estimates of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, our estimated regression equation is</p>
<p><span class="math display">\[Y_i = b_0 + b_1X_i + \epsilon_i = -0.1299087 + 2.0312489X_i + \epsilon_i
\]</span></p>
<p>where <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0,\sigma)\)</span>.</p>
<p>An estimate for <span class="math inline">\(\sigma\)</span> is given by</p>
<p><span class="math inline">\(s =\sqrt{\frac{\text{SSR}}{n-(p+1)}} = \sqrt{\frac{\displaystyle\sum_{i=1}^n(y_i-\hat{y}_i)^2}{(n-(p+1))}}\)</span>.</p>
<p>We calculate this estimate of <span class="math inline">\(\hat{\sigma}\)</span>, using R.</p>
<div class="sourceCode" id="cb498"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb498-1"><a href="normal-error-regression-model.html#cb498-1" aria-hidden="true" tabindex="-1"></a>s <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>(IC_Model<span class="sc">$</span>residuals<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>(<span class="dv">15-2</span>))</span>
<span id="cb498-2"><a href="normal-error-regression-model.html#cb498-2" aria-hidden="true" tabindex="-1"></a>s</span></code></pre></div>
<pre><code>## [1] 0.4527185</code></pre>
<p>The estimates of <span class="math inline">\(b_0 = -0.1299087\)</span>, <span class="math inline">\(b_1=2.0312489\)</span>, and <span class="math inline">\(s = 0.4527185\)</span> are resonably close estimates to the values <span class="math inline">\(\beta_0=0, \beta_1=2\)</span>, and <span class="math inline">\(\sigma = 0.5\)</span>, that we used to generate the data.</p>
<p>In a real situation, we’ll have only statistics <span class="math inline">\(b_0\)</span>, <span class="math inline">\(b_1\)</span>, and <span class="math inline">\(s\)</span>, and we’ll need to use them to draw conclusions about parameters <span class="math inline">\(\beta_0=0, \beta_1=2\)</span>, and <span class="math inline">\(\sigma = 0.5\)</span>.</p>
</div>
<div id="normal-error-regression-model-1" class="section level3 hasAnchor" number="5.1.5">
<h3><span class="header-section-number">5.1.5</span> Normal Error Regression Model<a href="normal-error-regression-model.html#normal-error-regression-model-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the ice cream example, the relationship between expected amount and time holding the dispenser was given by a linear equation involving a single numeric explanatory variable. We can generalize this to situations with multiple explanatory variables, which might be numeric or categorical.</p>
<p>Individual observations are then assumed to vary from their expectation in accordance with a normal distribution, representing random noise (or error).</p>
<p>The mathematical form of a normal error linear regression model is</p>
<p><span class="math inline">\(Y_i = \beta_0 + \beta_1X_{i1}+ \ldots + \beta_pX_{ip} + \epsilon_i\)</span>, with <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0,\sigma)\)</span>.</p>
<p>Note that in place of <span class="math inline">\(X_{ip}\)</span>, we could have indicators for categories, or functions of <span class="math inline">\(X_{ip}\)</span>, such as <span class="math inline">\(X_{ip}^2\)</span>, <span class="math inline">\(\text{log}(X_{ip})\)</span>, or <span class="math inline">\(\text{sin}(X_{ip})\)</span>.</p>
<ul>
<li><p>The quantities <span class="math inline">\(\beta_0, \beta_1, \ldots, \beta_p\)</span> are parameters, pertaining to the true but unknown data generating mechanism.</p></li>
<li><p>The estimates <span class="math inline">\(b_0, b_1, \ldots, b_p\)</span>, are statistics, calculated from our observed data.<br />
</p></li>
<li><p>We use confidence intervals and hypothesis tests to make statements about parameters, based on information provided by statistics.</p></li>
</ul>
</div>
<div id="examples-of-normal-error-regression-model" class="section level3 hasAnchor" number="5.1.6">
<h3><span class="header-section-number">5.1.6</span> Examples of Normal Error Regression Model<a href="normal-error-regression-model.html#examples-of-normal-error-regression-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can formulate all of the examples we’ve worked with so far in terms of the normal error regression model.</p>
<p>In the house price example, consider the following models:</p>
<p><strong>Model 1:</strong>
<span class="math inline">\(\text{Price}_i = \beta_0 + \beta_1\text{Sq.Ft.}_{i} + \epsilon_i\)</span>, where <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0,\sigma)\)</span>.
If we use this model, we’re saying that we believe the expected price of a house is a linear function of its size, and that for any given size, the distribution of actual prices are normally distributed around their expected value of <span class="math inline">\(\beta_0 + \beta_1\text{Sq.Ft.}_{i}\)</span>.</p>
<p><strong>Model 2:</strong></p>
<p><span class="math inline">\(\text{Price}_i = \beta_0 + \beta_2\text{Waterfront}_{i}+ \epsilon_i\)</span>, where <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0,\sigma)\)</span>.</p>
<p>If we use this model, we’re saying that we believe the expected price of a house depends only on whether or not it is on the waterfront, and that prices of both waterfront and non-waterfront houses follow normal distributions, though these distributions may have different means (<span class="math inline">\(\beta_0\)</span> for non-waterfront houses, and <span class="math inline">\(\beta_1\)</span> for waterfront houses).</p>
<p><strong>Model 3:</strong></p>
<p><span class="math inline">\(\text{Price}_i = \beta_0 + \beta_1\text{Sq.Ft.}_{i}+ \beta_2\text{Waterfront}_{i}+ \beta_3\times\text{Sq.Ft.}_i\times\text{Waterfront}_{i} + \epsilon_i\)</span>, where <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0,\sigma)\)</span>.</p>
<p>and</p>
<p><strong>Model 4:</strong>
<span class="math inline">\(\text{Price}_i = \beta_0 + \beta_1\text{Sq.Ft.}_{i}+ \beta_2\text{Waterfront}_{i}+ \beta_3\times\text{Sq.Ft.}_i\times\text{Waterfront}_{i} + \epsilon_i\)</span>, where <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0,\sigma)\)</span>.</p>
<p>Both models assume that actual prices of houses with the same size and waterfront status are normally distributed, and that the mean of the normal distribution is a linear function of its size. Model 3 allows for the intercept of the lines to differ between waterfront and non-waterfront houses, while Model 4 allows both the intercept and slope to differ.</p>
</div>
<div id="implications-of-normal-error-regression-model" class="section level3 hasAnchor" number="5.1.7">
<h3><span class="header-section-number">5.1.7</span> Implications of Normal Error Regression Model<a href="normal-error-regression-model.html#implications-of-normal-error-regression-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If we really believe that data come about as the normal error regression model describes, then probability theory tells us that regression coefficients <span class="math inline">\(b_j\)</span>’s, representing differences between categories for categorical variables and rates of change for quantitative variables, follow symmetric and bell-shaped distributions. We can use this fact, along with the standard error formulas in Section 4.4 to create confidence intervals and perform hypothesis tests, without needing to perform simulation. This is, in fact what R does in it’s model summary output.</p>
<p>These methods are only valid, however, if data can reasonably be thought of as having come the normal error regression model process. Thus, if we don’t believe that our observed data can be reasonably thought of terms representing underlying signal as a linear function of explanatory variables, and a normally distributed random error (or noise) term, then the confidence intervals and p-values produced by R, and other places that rely on probability-based methods will not be reliable.</p>
</div>
<div id="philosophical-question" class="section level3 hasAnchor" number="5.1.8">
<h3><span class="header-section-number">5.1.8</span> Philosophical Question<a href="normal-error-regression-model.html#philosophical-question" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We close the section with a philosophical question:</p>
<p>Do data really come about from processes like the normal error regression model? That is, do you think it is reasonable to believe that data we see in the real world (perhaps the amount of ice cream dispensed by an ice cream machine) is a combination of some true, but unknown equation involving the explanatory and response variables, and some unexplained noise, coming from a normal distribution?</p>
<p>We won’t attempt to answer that question here, but it is worth thinking about. After all, it is an assumption on which many frequently employed methods of statistical inference depends.</p>
</div>
</div>
<div id="inference-in-normal-error-regression-model" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Inference in Normal Error Regression Model<a href="normal-error-regression-model.html#inference-in-normal-error-regression-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>When data can reasonably be assumed to have come from a process consistent with the normal error regression model, we can perform hypothesis tests and make confidence intervals for regression coefficients <span class="math inline">\(\beta_j\)</span>’s, (which represent slopes or differences in means), using probability-based methods rather than simulation. This is done in the R output for the <code>lm</code> <code>summary</code> command.</p>
<div id="lm-summary-output" class="section level3 hasAnchor" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> <code>lm</code> <code>summary</code> Output<a href="normal-error-regression-model.html#lm-summary-output" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <code>summary</code> command for a linear model in R displays a table including 4 columns.</p>
<p><strong>Linear Model <code>summary()</code> Output in R</strong></p>
<ul>
<li><p><strong>Estimate</strong> gives the least-squares estimates <span class="math inline">\(b_0, b_1, \ldots, b_p\)</span></p></li>
<li><p><strong>Standard Error</strong> gives estimates of the standard deviation in the sampling distribution for estimate. (i.e. how much uncertainty is there about the estimate?) These are computed using the formulas in Section 4.4.</p></li>
<li><p><strong>t value</strong> is the estimate divided by its standard error.</p></li>
<li><p><strong>Pr(&gt;|t|)</strong> is a p-value for the hypothesis test associated with the null hypothesis <span class="math inline">\(\beta_j = 0\)</span>, where <span class="math inline">\(\beta_j\)</span> is the regression coefficient pertaining to the given line. Note that <span class="math inline">\(\beta_j\)</span> is the unknown population parameter estimated by <span class="math inline">\(b_j\)</span>.</p></li>
<li><p>The <strong>Residual Standard Error</strong> is <span class="math inline">\(s =\sqrt{\frac{\text{SSR}}{n-(p+1)}} = \sqrt{\frac{\displaystyle\sum_{i=1}^n(y_i-\hat{y}_i)^2}{(n-(p+1))}}\)</span>. This is an estimate of <span class="math inline">\(\sigma\)</span>, which represents the standard deviation in the distribution of the response variable for given value(s) or category(ies) of explanatory variable(s).</p></li>
<li><p>The <strong>degrees of freedom</strong> are <span class="math inline">\(n-(p+1)\)</span>.</p></li>
<li><p>The <strong>Multiple R-Squared</strong> value is the <span class="math inline">\(R^2\)</span> value seen in Chapter 2. <span class="math inline">\(R^2 = \frac{\text{SST} -\text{SSR}}{\text{SST}} = \frac{\displaystyle\sum_{i=1}^n(y_i-\hat{y}_i)^2}{\displaystyle\sum_{i=1}^n(y_i-\bar{y}_i)^2}\)</span></p></li>
<li><p>We know that <span class="math inline">\(R^2\)</span> can never decrease when additional variables are added to a model. The <strong>Adjusted-R^2</strong> value is an alternate version of <span class="math inline">\(R^2\)</span> that is designed to penalize adding variables that do little to explain variation in the response. Adjusted <span class="math inline">\(R^2\)</span> can decrease as additional variables are added to a model. We’ll learn more about adjusted <span class="math inline">\(R^2\)</span> in Chapter 7.</p></li>
<li><p>The F-statistic on the bottom line of the R-output corresponds to an F-test of the given model against a reduced model that include no explanatory variables. The p-value on this line is associated with the test of the null hypothesis that there is no relationship between the response variable and any of the explanatory variables. Since SSR for this reduced model is equal to SST, the F-statistic calculation simplifies to:</p></li>
</ul>
<p><span class="math display">\[
F=\frac{\frac{SST - SSR}{p}}{\frac{SSR}{n-(p+1)}}
\]</span></p>
<p>The degrees of freedom associated with the F-statistic are given by <span class="math inline">\(p\)</span> and <span class="math inline">\((n-(p+1))\)</span>.</p>
<p><strong>Example:</strong> Northern vs Southern Florida Lakes</p>
<p>Recall our linear model for mercury levels of lakes in Northern Florida, compared to Southern Florida.</p>
<p>The equation of the model is:</p>
<p><span class="math display">\[
\text{Mercury} = \beta_0+\beta_1\times\text{South} + \epsilon_i, \text{where } \epsilon_i\sim\mathcal{N}(0, \sigma)
\]</span></p>
<p>We fit the model in R and display its summary output below.</p>
<div class="sourceCode" id="cb500"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb500-1"><a href="normal-error-regression-model.html#cb500-1" aria-hidden="true" tabindex="-1"></a>Lakes_M <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>FloridaLakes, Mercury<span class="sc">~</span>Location)</span>
<span id="cb500-2"><a href="normal-error-regression-model.html#cb500-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Lakes_M)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Mercury ~ Location, data = FloridaLakes)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.65650 -0.23455 -0.08455  0.24350  0.67545 
## 
## Coefficients:
##             Estimate Std. Error t value       Pr(&gt;|t|)    
## (Intercept)  0.42455    0.05519   7.692 0.000000000441 ***
## LocationS    0.27195    0.08985   3.027        0.00387 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.3171 on 51 degrees of freedom
## Multiple R-squared:  0.1523, Adjusted R-squared:  0.1357 
## F-statistic: 9.162 on 1 and 51 DF,  p-value: 0.003868</code></pre>
<p>The estimated regression equation is</p>
<p><span class="math display">\[
\text{Mercury} = 0.42455+0.27195\times\text{South}, \text{where } \epsilon_i\sim\mathcal{N}(0, \sigma)
\]</span></p>
<ul>
<li>SSR is:</li>
</ul>
<div class="sourceCode" id="cb502"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb502-1"><a href="normal-error-regression-model.html#cb502-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(Lakes_M<span class="sc">$</span>residuals<span class="sc">^</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 5.126873</code></pre>
<ul>
<li>SST is:</li>
</ul>
<div class="sourceCode" id="cb504"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb504-1"><a href="normal-error-regression-model.html#cb504-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>((FloridaLakes<span class="sc">$</span>Mercury <span class="sc">-</span> <span class="fu">mean</span>(FloridaLakes<span class="sc">$</span>Mercury))<span class="sc">^</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 6.047875</code></pre>
<ul>
<li>The residual standard error <span class="math inline">\(s\)</span> is our estimate of <span class="math inline">\(\sigma\)</span>, the standard deviation among lakes in the same location (either Northern or Southern Florida).</li>
</ul>
<p><span class="math display">\[
s =\sqrt{\frac{\text{SSR}}{n-(p+1)}} = \sqrt{\frac{\text{SSR}}{n-(p+1)}} = \sqrt{\frac{5.126873}{53-(1+1)}}=0.3171
\]</span></p>
<p>The degrees of freedom associated with this estimate is <span class="math inline">\(53-(1+1) = 51\)</span>.</p>
<ul>
<li>The Multiple R-Squared is:</li>
</ul>
<p><span class="math display">\[
R^2 = \frac{6.047875 - 5.126873}{6.047875} = 0.1523
\]</span></p>
<ul>
<li>The F-statistic is</li>
</ul>
<p><span class="math display">\[
F=\frac{\frac{SST - SSR}{p}}{\frac{SSR}{n-(p+1)}} = \frac{\frac{6.047875 - 5.126873}{1}}{\frac{5.126873}{53-(1+1)}} = 9.162
\]</span></p>
<p>This F-statistic is associated with 1 and 51 degrees of freedom.</p>
<p>Using formulas in Section 4.4.3, we obtain the standard error estimates for <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>, given in the second column of the table.</p>
<p><span class="math display">\[
SE(b_0) = SE(\bar{x}_N)=s\frac{1}{\sqrt{n_{\text{North}}}} = \frac{0.3171}{\sqrt{33}} =0.0552
\]</span></p>
<p><span class="math inline">\(SE(b_0)\)</span> represents the variability in average mercury levels between different samples of 33 Northern Florida lakes.</p>
<p><span class="math display">\[
SE(b_1) = SE(\bar{x}_{South}-\bar{x}_{North})=s\sqrt{\frac{1}{n_{North}}+\frac{1}{n_{South}}} = 0.3171\sqrt{\frac{1}{20} + \frac{1}{33}} =0.0898  
\]</span></p>
<p><span class="math inline">\(SE(b_1)\)</span> represents the variability in average difference in mercury levels between northern and southern lakes between different samples of 33 Northern Florida lakes and 20 Southern Florida lakes.</p>
<p>The last column, labeled “Pr(&gt;|t|)” is, in fact a p-value associated with associated with the null hypothesis that the regression parameter on that line is zero. (i.e. <span class="math inline">\(\beta_j=0\)</span>).</p>
<p><strong>Hypothesis Test for line (intercept)</strong></p>
<p><strong>Null Hypothesis:</strong> The average mercury level among all lakes in North Florida is 0 (<span class="math inline">\(\beta_0=0\)</span>).</p>
<p><strong>Alternative Hypothesis:</strong> The average mercury level among all lakes in Northern Florida is not 0 (<span class="math inline">\(\beta_0\neq 0\)</span>).</p>
<p>We already know the average mercury level among all lakes in North Florida is not 0, so this is a silly test.</p>
<p><strong>Hypothesis Test for line LocationS</strong></p>
<p><strong>Null Hypothesis:</strong> There is no difference in average mercury levels between Northern and Southern Florida (<span class="math inline">\(\beta_1=0\)</span>).</p>
<p><strong>Alternative Hypothesis:</strong> There is a difference in average mercury levels in Northern and Southern Florida (<span class="math inline">\(\beta_1\neq 0\)</span>).</p>
<p>This test is relevant to us.</p>
<p>R does not obtain these p-values through simulation, but rather by using the symmetric and bell-shaped t-distribution to approximate the distribution of these statistics. This is appropriate when the sampling distribution for our test statistic is reasonably symmetric and bell-shaped.</p>
<p>You’ve probably noticed that the sampling distributions in our permutation-based hypothesis tests, and our bootstrap distributions for regression coefficients have often been roughly symmetric and bell-shaped. When this happens, we can use a symmetric and bell-shaped distribution to model the distribution of a test statistic when the null hypothesis is true, bypassing the need to use simulation.</p>
<p>There is statistical theory which shows that if data really do come from the normal error regression model process, like the ice cream dispenser in the previous section, then the ratio of regression coefficients (means, differences in means, slopes) divided by their standard error, will follow a symmetric bell-shaped distribution called a t-distribution.</p>
</div>
<div id="t-distribution" class="section level3 hasAnchor" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> t-distribution<a href="normal-error-regression-model.html#t-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A t-distribution is a symmetric, bell-shaped curve, with thicker tails (hence more variability), than a <span class="math inline">\(\mathcal{N}(0,1)\)</span> distribution. The t-distribution depends on a parameter called <strong>degrees of freedom</strong>, which determines the thickness of the distribution’s tails.</p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-369-1.png" width="768" /></p>
<p>For data that come from a normal error regression model, we can use a t-distribution to approximate the sampling distribution used in our hypothesis tests, when the null hypothesis is assumed to be true.</p>
<p><strong>Important Fact:</strong> If <span class="math inline">\(Y_i = \beta_0 + \beta_1X_{i1}+ \ldots + \beta_pX_{ip} + \epsilon_i\)</span>, with <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0,\sigma)\)</span>, then</p>
<p><span class="math display">\[
t= \frac{{b_j}}{\text{SE}(b_j)}  
\]</span></p>
<p>follows a t-distribution.</p>
<p>The <span class="math inline">\(t=\frac{{b_j}}{\text{SE}(b_j)}\)</span> is called a <strong>t-statistic</strong>.</p>
<p>We’ll use this t-statistic as the test statistic in our hypothesis test.</p>
<p>The degrees of freedom are given by <span class="math inline">\(n-(p+1)\)</span>, where <span class="math inline">\(p\)</span> represents the number of terms in the model, not including the intercept.</p>
</div>
<div id="difference-in-means-example-1" class="section level3 hasAnchor" number="5.2.3">
<h3><span class="header-section-number">5.2.3</span> Difference in Means Example<a href="normal-error-regression-model.html#difference-in-means-example-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall the hypothesis test we performed to investigate whether there is a difference in average mercury level between lakes in Northern Florida and Southern Florida.</p>
<p><strong>Null Hypothesis:</strong> There is no difference in average mercury levels between Northern and Southern Florida (<span class="math inline">\(\beta_1=0\)</span>).</p>
<p><strong>Alternative Hypothesis:</strong> There is a difference in average mercury levels in Northern and Southern Florida (<span class="math inline">\(\beta_1\neq 0\)</span>).</p>
<p><strong>Test Statistic</strong>: <span class="math inline">\(t=\frac{{b_j}}{\text{SE}(b_j)} = \frac{0.27195}{0.08985} = 3.027\)</span></p>
<p><strong>Key Question:</strong> What is the probability of getting a t-statistic as extreme as 3.027 if <span class="math inline">\(\beta_1=0\)</span> (i.e. there is no difference in mercury levels between northern and southern lakes).</p>
<p>We plot the t-statistic of 3.027 that we observed in our data and observe where it lies on a t-distribution.</p>
<div class="sourceCode" id="cb506"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb506-1"><a href="normal-error-regression-model.html#cb506-1" aria-hidden="true" tabindex="-1"></a>ts<span class="ot">=</span><span class="fl">3.027</span></span>
<span id="cb506-2"><a href="normal-error-regression-model.html#cb506-2" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_dist</span>(<span class="st">&quot;t&quot;</span>, <span class="at">df=</span><span class="dv">51</span>, <span class="at">geom =</span> <span class="st">&quot;area&quot;</span>, <span class="at">fill =</span> <span class="sc">~</span> (<span class="fu">abs</span>(x)<span class="sc">&lt;</span> <span class="fu">abs</span>(ts)), <span class="at">show.legend=</span><span class="cn">FALSE</span>) <span class="sc">+</span> <span class="fu">geom_vline</span>(<span class="at">xintercept=</span><span class="fu">c</span>(ts, <span class="sc">-</span>ts), <span class="at">color=</span><span class="st">&quot;red&quot;</span>)  <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;t&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-370-1.png" width="768" /></p>
<div class="sourceCode" id="cb507"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb507-1"><a href="normal-error-regression-model.html#cb507-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">*</span><span class="fu">pt</span>(<span class="sc">-</span><span class="fu">abs</span>(ts), <span class="at">df=</span><span class="dv">51</span>)</span></code></pre></div>
<pre><code>## [1] 0.003866374</code></pre>
<p>The low p-value gives us strong evidence of a difference in average mercury levels between lakes in Northern and Southern Florida.</p>
<p>This is the p-value reported in R’s <code>lm</code> <code>summary()</code> output.</p>
<p>A t-statistic more extreme than <span class="math inline">\(\pm 2\)</span> will roughly correspond to a p-value less than 0.05.</p>
<p>*<strong>Comparison to Simulation</strong></p>
<p>Let’s compare these results to those given by the permutation test and bootstrap confidence interval.</p>
<p><strong>Permutation Test</strong></p>
<div class="sourceCode" id="cb509"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb509-1"><a href="normal-error-regression-model.html#cb509-1" aria-hidden="true" tabindex="-1"></a>NSLakes_SimulationResultsPlot</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-372-1.png" width="672" /></p>
<p>p-value:</p>
<div class="sourceCode" id="cb510"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb510-1"><a href="normal-error-regression-model.html#cb510-1" aria-hidden="true" tabindex="-1"></a>b1 <span class="ot">&lt;-</span> Lakes_M<span class="sc">$</span>coef[<span class="dv">2</span>] <span class="do">## record value of b1 from actual data</span></span>
<span id="cb510-2"><a href="normal-error-regression-model.html#cb510-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb510-3"><a href="normal-error-regression-model.html#cb510-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">abs</span>(NSLakes_SimulationResults<span class="sc">$</span>b1Sim) <span class="sc">&gt;</span> <span class="fu">abs</span>(b1))</span></code></pre></div>
<pre><code>## [1] 0.0039</code></pre>
</div>
<div id="simple-linear-regression-example" class="section level3 hasAnchor" number="5.2.4">
<h3><span class="header-section-number">5.2.4</span> Simple Linear Regression Example<a href="normal-error-regression-model.html#simple-linear-regression-example" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We examine the model summary output for the model predicting a lake’s mercury level, using pH as the explanatory variable.</p>
<div class="sourceCode" id="cb512"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb512-1"><a href="normal-error-regression-model.html#cb512-1" aria-hidden="true" tabindex="-1"></a>M_pH <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>FloridaLakes, Mercury<span class="sc">~</span>pH)</span>
<span id="cb512-2"><a href="normal-error-regression-model.html#cb512-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(M_pH)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Mercury ~ pH, data = FloridaLakes)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.48895 -0.19188 -0.05774  0.09456  0.71134 
## 
## Coefficients:
##             Estimate Std. Error t value       Pr(&gt;|t|)    
## (Intercept)  1.53092    0.20349   7.523 0.000000000814 ***
## pH          -0.15230    0.03031  -5.024 0.000006572811 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.2816 on 51 degrees of freedom
## Multiple R-squared:  0.3311, Adjusted R-squared:  0.318 
## F-statistic: 25.24 on 1 and 51 DF,  p-value: 0.000006573</code></pre>
<p>The estimated regression equation is</p>
<p><span class="math display">\[
\text{Mercury} = 1.53 - 0.15 \times\text{pH}, \text{where } \epsilon_i\sim\mathcal{N}(0, \sigma)
\]</span></p>
<ul>
<li>SSR is:</li>
</ul>
<div class="sourceCode" id="cb514"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb514-1"><a href="normal-error-regression-model.html#cb514-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(M_pH<span class="sc">$</span>residuals<span class="sc">^</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 4.045513</code></pre>
<ul>
<li>SST is:</li>
</ul>
<div class="sourceCode" id="cb516"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb516-1"><a href="normal-error-regression-model.html#cb516-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>((FloridaLakes<span class="sc">$</span>Mercury <span class="sc">-</span> <span class="fu">mean</span>(FloridaLakes<span class="sc">$</span>Mercury))<span class="sc">^</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 6.047875</code></pre>
<ul>
<li>The residual standard error <span class="math inline">\(s\)</span> is our estimate of <span class="math inline">\(\sigma\)</span>, the standard deviation among lakes with the same pH.</li>
</ul>
<p><span class="math display">\[
s =\sqrt{\frac{\text{SSR}}{n-(p+1)}} = \sqrt{\frac{\text{SSR}}{n-(p+1)}} = \sqrt{\frac{4.045513}{53-(1+1)}}=0.2816
\]</span></p>
<p>The degrees of freedom associated with this estimate is <span class="math inline">\(53-(1+1) = 51\)</span>.</p>
<ul>
<li>The Multiple R-Squared is:</li>
</ul>
<p><span class="math display">\[
R^2 = \frac{6.047875 - 4.045513}{6.047875} = 0.3311
\]</span></p>
<ul>
<li>The F-statistic is</li>
</ul>
<p><span class="math display">\[
F=\frac{\frac{SST - SSR}{p}}{\frac{SSR}{n-(p+1)}} = \frac{\frac{6.047875 - 4.045513}{1}}{\frac{4.045513}{53-(1+1)}} = 25.24
\]</span></p>
<p>This F-statistic is associated with 1 and 51 degrees of freedom.</p>
<p>Using formulas in Section 4.4.3, we obtain the standard error estimates for <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>, given in the second column of the table.</p>
<p>To do this, we need to calculate <span class="math inline">\(\bar{x}\)</span> and <span class="math inline">\(\sum(x_i-\bar{x})^2\)</span>, where <span class="math inline">\(x\)</span> represents the explanatory variable, <span class="math inline">\(pH\)</span>.</p>
<div class="sourceCode" id="cb518"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb518-1"><a href="normal-error-regression-model.html#cb518-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(FloridaLakes<span class="sc">$</span>pH)</span></code></pre></div>
<pre><code>## [1] 6.590566</code></pre>
<div class="sourceCode" id="cb520"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb520-1"><a href="normal-error-regression-model.html#cb520-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>((FloridaLakes<span class="sc">$</span>pH<span class="sc">-</span><span class="fu">mean</span>(FloridaLakes<span class="sc">$</span>pH))<span class="sc">^</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 86.32528</code></pre>
<p><span class="math display">\[
SE(b_0)=s\sqrt{\frac{1}{n}+\frac{\bar{x}^2}{\sum(x_i-\bar{x})^2}} = 0.2816\sqrt{\frac{1}{53} + \frac{6.59^2}{86.32528} } = 0.2034
\]</span></p>
<p><span class="math inline">\(SE(b_0)\)</span> represents the variability in mercury levels among lakes with pH of 0 between different samples of size 53. Since we don’t have any lakes with pH of 0, this is not a meaningful calculation.</p>
<p><span class="math display">\[
SE(b_1)=\sqrt{\frac{s^2}{\sum(x_i-\bar{x})^2}}=\sqrt{\frac{0.2816^2}{86.32528}} = 0.0303
\]</span></p>
<p><span class="math inline">\(SE(b_1)\)</span> represents the variability in rate of change in mercury level for each additional one unit increase in pH, between different samples of size 53.
<strong>Hypothesis Test for Intercept Line</strong></p>
<p><strong>Null Hypothesis:</strong> The average mercury level among all Florida lakes with pH = 0 is 0. (<span class="math inline">\(\beta_0=0\)</span>).</p>
<p><strong>Alternative Hypothesis:</strong> The average mercury level among all Florida lakes with pH = 0 not 0. (<span class="math inline">\(\beta_0 \neq 0\)</span>).</p>
<p>Since there are no lakes with pH level 0, this is not a meaningful test.</p>
<p><strong>Hypothesis Test for pH Line</strong></p>
<p><strong>Null Hypothesis:</strong> There is no relationship between mercury and pH level among all Florida lakes. (<span class="math inline">\(\beta_1=0\)</span>).</p>
<p><strong>Alternative Hypothesis:</strong> There is a relationship between mercury and pH level among all Florida lakes. (<span class="math inline">\(\beta_1 \neq 0\)</span>).</p>
<p><strong>Test Statistic</strong>: <span class="math inline">\(t=\frac{{b_j}}{\text{SE}(b_j)} = \frac{-0.15230}{0.03031} = -5.024\)</span></p>
<div class="sourceCode" id="cb522"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb522-1"><a href="normal-error-regression-model.html#cb522-1" aria-hidden="true" tabindex="-1"></a>ts<span class="ot">=</span><span class="fl">5.024</span></span>
<span id="cb522-2"><a href="normal-error-regression-model.html#cb522-2" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_dist</span>(<span class="st">&quot;t&quot;</span>, <span class="at">df=</span><span class="dv">51</span>, <span class="at">geom =</span> <span class="st">&quot;area&quot;</span>, <span class="at">fill =</span> <span class="sc">~</span> (<span class="fu">abs</span>(x)<span class="sc">&lt;</span> <span class="fu">abs</span>(ts)), <span class="at">show.legend=</span><span class="cn">FALSE</span>) <span class="sc">+</span> <span class="fu">geom_vline</span>(<span class="at">xintercept=</span><span class="fu">c</span>(ts, <span class="sc">-</span>ts), <span class="at">color=</span><span class="st">&quot;red&quot;</span>)  <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;t&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-379-1.png" width="768" /></p>
<div class="sourceCode" id="cb523"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb523-1"><a href="normal-error-regression-model.html#cb523-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">*</span><span class="fu">pt</span>(<span class="sc">-</span><span class="fu">abs</span>(ts), <span class="at">df=</span><span class="dv">51</span>)</span></code></pre></div>
<pre><code>## [1] 0.000006578117</code></pre>
<p>The p-value is extremely small, just as the simulation-based p-value we saw in Chapter 3.</p>
</div>
<div id="multiple-regression-example" class="section level3 hasAnchor" number="5.2.5">
<h3><span class="header-section-number">5.2.5</span> Multiple Regression Example<a href="normal-error-regression-model.html#multiple-regression-example" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We perform hypothesis tests on a model predicting house price using square feet and waterfront status as explanatory variables.</p>
<div class="sourceCode" id="cb525"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb525-1"><a href="normal-error-regression-model.html#cb525-1" aria-hidden="true" tabindex="-1"></a>M_wf_sqft <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>Houses, price<span class="sc">~</span>sqft_living<span class="sc">+</span>waterfront)</span>
<span id="cb525-2"><a href="normal-error-regression-model.html#cb525-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(M_wf_sqft)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = price ~ sqft_living + waterfront, data = Houses)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1363.79  -251.55    59.28   177.58  1599.72 
## 
## Coefficients:
##                Estimate Std. Error t value             Pr(&gt;|t|)    
## (Intercept)   -407.6549    86.2868  -4.724        0.00000779668 ***
## sqft_living      0.4457     0.0353  12.626 &lt; 0.0000000000000002 ***
## waterfrontYes  814.3613   124.8546   6.522        0.00000000313 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 412.7 on 97 degrees of freedom
## Multiple R-squared:  0.7607, Adjusted R-squared:  0.7558 
## F-statistic: 154.2 on 2 and 97 DF,  p-value: &lt; 0.00000000000000022</code></pre>
<p>We won’t go through the standard error calculations here, though the details are given in the link provided in Section 4.4.</p>
<p><strong>Intercept Line:</strong></p>
<p><strong>Null Hypothesis</strong> The average price among all non-waterfront houses with 0 square feet is 0 dollars. (<span class="math inline">\(\beta_0=0\)</span>)</p>
<p>This is not a sensible hypothesis to test.</p>
<p><strong>sqft_living Line:</strong></p>
<p><strong>Null Hypothesis</strong> There is no relationship between price and square feet in a house, after accounting for waterfront status. (<span class="math inline">\(\beta_1=0\)</span>)</p>
<p>The large t-statistic (12.626) and small p-value provide strong evidence against this null hypothesis.</p>
<p>We know that a small p-value alone does not provide evidence of a relationship that is practically meaningful, but since our model estimates an expected 45 thousand dollar increase for each additional 100 square feet, this seems like a meaningful relationship.</p>
<p><strong>waterfrontYes Line:</strong></p>
<p><strong>Null Hypothesis</strong> On average, there is no difference between average price of waterfront and non-waterfront houses, assuming they are the same size. (<span class="math inline">\(\beta_2=0\)</span>)</p>
<p>The large t-statistic (6.522) and small p-value provide strong evidence against this null hypothesis. Waterfront houses are estimated to cost 814 thousand dollars more, on average, than non-waterfront houses of the same size.</p>
</div>
<div id="mr-with-interaction-example" class="section level3 hasAnchor" number="5.2.6">
<h3><span class="header-section-number">5.2.6</span> MR with Interaction Example<a href="normal-error-regression-model.html#mr-with-interaction-example" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb527"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb527-1"><a href="normal-error-regression-model.html#cb527-1" aria-hidden="true" tabindex="-1"></a>M_House_Int <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>Houses, price <span class="sc">~</span> sqft_living <span class="sc">*</span> waterfront)</span>
<span id="cb527-2"><a href="normal-error-regression-model.html#cb527-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(M_House_Int)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = price ~ sqft_living * waterfront, data = Houses)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1559.34  -114.93   -30.24   131.09  1266.58 
## 
## Coefficients:
##                             Estimate Std. Error t value         Pr(&gt;|t|)    
## (Intercept)                 67.39594   91.39267   0.737           0.4627    
## sqft_living                  0.21837    0.04035   5.412 0.00000045752269 ***
## waterfrontYes             -364.59498  180.75875  -2.017           0.0465 *  
## sqft_living:waterfrontYes    0.43267    0.05566   7.773 0.00000000000857 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 325 on 96 degrees of freedom
## Multiple R-squared:  0.8531, Adjusted R-squared:  0.8486 
## F-statistic: 185.9 on 3 and 96 DF,  p-value: &lt; 0.00000000000000022</code></pre>
<p><strong>Intercept Line:</strong></p>
<p><strong>Null Hypothesis</strong> The average price among all non-waterfront houses with 0 square feet is 0 dollars. (<span class="math inline">\(\beta_0=0\)</span>)</p>
<p>This is not a sensible hypothesis to test.</p>
<p><strong>sqft_living Line:</strong></p>
<p><strong>Null Hypothesis</strong> There is no relationship between price and square feet among non-waterfront houses. (<span class="math inline">\(\beta_1=0\)</span>)</p>
<p>The large t-statistic (5.412) and small p-value provide strong evidence against this null hypothesis.</p>
<p><strong>waterfrontYes Line:</strong></p>
<p><strong>Null Hypothesis</strong> On average, there is no difference between average price of waterfront and non-waterfront houses with 0 square feet. (<span class="math inline">\(\beta_2=0\)</span>)</p>
<p>This is not a sensible hypothesis to test.</p>
<p><strong>sqft_living:waterfrontYes</strong></p>
<p><strong>Null Hypothesis</strong>: There is no interaction between square feet and waterfront. (<span class="math inline">\(\beta_3=0\)</span>) (That is, the effect of size on price is the same for waterfront and non-waterfront houses).</p>
<p>The large t-statistic (7.773) and small p-value provide strong evidence against this null hypothesis. It appears there really is evidence of an interaction between price and waterfront status, as we previously suspected, based on graphical representation and background knowledge.</p>
<p>Note that if the interaction term had yielded a large p-value, indicating a lack of evidence of an interaction, we might have wanted to drop the interaction term from the model, in order to make the interpretations of the other estimates and hypothesis tests simpler.</p>
</div>
<div id="limitations" class="section level3 hasAnchor" number="5.2.7">
<h3><span class="header-section-number">5.2.7</span> Limitations<a href="normal-error-regression-model.html#limitations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We’ve seen that in situations where the sampling distribution for a regression coefficient <span class="math inline">\(b_j\)</span> is symmetric and bell-shaped, we can create confidence intervals and perform hypothesis tests using the t-distribution without performing permutation for hypothesis tests, or bootstrapping for confidence intervals.</p>
<p>There are, however, limitations to this approach, which underscore the importance of the simulation-based approaches seen in Chapters 3 and 4.</p>
<p>These include:</p>
<ol style="list-style-type: decimal">
<li><p>There are lots of statistics, like medians and standard deviations, that do not have known standard error formulas, and do not follow symmetric bell-shaped distributions. In more advanced and complicated models, it is common to encounter statistics of interest with unknown sampling distributions. In these cases, we can estimate p-values and build confidence intervals via simulation, even if we cannot identify the distribution by name.</p></li>
<li><p>Even for statistics with known standard error formulas, the t-test is only appropriate when the sampling distribution for <span class="math inline">\(b_j\)</span> is symmetric and bell-shaped. While there is probability theory that shows this will happen when the sample size is “large enough,” there is no set sample size that guarantees this. Datasets with heavier skewness in the response variable will require larger sample sizes than datasets with less skewness in the response.</p></li>
<li><p>The simulation-based approaches provide valuable insight to the logic behind hypothesis tests. When we permute values of an explanatory variable in a hypothesis test it is clear that we are simulating a situation where the null hypothesis is true. Likewise, when we simulate taking many samples in bootstrapping, it is clear that we are assessing the variability in a statistic across samples. Simply jumping to the t-based approximations of these distributions makes it easy to lose our sense of what they actually represent, and thus increases the likelihood of interpreting them incorrectly.</p></li>
</ol>
<p>In fact prominent statistician R.A. Fisher wrote of simulation-based methods in 1936:</p>
<p><em>``Actually, the statistician does not carry out this very simple and very tedious process, but his conclusions have no justification beyond the fact that they agree with those which could have been arrived at by this elementary method.”</em></p>
<p>Fisher’s comment emphasizes the fact that probability-based tests, like the t-test are simply approximations to what we would obtain via simulation-based approaches, which were not possible in his day, but are now.</p>
<p>Proponents of simulation-based inference include Tim Hesterberg, Senior Statistician at Instacart, and former Senior Statistician at Google, which heavily used simulation-based tests associated with computer experiments associated with their search settings. Hesterberg wrote a <a href="https://browse.arxiv.org/pdf/1411.5279.pdf">2015 paper</a>, arguing for the use and teaching of simulation-based techniques.</p>
<p>We will move forward by using probability-based inference where appropriate, while understanding that we are merely approximating what we would obtain via simulation. Meanwhile, we’ll continue to employ simulation-based approaches where probability-based techniques are inappropriate or unavailable.</p>
</div>
</div>
<div id="f-distributions" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> F-Distributions<a href="normal-error-regression-model.html#f-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Just as we’ve seen that the ratio of a regression statistic to its standard error follows a t-distribution when can be thought of as having come from a process that can be approximated with the normal error regression model, F-statistics also follow a known probability distribution under this assumption.</p>
<div id="f-distribution" class="section level3 hasAnchor" number="5.3.1">
<h3><span class="header-section-number">5.3.1</span> F-Distribution<a href="normal-error-regression-model.html#f-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>An <strong>F distribution</strong> is a right-skewed distribution. It is defined by two parameters, <span class="math inline">\(\nu_1, \nu_2\)</span>, called numerator and denominator degrees of freedom.</p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-383-1.png" width="960" /></p>
<p><strong>Important Fact:</strong></p>
<p>If <span class="math inline">\(Y_i = \beta_0 + \beta_1X_{i1} + \beta_2{X_i2} + \ldots + \beta_qX_{iq} + \epsilon_i\)</span>, with <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0,\sigma)\)</span>,</p>
<p>and <span class="math inline">\(Y_i = \beta_0 + \beta_1X_{i1} + \beta_2{X_i2} + \ldots + \beta_qX_{iq} + \beta_{q+1}X_{i{q+1}} \ldots + \beta_pX_{ip}+ \epsilon_i\)</span>, is another proposed model, then</p>
<p><span class="math display">\[
F=\frac{\frac{\text{Unexplained Variability in Reduced Model}-\text{Unexplained Variability in Full Model}}{p-q}}{\frac{\text{Unexplained Variability in Full Model}}{n-(p+1)}}
\]</span></p>
<p>follows an F-distribution.</p>
<p>The numerator and denominator degrees of freedom are given by <span class="math inline">\(p-q\)</span> and <span class="math inline">\(n-(p+1)\)</span>, respectively. These are the same values we divided by when computing the F-statistic.</p>
</div>
<div id="house-condition-example" class="section level3 hasAnchor" number="5.3.2">
<h3><span class="header-section-number">5.3.2</span> House Condition Example<a href="normal-error-regression-model.html#house-condition-example" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall our F-statistic for comparing prices of houses in either very good, good, or average condition, calculated in Section 2.5.3 and the simulation-based F-test associated with this statistic that we performed in Section 3.2.5.</p>
<p><strong>Null Hypothesis:</strong> There is no difference in average prices between houses of the three different conditions, among all houses in King County, WA.</p>
<p><strong>Alternative Hypothesis:</strong> There is a difference in average prices between houses of the three different conditions, among all houses in King County, WA.</p>
<p>Reduced Model: <span class="math inline">\(\text{Price}= \beta_0 + \epsilon_i , \text{ where } \epsilon_i\sim\mathcal{N}(0, \sigma)\)</span></p>
<p>Full Model: <span class="math inline">\(\text{Price}= \beta_0+ \beta_1 \times\text{good condition}+ \beta_2\times\text{very good condition} + \epsilon_i , \text{ where } \epsilon_i\sim\mathcal{N}(0, \sigma)\)</span></p>
<p><span class="math display">\[
\begin{aligned}
F &amp;= \frac{\frac{\text{SSR}_{\text{Reduced}}-\text{SSR}_{\text{Full}}}{p-q}}{\frac{\text{SSR}_{\text{Full}}}{n-(p+1)}} \\
&amp;=\frac{\frac{69,045,634-68,195,387}{2-0}}{\frac{68,195,387}{100-(2+1)}} \\
\end{aligned}
\]</span></p>
<div class="sourceCode" id="cb529"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb529-1"><a href="normal-error-regression-model.html#cb529-1" aria-hidden="true" tabindex="-1"></a>((SST <span class="sc">-</span> SSR_cond)<span class="sc">/</span>(<span class="dv">2-0</span>))<span class="sc">/</span>(SSR_cond<span class="sc">/</span>(<span class="dv">100</span><span class="sc">-</span>(<span class="dv">2</span><span class="sc">+</span><span class="dv">1</span>)))</span></code></pre></div>
<pre><code>## [1] 0.6046888</code></pre>
<p>The results of the simulation-based hypothesis test are shown below.</p>
<div class="sourceCode" id="cb531"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb531-1"><a href="normal-error-regression-model.html#cb531-1" aria-hidden="true" tabindex="-1"></a>House_Cond_SimulationResults_Plot</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-385-1.png" width="672" /></p>
<p><strong>simulation-based p-value:</strong></p>
<div class="sourceCode" id="cb532"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb532-1"><a href="normal-error-regression-model.html#cb532-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(FSim <span class="sc">&gt;</span> Fstat)</span></code></pre></div>
<pre><code>## [1] 0.5568</code></pre>
<p>Now, we calculate the p-value using the probability-based F-distribution.</p>
<div class="sourceCode" id="cb534"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb534-1"><a href="normal-error-regression-model.html#cb534-1" aria-hidden="true" tabindex="-1"></a>ts<span class="ot">=</span><span class="fl">0.605</span></span>
<span id="cb534-2"><a href="normal-error-regression-model.html#cb534-2" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_dist</span>(<span class="st">&quot;f&quot;</span>, <span class="at">df1=</span><span class="dv">2</span>, <span class="at">df2=</span><span class="dv">97</span>, <span class="at">geom =</span> <span class="st">&quot;area&quot;</span>, <span class="at">fill =</span> <span class="sc">~</span> (<span class="fu">abs</span>(x)<span class="sc">&lt;</span> <span class="fu">abs</span>(ts)), <span class="at">show.legend=</span><span class="cn">FALSE</span>) <span class="sc">+</span> <span class="fu">geom_vline</span>(<span class="at">xintercept=</span><span class="fu">c</span>(ts), <span class="at">color=</span><span class="st">&quot;red&quot;</span>)  <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;F&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-387-1.png" width="768" /></p>
<p><strong>p-value:</strong></p>
<div class="sourceCode" id="cb535"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb535-1"><a href="normal-error-regression-model.html#cb535-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span><span class="fu">pf</span>(ts, <span class="at">df1=</span><span class="dv">2</span>, <span class="at">df2=</span><span class="dv">97</span>)</span></code></pre></div>
<pre><code>## [1] 0.5481219</code></pre>
<p>The p-value we obtained is very similar to the one we obtained using the simulation-based test.</p>
<p>We can obtain this p-value directly using the <code>anova</code> command.</p>
<div class="sourceCode" id="cb537"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb537-1"><a href="normal-error-regression-model.html#cb537-1" aria-hidden="true" tabindex="-1"></a>M_cond <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>Houses, price <span class="sc">~</span> condition)</span>
<span id="cb537-2"><a href="normal-error-regression-model.html#cb537-2" aria-hidden="true" tabindex="-1"></a>M0 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>Houses, price <span class="sc">~</span> <span class="dv">1</span>)</span>
<span id="cb537-3"><a href="normal-error-regression-model.html#cb537-3" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(M0, M_cond)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: price ~ 1
## Model 2: price ~ condition
##   Res.Df      RSS Df Sum of Sq      F Pr(&gt;F)
## 1     99 69045634                           
## 2     97 68195387  2    850247 0.6047 0.5483</code></pre>
</div>
<div id="interaction-example" class="section level3 hasAnchor" number="5.3.3">
<h3><span class="header-section-number">5.3.3</span> Interaction Example<a href="normal-error-regression-model.html#interaction-example" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can also use an F-test to compare a model predicting house prices with an interaction term to one without one.</p>
<p>Reduced Model: <span class="math inline">\(\text{Price}= \beta_0+ \beta_1 \times\text{sqft_living} + \beta_2\times\text{Waterfront} + \epsilon_i , \text{ where } \epsilon_i\sim\mathcal{N}(0, \sigma)\)</span></p>
<p>Full Model: <span class="math inline">\(\text{Price}= \beta_0+ \beta_1 \times\text{sqft_living}+ \beta_2\times\text{Waterfront} + \beta_3\times\text{sqft_living}\times\text{Waterfront} + \epsilon_i , \text{ where } \epsilon_i\sim\mathcal{N}(0, \sigma)\)</span></p>
<p><span class="math display">\[
\begin{aligned}
F &amp;= \frac{\frac{\text{SSR}_{\text{Reduced}}-\text{SSR}_{\text{Full}}}{p-q}}{\frac{\text{SSR}_{\text{Full}}}{n-(p+1)}} \\
&amp;=\frac{\frac{16,521,296-10,139,974}{3-2}}{\frac{10,139,974}{100-(3+1)}} \\
\end{aligned}
\]</span></p>
<div class="sourceCode" id="cb539"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb539-1"><a href="normal-error-regression-model.html#cb539-1" aria-hidden="true" tabindex="-1"></a>((SSR_wf_sqft<span class="sc">-</span>SSR_int)<span class="sc">/</span>(<span class="dv">3-2</span>))<span class="sc">/</span>((SSR_int)<span class="sc">/</span>(<span class="dv">100</span><span class="sc">-</span>(<span class="dv">3</span><span class="sc">+</span><span class="dv">1</span>)))</span></code></pre></div>
<pre><code>## [1] 60.41505</code></pre>
<div class="sourceCode" id="cb541"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb541-1"><a href="normal-error-regression-model.html#cb541-1" aria-hidden="true" tabindex="-1"></a>ts<span class="ot">=</span><span class="fl">60.41505</span></span>
<span id="cb541-2"><a href="normal-error-regression-model.html#cb541-2" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_dist</span>(<span class="st">&quot;f&quot;</span>, <span class="at">df1=</span><span class="dv">1</span>, <span class="at">df2=</span><span class="dv">96</span>, <span class="at">geom =</span> <span class="st">&quot;area&quot;</span>, <span class="at">fill =</span> <span class="sc">~</span> (<span class="fu">abs</span>(x)<span class="sc">&gt;!</span> <span class="fu">abs</span>(ts)), <span class="at">show.legend=</span><span class="cn">FALSE</span>) <span class="sc">+</span> <span class="fu">geom_vline</span>(<span class="at">xintercept=</span><span class="fu">c</span>(ts), <span class="at">color=</span><span class="st">&quot;red&quot;</span>)  <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;F&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-391-1.png" width="768" /></p>
<p><strong>p-value:</strong></p>
<div class="sourceCode" id="cb542"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb542-1"><a href="normal-error-regression-model.html#cb542-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span><span class="fu">pf</span>(ts, <span class="at">df1=</span><span class="dv">1</span>, <span class="at">df2=</span><span class="dv">96</span>)</span></code></pre></div>
<pre><code>## [1] 0.000000000008572476</code></pre>
<p>The probability-based F-test is used in the <code>anova</code> command.</p>
<div class="sourceCode" id="cb544"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb544-1"><a href="normal-error-regression-model.html#cb544-1" aria-hidden="true" tabindex="-1"></a>M_wf_SqFt <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>Houses, price<span class="sc">~</span>sqft_living <span class="sc">+</span> waterfront)</span>
<span id="cb544-2"><a href="normal-error-regression-model.html#cb544-2" aria-hidden="true" tabindex="-1"></a>M_House_Int <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>Houses, price<span class="sc">~</span>sqft_living <span class="sc">*</span> waterfront)</span>
<span id="cb544-3"><a href="normal-error-regression-model.html#cb544-3" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(M_wf_SqFt, M_House_Int)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: price ~ sqft_living + waterfront
## Model 2: price ~ sqft_living * waterfront
##   Res.Df      RSS Df Sum of Sq      F            Pr(&gt;F)    
## 1     97 16521296                                          
## 2     96 10139974  1   6381323 60.415 0.000000000008572 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Notice that this p-value is identical to the one we obtained in the previous section, using the <code>lm</code> command.</p>
</div>
</div>
<div id="regression-model-assumptions" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> Regression Model Assumptions<a href="normal-error-regression-model.html#regression-model-assumptions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="regression-assumptions" class="section level3 hasAnchor" number="5.4.1">
<h3><span class="header-section-number">5.4.1</span> Regression Assumptions<a href="normal-error-regression-model.html#regression-assumptions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s think carefully about what we are assuming in order to use the hypothesis tests and confidence intervals associated with the normal error regression model.</p>
<p>The statement <span class="math inline">\(Y_i = \beta_0 + \beta_1X_{i1}+ \ldots + \beta_pX_{ip} + \epsilon_i\)</span>, with <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0,\sigma)\)</span> implies the following:</p>
<ol style="list-style-type: decimal">
<li><p>Linearity: the expected value of <span class="math inline">\(Y\)</span> is a linear function of <span class="math inline">\(X_1, X_2, \ldots, X_p\)</span>. (This assumption is only relevent for models including at least one quantitative explanatory variable.)</p></li>
<li><p>Normality: Given the values of <span class="math inline">\(X_1, X_2, \ldots, X_p\)</span>, <span class="math inline">\(Y\)</span> follows a normal distribution.</p></li>
<li><p>Constant Variance: Regardless of the values of <span class="math inline">\(X_1, X_2, \ldots, X_p\)</span>, the variance (or standard deviation) in the normal distribution for <span class="math inline">\(Y\)</span> is the same.</p></li>
<li><p>Independence: each observation is independent of the rest.</p></li>
</ol>
<p><strong>Illustration of Model Assumptions</strong></p>
<p><img src="SLR_Model_Assumptions.png" width="50%" /></p>
<p>We know that these assumptions held true in the ice cream example, because we generated the data in a way that was consistent with these.</p>
<p>In practice, we will have only the data, without knowing the exact mechanism that produced it. We should only rely on the t-distribution based p-values and confidence intervals in the R output if these appear to be reasonable assumptions.</p>
<p>Of course, these assumptions will almost never be truly satisfied, but they should at least be a reasonable approximation if we are to draw meaningful conclusions.</p>
</div>
<div id="checking-model-assumptions" class="section level3 hasAnchor" number="5.4.2">
<h3><span class="header-section-number">5.4.2</span> Checking Model Assumptions<a href="normal-error-regression-model.html#checking-model-assumptions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The following plots are useful when assessing the appropriateness of the normal error regression model.</p>
<ol style="list-style-type: decimal">
<li><p>Scatterplot of residuals against predicted values</p></li>
<li><p>Histogram of standardized residuals</p>
<ul>
<li>heavy skewness indicates a problem with normality assumption</li>
</ul></li>
<li><p>Normal quantile plot</p>
<ul>
<li>severe departures from diagonal line indicate problem with normality assumption</li>
</ul></li>
</ol>
<p><strong>Residual vs Predicted Plots</strong></p>
<p>A residual vs predicted plot is useful for detecting issues with the linearity or constant variance assumption.</p>
<ul>
<li>curvature indicates a problem with linearity assumption<br />
</li>
<li>“funnel” or “megaphone” shape indicates problem with constant variance assumption</li>
</ul>
<div class="sourceCode" id="cb546"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb546-1"><a href="normal-error-regression-model.html#cb546-1" aria-hidden="true" tabindex="-1"></a>P1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>Violations, <span class="fu">aes</span>(<span class="at">y=</span>no_viol_Model<span class="sc">$</span>residuals, <span class="at">x=</span>no_viol_Model<span class="sc">$</span>fitted.values)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;No Violation&quot;</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Predicted Values&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Residuals&quot;</span>)</span>
<span id="cb546-2"><a href="normal-error-regression-model.html#cb546-2" aria-hidden="true" tabindex="-1"></a>P2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>Violations, <span class="fu">aes</span>(<span class="at">y=</span>lin_viol_Model<span class="sc">$</span>residuals, <span class="at">x=</span>no_viol_Model<span class="sc">$</span>fitted.values)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Violation of Linearity Assumption&quot;</span>)<span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Predicted Values&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Residuals&quot;</span>)</span>
<span id="cb546-3"><a href="normal-error-regression-model.html#cb546-3" aria-hidden="true" tabindex="-1"></a>P3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>Violations, <span class="fu">aes</span>(<span class="at">y=</span>cvar_viol_Model<span class="sc">$</span>residuals, <span class="at">x=</span>no_viol_Model<span class="sc">$</span>fitted.values)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Violation of Constant Variance Assumption&quot;</span>)<span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Predicted Values&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Residuals&quot;</span>)</span>
<span id="cb546-4"><a href="normal-error-regression-model.html#cb546-4" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(P1, P2, P3, <span class="at">ncol=</span><span class="dv">3</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-396-1.png" width="768" /></p>
<p>If there is only one explanatory variable, plotting the residuals against that variable reveals the same information as a residual vs predicted plot.</p>
<p><strong>Histogram of Residuals</strong></p>
<p>A histogram of the residuals is useful for assessing the normality assumption.</p>
<ul>
<li>Severe skewness indicates violation of normality assumption</li>
</ul>
<div class="sourceCode" id="cb547"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb547-1"><a href="normal-error-regression-model.html#cb547-1" aria-hidden="true" tabindex="-1"></a>P1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>Violations, <span class="fu">aes</span>(<span class="at">x=</span>no_viol_Model<span class="sc">$</span>residuals)) <span class="sc">+</span> <span class="fu">geom_histogram</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;No Violation&quot;</span>) <span class="sc">+</span><span class="fu">xlab</span>(<span class="st">&quot;Residual&quot;</span>)</span>
<span id="cb547-2"><a href="normal-error-regression-model.html#cb547-2" aria-hidden="true" tabindex="-1"></a>P2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>Violations, <span class="fu">aes</span>(<span class="at">x=</span>norm_viol_Model<span class="sc">$</span>residuals)) <span class="sc">+</span> <span class="fu">geom_histogram</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Violation of Normality Assumption&quot;</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Residual&quot;</span>)</span>
<span id="cb547-3"><a href="normal-error-regression-model.html#cb547-3" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(P1, P2, <span class="at">ncol=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-397-1.png" width="768" /></p>
<p><strong>Normal Quantile-Quantile (QQ) Plot</strong></p>
<p>Sometimes histograms can be inconclusive, especially when sample size is smaller.</p>
<p>A Normal quantile-quantile plot displays quantiles of the residuals against the expected quantiles of a normal distribution.</p>
<ul>
<li>Severe departures from diagonal line indicate a problem with normality assumption.</li>
</ul>
<div class="sourceCode" id="cb548"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb548-1"><a href="normal-error-regression-model.html#cb548-1" aria-hidden="true" tabindex="-1"></a>P1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>Violations, <span class="fu">aes</span>(<span class="at">sample =</span> <span class="fu">scale</span>(no_viol_Model<span class="sc">$</span>residuals))) <span class="sc">+</span> <span class="fu">stat_qq</span>() <span class="sc">+</span> <span class="fu">stat_qq_line</span>() <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Normal Quantiles&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Residual Quantiles&quot;</span>) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;No Violation&quot;</span>) <span class="sc">+</span> <span class="fu">xlim</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>,<span class="dv">4</span>)) <span class="sc">+</span> <span class="fu">ylim</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>,<span class="dv">4</span>))</span>
<span id="cb548-2"><a href="normal-error-regression-model.html#cb548-2" aria-hidden="true" tabindex="-1"></a>P2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>Violations, <span class="fu">aes</span>(<span class="at">sample =</span> <span class="fu">scale</span>(norm_viol_Model<span class="sc">$</span>residuals))) <span class="sc">+</span> <span class="fu">stat_qq</span>() <span class="sc">+</span> <span class="fu">stat_qq_line</span>() <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Normal Quantiles&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Residual Quantiles&quot;</span>) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Violation of Normality Assumption&quot;</span>) <span class="sc">+</span> <span class="fu">xlim</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>,<span class="dv">4</span>)) <span class="sc">+</span> <span class="fu">ylim</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>,<span class="dv">4</span>))</span>
<span id="cb548-3"><a href="normal-error-regression-model.html#cb548-3" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(P1, P2, <span class="at">ncol=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-398-1.png" width="768" /></p>
<p><strong>Checking Model Assumptions - Independence</strong></p>
<p>Independence is often difficult to assess through plots of data, but it is important to think about whether there were factors in the data collection that would cause some observations to be more highly correlated than others.</p>
<p>For example:</p>
<ol style="list-style-type: decimal">
<li>People in the study who are related.<br />
</li>
<li>Some plants grown in the same greenhouse and others in different greenhouses.<br />
</li>
<li>Some observations taken in same time period and others at different times.</li>
</ol>
<p>All of these require more complicated models that account for correlation using spatial and time structure.</p>
</div>
<div id="summary-of-checks-for-model-assumptions" class="section level3 hasAnchor" number="5.4.3">
<h3><span class="header-section-number">5.4.3</span> Summary of Checks for Model Assumptions<a href="normal-error-regression-model.html#summary-of-checks-for-model-assumptions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<colgroup>
<col width="52%" />
<col width="47%" />
</colgroup>
<thead>
<tr class="header">
<th>Model assumption</th>
<th>How to detect violation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Linearity</td>
<td>Curvature in residual plot</td>
</tr>
<tr class="even">
<td>Constant Variance</td>
<td>Funnel shape in residual plot</td>
</tr>
<tr class="odd">
<td>Normality</td>
<td>Skewness in histogram of residuals or departure from diag. line in QQ plot</td>
</tr>
<tr class="even">
<td>Independence</td>
<td>No graphical check, carefully examine data collection</td>
</tr>
</tbody>
</table>
</div>
<div id="example-n-v-s-lakes" class="section level3 hasAnchor" number="5.4.4">
<h3><span class="header-section-number">5.4.4</span> Example: N v S Lakes<a href="normal-error-regression-model.html#example-n-v-s-lakes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall our sample of 53 Florida Lakes, 33 in the north, and 20 in the south.</p>
<p><span class="math inline">\(\text{Mercury}_i = \beta_0 + \beta_1\times\text{I}_{\text{South}_i} + \epsilon_i\)</span>, where <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0, \sigma)\)</span>.</p>
<div class="sourceCode" id="cb549"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb549-1"><a href="normal-error-regression-model.html#cb549-1" aria-hidden="true" tabindex="-1"></a>LakesBP</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-399-1.png" width="768" /></p>
<p>When we use the normal error regression model, we are assuming the following:</p>
<ol style="list-style-type: decimal">
<li><p>Linearity: there is an expected mercury concentration for lakes in North Florida, and another for lakes in South Florida.</p></li>
<li><p>Normality: mercury concentrations of individual lakes in the north are normally distributed, and so are mercury concentrations in the south. These normal distributions might have different means.</p></li>
<li><p>Constant Variance: the normal distribution for mercury concentrations in North Florida has the same standard deviation as the normal distribution for mercury concentrations in South Florida</p></li>
<li><p>Independence: no two lakes are any more alike than any others, except for being in the north or south, which we account for in the model. We might have concerns about this, do to some lakes being geographically closer to each other than others.</p></li>
</ol>
<p>We should only use the p-values and confidence intervals provided by R, which depend on the t-distribution approximation, if we believe these assumptions are reasonable.</p>
<p>A residual by predicted plot, histogram of residuals, and normal quantile-quantile plot are shown below.</p>
<div class="sourceCode" id="cb550"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb550-1"><a href="normal-error-regression-model.html#cb550-1" aria-hidden="true" tabindex="-1"></a>P1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>FloridaLakes, <span class="fu">aes</span>(<span class="at">y=</span>Lakes_M<span class="sc">$</span>residuals, <span class="at">x=</span>Lakes_M<span class="sc">$</span>fitted.values)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Residual vs Predicted Plot&quot;</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Predicted Values&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Residuals&quot;</span>)</span>
<span id="cb550-2"><a href="normal-error-regression-model.html#cb550-2" aria-hidden="true" tabindex="-1"></a>P2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>FloridaLakes, <span class="fu">aes</span>(<span class="at">x=</span>Lakes_M<span class="sc">$</span>residuals)) <span class="sc">+</span> <span class="fu">geom_histogram</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Histogram of Residuals&quot;</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Residual&quot;</span>)</span>
<span id="cb550-3"><a href="normal-error-regression-model.html#cb550-3" aria-hidden="true" tabindex="-1"></a>P3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>FloridaLakes, <span class="fu">aes</span>(<span class="at">sample =</span> <span class="fu">scale</span>(Lakes_M<span class="sc">$</span>residuals))) <span class="sc">+</span> <span class="fu">stat_qq</span>() <span class="sc">+</span> <span class="fu">stat_qq_line</span>() <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Normal Quantiles&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Residual Quantiles&quot;</span>) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Normal QQ Plot&quot;</span>)</span>
<span id="cb550-4"><a href="normal-error-regression-model.html#cb550-4" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(P1, P2, P3, <span class="at">ncol=</span><span class="dv">3</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-400-1.png" width="960" /></p>
<p>Notice that we see two lines of predicted values and residuals. This makes sense since all lakes in North Florida will have the same predicted value, as will all lakes in Southern Florida.</p>
<p>There appears to be a little more variability in residuals for Southern Florida (on the right), than Northern Florida, causing some concern about the constant variance assumption.</p>
<p>Overall, though, the assumptions seem mostly reasonable.</p>
<p>We shouldn’t be concerned about using theory-based hypothesis tests or confidence intervals for the mean mercury level or difference in mean mercury levels. There might be some concern that prediction intervals could be either too wide or too narrow, but this is not a major concern, since the constant variance assumption is not severe.</p>
</div>
<div id="example-ph-model" class="section level3 hasAnchor" number="5.4.5">
<h3><span class="header-section-number">5.4.5</span> Example: pH Model<a href="normal-error-regression-model.html#example-ph-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall the regression line estimating the relationship between a lake’s mercury level and pH.</p>
<p><span class="math inline">\(\text{Mercury}_i = \beta_0 + \beta_1\times\text{pH}_i + \epsilon_i\)</span>, where <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0, \sigma)\)</span>.</p>
<p>The model assumes:</p>
<ol style="list-style-type: decimal">
<li><p>Linearity: the expected mercury level of a lake is a linear function of pH.</p></li>
<li><p>Normality: for any given pH, the mercury levels of lakes with that pH follow a normal distribution. For example, mercury levels for lakes with pH of 6 is are normally distributed, and mercury levels for lakes with pH of 9 are normally distributed, though these normal distributions may have different means.</p></li>
<li><p>Constant Variance: the variance (or standard deviation) in the normal distribution for mercury level is the same for each pH. For example, there is the same amount of variability associated with lakes with pH level 6, as pH level 8.</p></li>
<li><p>Independence: no two lakes are any more alike than any others, except with respect to pH, which is accounted for in the model. This may not be a reasonable assumption, but it’s unclear what the effects of such a violation would be.</p></li>
</ol>
<p>We should only use the p-values and confidence intervals provided by R, which depend on the t-distribution approximation, if we believe these assumptions are reasonable.</p>
<p>The plots for checking these assumptions are shown below.</p>
<div class="sourceCode" id="cb551"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb551-1"><a href="normal-error-regression-model.html#cb551-1" aria-hidden="true" tabindex="-1"></a>P1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>FloridaLakes, <span class="fu">aes</span>(<span class="at">y=</span>M_pH<span class="sc">$</span>residuals, <span class="at">x=</span>M_pH<span class="sc">$</span>fitted.values)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Residual vs Predicted Plot&quot;</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Predicted Values&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Residuals&quot;</span>)</span>
<span id="cb551-2"><a href="normal-error-regression-model.html#cb551-2" aria-hidden="true" tabindex="-1"></a>P2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>FloridaLakes, <span class="fu">aes</span>(<span class="at">x=</span>M_pH<span class="sc">$</span>residuals)) <span class="sc">+</span> <span class="fu">geom_histogram</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Histogram of Residuals&quot;</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Residual&quot;</span>)</span>
<span id="cb551-3"><a href="normal-error-regression-model.html#cb551-3" aria-hidden="true" tabindex="-1"></a>P3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>FloridaLakes, <span class="fu">aes</span>(<span class="at">sample =</span> <span class="fu">scale</span>(M_pH<span class="sc">$</span>residuals))) <span class="sc">+</span> <span class="fu">stat_qq</span>() <span class="sc">+</span> <span class="fu">stat_qq_line</span>() <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Normal Quantiles&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Residual Quantiles&quot;</span>) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Normal QQ Plot&quot;</span>)</span>
<span id="cb551-4"><a href="normal-error-regression-model.html#cb551-4" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(P1, P2, P3, <span class="at">ncol=</span><span class="dv">3</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-401-1.png" width="960" /></p>
<p>The residual vs predicted plot does not show any linear trend, and variability appears to be about the same for low predicted values as for high ones. Thus, the linearity and constant variance assumptions appear reasonable.</p>
<p>The histogram shows some right-skewness, and the right-most points on the normal-qq plot are above the line, indicating a possible concern with the normality assumption. There is some evidence of right-skewness, which might impact the appropriatness of the normal error regression model.</p>
<p>Nevertheless, we obtained similar results using the simulation-based results as the normal error regression model, suggesting that the concern about normality did not have much impact on the estimation of <span class="math inline">\(\beta_1\)</span>. It is possible that this concern could have implications for other kinds of inference, such as confidence intervals for an expected response, and prediction intervals, which we’ll explore later in the chapter.</p>
</div>
<div id="example-house-prices" class="section level3 hasAnchor" number="5.4.6">
<h3><span class="header-section-number">5.4.6</span> Example: House Prices<a href="normal-error-regression-model.html#example-house-prices" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall the model for estimating price of a house, using size, waterfront status, and an interaction term.</p>
<p><span class="math inline">\(\text{Price}_i = \beta_0 + \beta_1\text{Sq.Ft.}_{i}+ \beta_2\text{Waterfront}_{i}+ \beta_3\times\text{Sq.Ft.}_i\times\text{Waterfront}_{i} + \epsilon_i\)</span>, where <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0,\sigma)\)</span>.</p>
<p>The model assumes:</p>
<ol style="list-style-type: decimal">
<li><p>Linearity: the expected price of a house is a linear function of its size. The slope and intercept of this function may be different for houses on the waterfront, compared to houses not on the waterfront.</p></li>
<li><p>Normality: prices of houses of a given size and waterfront status are normally distributed.</p></li>
<li><p>Constant Variance: the variance (or standard deviation) in the normal distribution for prices is the same for all sizes and waterfront statuses.</p></li>
<li><p>Independence: no two houses are any more alike than any others, except with respect to size and waterfront status.</p></li>
</ol>
<p>We should only use the p-values and confidence intervals provided by R, which depend on the t-distribution approximation, if we believe these assumptions are reasonable.</p>
<p>Several reasons come to mind that might cause us to doubt the validity of these assumptions, but let’s investigate them emperically, using our data on 100 houses.</p>
<p>The plots for checking these assumptions are shown below.</p>
<div class="sourceCode" id="cb552"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb552-1"><a href="normal-error-regression-model.html#cb552-1" aria-hidden="true" tabindex="-1"></a>P1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>Houses, <span class="fu">aes</span>(<span class="at">y=</span>M_House_Int<span class="sc">$</span>residuals, <span class="at">x=</span>M_House_Int<span class="sc">$</span>fitted.values)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Residual vs Predicted Plot&quot;</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Predicted Values&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Residuals&quot;</span>)</span>
<span id="cb552-2"><a href="normal-error-regression-model.html#cb552-2" aria-hidden="true" tabindex="-1"></a>P2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>Houses, <span class="fu">aes</span>(<span class="at">x=</span>M_House_Int<span class="sc">$</span>residuals)) <span class="sc">+</span> <span class="fu">geom_histogram</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Histogram of Residuals&quot;</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Residual&quot;</span>)</span>
<span id="cb552-3"><a href="normal-error-regression-model.html#cb552-3" aria-hidden="true" tabindex="-1"></a>P3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>Houses, <span class="fu">aes</span>(<span class="at">sample =</span> <span class="fu">scale</span>(M_House_Int<span class="sc">$</span>residuals))) <span class="sc">+</span> <span class="fu">stat_qq</span>() <span class="sc">+</span> <span class="fu">stat_qq_line</span>() <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Normal Quantiles&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Residual Quantiles&quot;</span>) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Normal QQ Plot&quot;</span>)</span>
<span id="cb552-4"><a href="normal-error-regression-model.html#cb552-4" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(P1, P2, P3, <span class="at">ncol=</span><span class="dv">3</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-402-1.png" width="960" /></p>
<p>Although we might have had some initial concerns about the model assumptions, the plots do not raise any serious concerns. There is no sign of a nonlinear relationship in the residual vs predicted plot, so the linearity assumption appears reasonable.</p>
<p>There is possibly more variability associated with prices or more expensive houses than less expensive ones, so we might have some concerns about constant variance, but since there are only a few very high-priced houses, and the increasing variance is not too severe, this may not be much of a concern.</p>
<p>There are a few houses on each end of the normal qq plot that deviate from their expected line, but not very many. It’s not uncommon to have a few points deviate from the line on the end, so we do not have severe concerns about normality. The histogram of residuals is roughly symmetric.</p>
<p>Thus, the normal error regression model appears to be reasonable for these data.</p>
</div>
</div>
<div id="intervals-for-expected-response" class="section level2 hasAnchor" number="5.5">
<h2><span class="header-section-number">5.5</span> Intervals for Expected Response<a href="normal-error-regression-model.html#intervals-for-expected-response" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="parameter-values-and-expected-responses" class="section level3 hasAnchor" number="5.5.1">
<h3><span class="header-section-number">5.5.1</span> Parameter Values and Expected Responses<a href="normal-error-regression-model.html#parameter-values-and-expected-responses" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall that in Chapter 4, we saw two different types of confidence intervals. One type was for regression parameters, <span class="math inline">\(\beta_0, \beta_1, \ldots, \beta_p\)</span>, using estimate <span class="math inline">\(b_0, b_1, \ldots, b_p\)</span>. The other type was for expected responses, which involved estimating linear functions of these parameters, for example <span class="math inline">\(\beta_0 + 7\beta_1\)</span>.</p>
<p>Under the assumptions of a normal error regression model, we an approximate 95% confidence interval for regression parameter <span class="math inline">\(\beta_j\)</span> is given by</p>
<p><span class="math display">\[
b_j + \pm t^*\text{SE}(b_j),
\]</span></p>
<p>where <span class="math inline">\(t^*\approx 2\)</span>.</p>
<p>We’ve seen that in R, confidence intervals for regression parameters can be obtained through the <code>confint()</code> command.</p>
<p>A 95% confidence interval for an expected response <span class="math inline">\(E(Y_i|X_{i1}=x_{i1}, \ldots X_{ip}=x_{ip}) = \beta_0 + \beta_1x_{i1} + \ldots + \beta_px_{ip}\)</span> is estimated by</p>
<p><span class="math display">\[
b_0 + b_1x_{i1} + \ldots + b_px_{ip} + \pm t^*\text{SE}(b_0 + b_1x_{i1} + \ldots + b_px_{ip}),
\]</span></p>
<p>In this section, we’ll look more into confidence intervals for expected responses and also another kind of interval involving expected responses, called a prediction interval.</p>
<p>For notational purposes, well sometimes write <span class="math inline">\(E(Y_i|X_{i1}=x_{i1}, \ldots X_{ip}=x_{ip})\)</span> as <span class="math inline">\(E(Y|X)\)</span></p>
</div>
<div id="estimation-and-prediction" class="section level3 hasAnchor" number="5.5.2">
<h3><span class="header-section-number">5.5.2</span> Estimation and Prediction<a href="normal-error-regression-model.html#estimation-and-prediction" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall the ice cream dispenser that is known to dispense ice cream at a rate of 2 oz. per second on average, with individual amounts varying according to a normal distribution with mean 0 and standard deviation 0.5</p>
<p>Consider the following two questions:</p>
<ol style="list-style-type: decimal">
<li><p>On average, how much ice cream will be dispensed for people who press the dispenser for 1.5 seconds?</p></li>
<li><p>If a single person presses the dispenser for 1.5 seconds, how much ice cream will be dispensed?</p></li>
</ol>
<p>The first question is one of estimation. The second pertains to prediction.</p>
<p>When estimating expected responses and making predictions on new observations, there are two sources of variability we must consider.</p>
<ol style="list-style-type: decimal">
<li>We are using data to estimate <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, which introduces sampling variability.<br />
</li>
<li>Even if we did know <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, there is variability in individual observations, which follows a <span class="math inline">\(\mathcal{N}(0, \sigma)\)</span> distribution.</li>
</ol>
<p>In an estimation problem, we only need to think about (1). When predicting the value of a single new observation, we need to think about both (1) and (2).</p>
<p>Thus, intervals for predictions of individual observations carry more uncertainty and are wider than confidence intervals for <span class="math inline">\(E(Y|X)\)</span>.</p>
<p><img src="SLR_Model_Assumptions.png" width="50%" /></p>
</div>
<div id="estimation-and-prediction-in-slr" class="section level3 hasAnchor" number="5.5.3">
<h3><span class="header-section-number">5.5.3</span> Estimation and Prediction in SLR<a href="normal-error-regression-model.html#estimation-and-prediction-in-slr" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the estimation setting, we are trying to determine the location of the regression line for the entire population. Uncertainty comes from the fact that we only have data from a sample.</p>
<p>In the ice cream example, we can see that the blue line, fit to our data, is a good approximation of the “true” regression line that pertains to the mechanism from which the data were generated. It does, however, vary from the red line slightly due to sampling variability.</p>
<div class="sourceCode" id="cb553"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb553-1"><a href="normal-error-regression-model.html#cb553-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>Icecream1, <span class="fu">aes</span>(<span class="at">x=</span>time, <span class="at">y=</span>amount)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Icecream Dispensed&quot;</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Time Pressing dispenser&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Amount Dispensed&quot;</span>) <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="at">slope=</span><span class="dv">2</span>, <span class="at">intercept=</span><span class="dv">0</span>, <span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">+</span> <span class="fu">stat_smooth</span>(<span class="at">method=</span><span class="st">&quot;lm&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-404-1.png" width="672" /></p>
<div class="sourceCode" id="cb554"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb554-1"><a href="normal-error-regression-model.html#cb554-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(IC_Model)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = lm(amount ~ time), data = Icecream1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.8645 -0.3553  0.0685  0.2252  0.6963 
## 
## Coefficients:
##             Estimate Std. Error t value     Pr(&gt;|t|)    
## (Intercept)  -0.1299     0.3968  -0.327        0.749    
## time          2.0312     0.1598  12.714 0.0000000104 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.4527 on 13 degrees of freedom
## Multiple R-squared:  0.9256, Adjusted R-squared:  0.9198 
## F-statistic: 161.6 on 1 and 13 DF,  p-value: 0.00000001042</code></pre>
<div class="sourceCode" id="cb556"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb556-1"><a href="normal-error-regression-model.html#cb556-1" aria-hidden="true" tabindex="-1"></a>b0 <span class="ot">&lt;-</span> IC_Model<span class="sc">$</span>coefficients[<span class="dv">1</span>]</span>
<span id="cb556-2"><a href="normal-error-regression-model.html#cb556-2" aria-hidden="true" tabindex="-1"></a>b1 <span class="ot">&lt;-</span> IC_Model<span class="sc">$</span>coefficients[<span class="dv">2</span>]</span>
<span id="cb556-3"><a href="normal-error-regression-model.html#cb556-3" aria-hidden="true" tabindex="-1"></a>s <span class="ot">&lt;-</span> <span class="fu">sigma</span>(IC_Model)</span></code></pre></div>
<p>The first question:</p>
<p>“On average, how much ice cream will be dispensed for people who press the dispenser for 1.5 seconds?”</p>
<p>is a question of estimation. It is of the form, for a given <span class="math inline">\(X\)</span>, on average what do we expect to be true of <span class="math inline">\(Y\)</span>.</p>
<p>In the ice cream question, we can answer this exactly, since we know <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>.</p>
<p>In a real situation, we don’t know these and have to estimate them from the data, which introduces uncertainty.</p>
<p>Confidence interval for <span class="math inline">\(E(Y | (X=x))\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; b_0+b_1x^* \pm t^*SE(\hat{Y}|X=x^*) \\
&amp; b_0+b_1x^* \pm t^*\sqrt{\widehat{Var}(\hat{Y}|X=x^*)}
\end{aligned}
\]</span></p>
<p>The second question is a question of prediction. Even if we knew the true values of <span class="math inline">\(beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, we would not be able to given the exact amount dispensed for an individual user, since this varies between users.</p>
<p>Prediction interval for <span class="math inline">\(E(Y | (X=x))\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; b_0+b_1x^* \pm t^*\sqrt{\widehat{Var}(\hat{Y}|X=x^*) + s^2}
\end{aligned}
\]</span></p>
<p>The extra <span class="math inline">\(s^2\)</span> in the calculation of prediction variance comes from the uncertainty associated with individual observations.</p>
</div>
<div id="intervals-in-r" class="section level3 hasAnchor" number="5.5.4">
<h3><span class="header-section-number">5.5.4</span> Intervals in R<a href="normal-error-regression-model.html#intervals-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In R, we can obtain confidence intervals for an expected response and prediction intervals for an individual response using the <code>predict</code> command, with either <code>interval="confidence"</code> or <code>interval="prediction"</code>.</p>
<div class="sourceCode" id="cb557"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb557-1"><a href="normal-error-regression-model.html#cb557-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(IC_Model, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">time=</span><span class="fl">1.5</span>), <span class="at">interval =</span> <span class="st">&quot;confidence&quot;</span>, <span class="at">level=</span><span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 2.916965 2.523728 3.310201</code></pre>
<p>We are 95% confident that the mean amount of ice cream dispensed when the dispenser is held for 1.5 seconds is between 2.52 and 3.31 oz.</p>
<div class="sourceCode" id="cb559"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb559-1"><a href="normal-error-regression-model.html#cb559-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(IC_Model, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">time=</span><span class="fl">1.5</span>), <span class="at">interval =</span> <span class="st">&quot;prediction&quot;</span>, <span class="at">level=</span><span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 2.916965 1.862832 3.971097</code></pre>
<p>We are 95% confident that in individual who holds the dispenser for 1.5 seconds will get between 1.86 and 3.97 oz of ice cream.</p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-409-1.png" width="768" /></p>
<p>The prediction interval (in red) is wider than the confidence interval (in blue), since it must account for variability between individuals, in addition to sampling variability.</p>
<p><img src="C_P_Band.png" width="75%" /></p>
</div>
<div id="slr-calculations-optional" class="section level3 hasAnchor" number="5.5.5">
<h3><span class="header-section-number">5.5.5</span> SLR Calculations (Optional)<a href="normal-error-regression-model.html#slr-calculations-optional" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In simple linear regression,</p>
<p><span class="math display">\[
\begin{aligned}
SE(\hat{Y}|X=x^*) = \sqrt{\frac{1}{n}+ \frac{(x^*-\bar{x})^2}{\displaystyle\sum_{i=1}^n(x_i-\bar{x})^2}}
\end{aligned}
\]</span></p>
<p>Thus a confidence interval for <span class="math inline">\(E(Y | (X=x))\)</span> is:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; b_0+b_1x^* \pm t^*SE(\hat{Y}|X=x^*) \\
&amp; = b_0+b_1x^* \pm 2s\sqrt{\frac{1}{n}+ \frac{(x^*-\bar{x})^2}{\displaystyle\sum_{i=1}^n(x_i-\bar{x})^2}}  \
\end{aligned}
\]</span></p>
<p>A prediction interval for <span class="math inline">\(E(Y | (X=x))\)</span> is:</p>
<p><span class="math display">\[\beta_0 + \beta_1x^* \pm t^* s\sqrt{\left(\frac{1}{n}+ \frac{(x^*-\bar{x})^2}{\displaystyle\sum_{i=1}^n(x_i-\bar{x})^2}\right) + 1}
\]</span></p>
<p><strong>Calculations in Icecream example</strong></p>
<p>For <span class="math inline">\(x=1.5\)</span>, a confidence interval is:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; b_0+b_1x^* \pm t^*SE(\hat{Y}|X=x^*) \\
&amp; = b_0+b_1x^* \pm 2s\sqrt{\frac{1}{n}+ \frac{(x^*-\bar{x})^2}{\displaystyle\sum_{i=1}^n(x_i-\bar{x})^2}}  \\
&amp; = -0.1299087 + 2.0312489 \pm 20.4527185 \sqrt{\frac{1}{15}+ \frac{(1.5-2.3733)^2}{8.02933}}
\end{aligned}
\]</span></p>
<p>A prediction interval is:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; b_0+b_1x^* \pm t^*SE(\hat{Y}|X=x^*) \\
&amp; = b_0+b_1x^* \pm 2s\sqrt{\frac{1}{n}+ \frac{(x^*-\bar{x})^2}{\displaystyle\sum_{i=1}^n(x_i-\bar{x})^2}}  \\
&amp; = -0.1299087 + 2.0312489 \pm 20.4527185 \sqrt{\left(\frac{1}{15}+ \frac{(1.5-2.3733)^2}{8.02933}\right)+1}
\end{aligned}
\]</span></p>
</div>
<div id="car-price-and-acceleration-time" class="section level3 hasAnchor" number="5.5.6">
<h3><span class="header-section-number">5.5.6</span> Car Price and Acceleration Time<a href="normal-error-regression-model.html#car-price-and-acceleration-time" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We consider data from the Kelly Blue Book, pertaining to new cars, released in 2015. We’ll investigate the relationship between price, length, and time it takes to accelerate from 0 to 60 mph.</p>
<p><code>Price</code> represents the price of a standard (non-luxury) model of a car. <code>Acc060</code> represents time it takes to accelerate from 0 to 60 mph.</p>
<div class="sourceCode" id="cb561"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb561-1"><a href="normal-error-regression-model.html#cb561-1" aria-hidden="true" tabindex="-1"></a>CarsA060 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>Cars2015, <span class="fu">aes</span>(<span class="at">x=</span>Acc060, <span class="at">y=</span>Price)) <span class="sc">+</span> <span class="fu">geom_point</span>() </span>
<span id="cb561-2"><a href="normal-error-regression-model.html#cb561-2" aria-hidden="true" tabindex="-1"></a>CarsA060 <span class="sc">+</span> <span class="fu">stat_smooth</span>(<span class="at">method=</span><span class="st">&quot;lm&quot;</span>, <span class="at">se=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-412-1.png" width="672" /></p>
<p><span class="math inline">\(Price = \beta_0 + \beta_1\times\text{Acc. Time} , \text{where } \epsilon_i\sim\mathcal{N}(0, \sigma)\)</span></p>
<p>The model assumes expected price is a linear function of acceleration time.</p>
<p>Parameter Interpretations:</p>
<p><span class="math inline">\(\beta_0\)</span> represents intercept of regression line, i.e. expected price of a car that can accelerate from 0 to 60 mph in no time. This is not a meaningful interpretation in context.</p>
<p><span class="math inline">\(\beta_1\)</span> represents slope of regression line, i.e. expected change in price for each additional second it takes to accelerate from 0 to 60 mph.</p>
<div class="sourceCode" id="cb562"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb562-1"><a href="normal-error-regression-model.html#cb562-1" aria-hidden="true" tabindex="-1"></a>Cars_M_A060 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>Cars2015, Price<span class="sc">~</span>Acc060)</span>
<span id="cb562-2"><a href="normal-error-regression-model.html#cb562-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Cars_M_A060)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Price ~ Acc060, data = Cars2015)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -29.512  -6.544  -1.265   4.759  27.195 
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)  89.9036     5.0523   17.79 &lt;0.0000000000000002 ***
## Acc060       -7.1933     0.6234  -11.54 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 10.71 on 108 degrees of freedom
## Multiple R-squared:  0.5521, Adjusted R-squared:  0.548 
## F-statistic: 133.1 on 1 and 108 DF,  p-value: &lt; 0.00000000000000022</code></pre>
<p>** Model Interpretations**</p>
<p><span class="math inline">\(\widehat{Price} = b_0 + b_1\times\text{Acc. Time}\)</span></p>
<p><span class="math inline">\(\widehat{Price} = 89.90 - 7.193\times\text{Acc. Time}\)</span></p>
<ul>
<li><p>Intercept <span class="math inline">\(b_0\)</span> might be interpreted as the price of a car that can accelerate from 0 to 60 in no time, but this is not a meaningful interpretation since there are no such cars.</p></li>
<li><p><span class="math inline">\(b_1=-7.1933\)</span> tells us that on average, the price of a car is expected to decrease by 7.19 thousand dollars for each additional second it takes to accelerate from 0 to 60 mph.</p></li>
<li><p><span class="math inline">\(R^2 = 0.5521\)</span> tells us that 55% of the variation in price is explained by the linear model using acceleration time as the explanatory variable.</p></li>
</ul>
<ol style="list-style-type: decimal">
<li><p>What is a reasonable range for the average price of all new 2015 cars that can accelerate from 0 to 60 mph in 7 seconds?</p></li>
<li><p>If a car I am looking to buy can accelerate from 0 to 60 mph in 7 seconds, what price range should I expect?</p></li>
</ol>
<p>What is a reasonable range for the average price of all new 2015 cars that can accelerate from 0 to 60 mph in 7 seconds?</p>
<div class="sourceCode" id="cb564"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb564-1"><a href="normal-error-regression-model.html#cb564-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(Cars_M_A060, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">Acc060=</span><span class="dv">7</span>), <span class="at">interval=</span><span class="st">&quot;confidence&quot;</span>, <span class="at">level=</span><span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>##       fit      lwr      upr
## 1 39.5502 37.21856 41.88184</code></pre>
<p>We are 95% confident that the average price of new 2015 cars that accelerate from 0 to 60 mph in 7 seconds is between 37.2 and 41.9 thousand dollars.</p>
<p>Note: this is a confidence interval for <span class="math inline">\(\beta_0 -7\beta_1\)</span>.</p>
<p>If a car I am looking to buy can accelerate from 0 to 60 mph in 7 seconds, what price range should I expect?</p>
<div class="sourceCode" id="cb566"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb566-1"><a href="normal-error-regression-model.html#cb566-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(Cars_M_A060, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">Acc060=</span><span class="dv">7</span>), <span class="at">interval=</span><span class="st">&quot;prediction&quot;</span>, <span class="at">level=</span><span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>##       fit      lwr      upr
## 1 39.5502 18.19826 60.90215</code></pre>
<p>We are 95% confident that a single new 2015 car that accelerates from 0 to 60 mph in 7 seconds will cost between 18.2 and 60.9 thousand dollars.</p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-416-1.png" width="768" /></p>
</div>
<div id="florida-lakes-est.-and-pred." class="section level3 hasAnchor" number="5.5.7">
<h3><span class="header-section-number">5.5.7</span> Florida Lakes Est. and Pred.<a href="normal-error-regression-model.html#florida-lakes-est.-and-pred." class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><p>Calculate an interval that we are 95% confident contains the mean mercury concentration for all lakes in Northern Florida. Do the same for Southern Florida.</p></li>
<li><p>Calculate an interval that we are 95% confident contains the mean mercury concentration for an individual lake in Northern Florida. Do the same for a lake in Southern Florida.</p></li>
</ol>
<div class="sourceCode" id="cb568"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb568-1"><a href="normal-error-regression-model.html#cb568-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(Lakes_M, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">Location=</span><span class="fu">c</span>(<span class="st">&quot;N&quot;</span>, <span class="st">&quot;S&quot;</span>)), <span class="at">interval=</span><span class="st">&quot;confidence&quot;</span>, <span class="at">level=</span><span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>##         fit       lwr       upr
## 1 0.4245455 0.3137408 0.5353501
## 2 0.6965000 0.5541689 0.8388311</code></pre>
<p>We are 95% confident that the mean mercury level in North Florida is between 0.31 and 0.54 ppm.<br />
We are 95% confident that the mean mercury level in South Florida is between 0.55 and 0.84 ppm.<br />
Note: these are confidence intervals for <span class="math inline">\(\beta_0\)</span>, and <span class="math inline">\(\beta_0 + \beta_1\)</span>, respectively.</p>
<div class="sourceCode" id="cb570"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb570-1"><a href="normal-error-regression-model.html#cb570-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(Lakes_M, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">Location=</span><span class="fu">c</span>(<span class="st">&quot;N&quot;</span>, <span class="st">&quot;S&quot;</span>)), <span class="at">interval=</span><span class="st">&quot;prediction&quot;</span>, <span class="at">level=</span><span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>##         fit         lwr      upr
## 1 0.4245455 -0.22155101 1.070642
## 2 0.6965000  0.04425685 1.348743</code></pre>
<p>We are 95% confident that an individual lake in North Florida will have mercury level between 0 and 1.07 ppm.</p>
<p>We are 95% confident that the mean mercury level in South Florida is between 0.04 and 1.35 ppm.</p>
<p>Note that the normality assumption, which allows for negative mercury levels leads to a somewhat nonsensical result.</p>
</div>
</div>
<div id="transformations" class="section level2 hasAnchor" number="5.6">
<h2><span class="header-section-number">5.6</span> Transformations<a href="normal-error-regression-model.html#transformations" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this section, we’ll explore an approach we can sometimes use when model assumptions are not satisfied.</p>
<div id="cars-assumptions-check" class="section level3 hasAnchor" number="5.6.1">
<h3><span class="header-section-number">5.6.1</span> Cars Assumptions Check<a href="normal-error-regression-model.html#cars-assumptions-check" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb572"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb572-1"><a href="normal-error-regression-model.html#cb572-1" aria-hidden="true" tabindex="-1"></a>P1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>Cars2015, <span class="fu">aes</span>(<span class="at">y=</span>Cars_M_A060<span class="sc">$</span>residuals, <span class="at">x=</span>Cars_M_A060<span class="sc">$</span>fitted.values)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Residual Plot&quot;</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Predicted Values&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Residuals&quot;</span>)</span>
<span id="cb572-2"><a href="normal-error-regression-model.html#cb572-2" aria-hidden="true" tabindex="-1"></a>P2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>Cars2015, <span class="fu">aes</span>(<span class="at">x=</span>Cars_M_A060<span class="sc">$</span>residuals)) <span class="sc">+</span> <span class="fu">geom_histogram</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Histogram of Residuals&quot;</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Residual&quot;</span>)</span>
<span id="cb572-3"><a href="normal-error-regression-model.html#cb572-3" aria-hidden="true" tabindex="-1"></a>P3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>Cars2015, <span class="fu">aes</span>(<span class="at">sample =</span> <span class="fu">scale</span>(Cars_M_A060<span class="sc">$</span>residuals))) <span class="sc">+</span> <span class="fu">stat_qq</span>() <span class="sc">+</span> <span class="fu">stat_qq_line</span>() <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Normal Quantiles&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Residual Quantiles&quot;</span>) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Normal QQ Plot&quot;</span>)</span>
<span id="cb572-4"><a href="normal-error-regression-model.html#cb572-4" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(P1, P2, P3, <span class="at">ncol=</span><span class="dv">3</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-419-1.png" width="1152" /></p>
<p>There is a funnel-shape in the residual plot, indicating a concern about the constant variance assumption. There appears to be more variability in prices for more expensive cars than for cheaper cars. There is also some concern about the normality assumption, as the histogram and QQ plot indicate right-skew in the residuals.</p>
</div>
<div id="log-transformation" class="section level3 hasAnchor" number="5.6.2">
<h3><span class="header-section-number">5.6.2</span> Log Transformation<a href="normal-error-regression-model.html#log-transformation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>When residual plots yield model inadequacy, we might try to correct these by applying a transformation to the response variable.</p>
<p>When working a nonnegative, right-skewed response variable, it is often helpful to work with the logarithm of the response variable.</p>
<p>Note: In R, <code>log()</code> denotes the natural (base e) logarithm, often denoted <code>ln()</code>. We can actually use any logarithm, but the natural logarithm is commonly used.</p>
</div>
<div id="log-transform-for-car-prices" class="section level3 hasAnchor" number="5.6.3">
<h3><span class="header-section-number">5.6.3</span> Log Transform for Car Prices<a href="normal-error-regression-model.html#log-transform-for-car-prices" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><span class="math display">\[
\text{Log Price} = \beta_0 + \beta_1\times \text{Acc060} + \epsilon_i , \text{ where } \epsilon_i\sim\mathcal{N}(0, \sigma)
\]</span></p>
<div class="sourceCode" id="cb573"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb573-1"><a href="normal-error-regression-model.html#cb573-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>Cars2015, <span class="fu">aes</span>(<span class="at">x=</span>Acc060, <span class="at">y=</span><span class="fu">log</span>(Price))) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb573-2"><a href="normal-error-regression-model.html#cb573-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Acceleration Time&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Log of Price&quot;</span>) <span class="sc">+</span> </span>
<span id="cb573-3"><a href="normal-error-regression-model.html#cb573-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Acceleration Time and Log Price&quot;</span>) <span class="sc">+</span> <span class="fu">stat_smooth</span>(<span class="at">method=</span><span class="st">&quot;lm&quot;</span>, <span class="at">se=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-420-1.png" width="672" /></p>
<div class="sourceCode" id="cb574"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb574-1"><a href="normal-error-regression-model.html#cb574-1" aria-hidden="true" tabindex="-1"></a>Cars_M_Log <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>Cars2015, <span class="fu">log</span>(Price)<span class="sc">~</span>Acc060)</span>
<span id="cb574-2"><a href="normal-error-regression-model.html#cb574-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Cars_M_Log)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(Price) ~ Acc060, data = Cars2015)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.84587 -0.19396  0.00908  0.18615  0.53350 
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)  5.13682    0.13021   39.45 &lt;0.0000000000000002 ***
## Acc060      -0.22064    0.01607  -13.73 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.276 on 108 degrees of freedom
## Multiple R-squared:  0.6359, Adjusted R-squared:  0.6325 
## F-statistic: 188.6 on 1 and 108 DF,  p-value: &lt; 0.00000000000000022</code></pre>
<p><strong>Log Transformation Model - What We’re Assuming</strong></p>
<ol style="list-style-type: decimal">
<li><p>Linearity: the log of expected price of a car is a linear function of its acceleration time.</p></li>
<li><p>Normality: for any given acceleration time, the log of prices of actual cars follow a normal distribution.</p></li>
<li><p>Constant Variance: the normal distribution for log of price is the same for all acceleration times.</p></li>
<li><p>Independence: no two cars are any more alike than any others.</p></li>
</ol>
<p>We should only use the p-values and confidence intervals provided by R, which depend on the t-distribution approximation, if we believe these assumptions are reasonable.</p>
<p><strong>Assumption Check for Model on Log Price</strong></p>
<div class="sourceCode" id="cb576"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb576-1"><a href="normal-error-regression-model.html#cb576-1" aria-hidden="true" tabindex="-1"></a>P1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>Cars2015, <span class="fu">aes</span>(<span class="at">y=</span>Cars_M_Log<span class="sc">$</span>residuals, <span class="at">x=</span>Cars_M_Log<span class="sc">$</span>fitted.values)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Cars Log Model Residual Plot&quot;</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Predicted Values&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Residuals&quot;</span>)</span>
<span id="cb576-2"><a href="normal-error-regression-model.html#cb576-2" aria-hidden="true" tabindex="-1"></a>P2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>Cars2015, <span class="fu">aes</span>(<span class="at">x=</span>Cars_M_Log<span class="sc">$</span>residuals)) <span class="sc">+</span> <span class="fu">geom_histogram</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Histogram of Residuals&quot;</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Residual&quot;</span>)</span>
<span id="cb576-3"><a href="normal-error-regression-model.html#cb576-3" aria-hidden="true" tabindex="-1"></a>P3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>Cars2015, <span class="fu">aes</span>(<span class="at">sample =</span> <span class="fu">scale</span>(Cars_M_Log<span class="sc">$</span>residuals))) <span class="sc">+</span> <span class="fu">stat_qq</span>() <span class="sc">+</span> <span class="fu">stat_qq_line</span>() <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Normal Quantiles&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Residual Quantiles&quot;</span>) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Cars Model QQ Plot&quot;</span>)</span>
<span id="cb576-4"><a href="normal-error-regression-model.html#cb576-4" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(P1, P2, P3, <span class="at">ncol=</span><span class="dv">3</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-422-1.png" width="864" /></p>
<p>There is still some concern about constant variance, though perhaps not as much. The normality assumption appears more reasonable.</p>
</div>
<div id="log-model-predictions" class="section level3 hasAnchor" number="5.6.4">
<h3><span class="header-section-number">5.6.4</span> Log Model Predictions<a href="normal-error-regression-model.html#log-model-predictions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Prediction Equation:</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{\text{Price}} &amp; = e^{5.13582-0.22064 \times \text{Acc060}}
\end{aligned}
\]</span></p>
<p>Predicted price for car that takes 7 seconds to accelerate:</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{\text{Price}} &amp; = e^{5.13582-0.22064 \times \text{7}} = 36.3
\end{aligned}
\]</span></p>
<p>Predicted price for car that takes 10 seconds to accelerate:</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{\text{Price}} &amp; = e^{5.13582-0.22064 \times \text{10}}= 18.7
\end{aligned}
\]</span></p>
<p>Predictions are for log(Price), so we need to exponentiate.</p>
<div class="sourceCode" id="cb577"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb577-1"><a href="normal-error-regression-model.html#cb577-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(Cars_M_Log, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">Acc060=</span><span class="fu">c</span>(<span class="dv">7</span>)))</span></code></pre></div>
<pre><code>##        1 
## 3.592343</code></pre>
<div class="sourceCode" id="cb579"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb579-1"><a href="normal-error-regression-model.html#cb579-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">predict</span>(Cars_M_Log, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">Acc060=</span><span class="fu">c</span>(<span class="dv">7</span>))))</span></code></pre></div>
<pre><code>##        1 
## 36.31908</code></pre>
<p>A car that accelerates from 0 to 60 mph in 7 seconds is expected to cost 36.3 thousand dollars.</p>
</div>
<div id="log-model-interpretations" class="section level3 hasAnchor" number="5.6.5">
<h3><span class="header-section-number">5.6.5</span> Log Model Interpretations<a href="normal-error-regression-model.html#log-model-interpretations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><span class="math display">\[
\begin{aligned}
\text{Log of Expected Price} &amp; = \beta_0 + \beta_1\times \text{Acc060}\  \text{, Thus:} \\
\text{ Expected Price} &amp; = e^{\beta_0 + \beta_1\times \text{Acc060} } \\
&amp; e^{\beta_0}e^{\beta_1 \times \text{Acc060}} \\
&amp; e^{\beta_0}(e^{\beta_1})^\text{Acc060}
\end{aligned}
\]</span></p>
<ul>
<li><p><span class="math inline">\(e^{\beta_0}\)</span> is theoretically the expected price of a car that can accelerate from 0 to 60 mph in no time, but this is not a meaningful interpretation.</p></li>
<li><p>For each additional second it takes a car to accelerate, price is expected to multiply by a factor of <span class="math inline">\(e^{b_1}\)</span>.</p></li>
</ul>
<p>Exponentiating the model coefficients gives:</p>
<div class="sourceCode" id="cb581"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb581-1"><a href="normal-error-regression-model.html#cb581-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(Cars_M_Log<span class="sc">$</span>coefficients)</span></code></pre></div>
<pre><code>## (Intercept)      Acc060 
## 170.1730148   0.8020062</code></pre>
<ul>
<li>For each additional second in acceleration time, price is expected to multiply by a a factor of <span class="math inline">\(e^{-0.22} = 0.80\)</span>. Thus, each 1-second increase in acceleration time is estimated to be associated with a 20% drop in price, on average.</li>
</ul>
</div>
<div id="log-model-ci-for-beta_0-beta_1" class="section level3 hasAnchor" number="5.6.6">
<h3><span class="header-section-number">5.6.6</span> Log Model CI for <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span><a href="normal-error-regression-model.html#log-model-ci-for-beta_0-beta_1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb583"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb583-1"><a href="normal-error-regression-model.html#cb583-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(Cars_M_Log)</span></code></pre></div>
<pre><code>##                  2.5 %     97.5 %
## (Intercept)  4.8787105  5.3949208
## Acc060      -0.2524862 -0.1887916</code></pre>
<div class="sourceCode" id="cb585"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb585-1"><a href="normal-error-regression-model.html#cb585-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">confint</span>(Cars_M_Log))</span></code></pre></div>
<pre><code>##                   2.5 %     97.5 %
## (Intercept) 131.4610408 220.284693
## Acc060        0.7768669   0.827959</code></pre>
<ul>
<li>We are 95% confident that the price of a car changes, on average, by multiplicative factor between <span class="math inline">\(e^{-0.252} = 0.7773\)</span> and <span class="math inline">\(e^{-0.189}=0.828\)</span> for each additional second in acceleration time. That is, we believe the price decreases between 17% and 23% on average for each additional second in acceleration time.</li>
</ul>
</div>
<div id="log-model-ci-for-expected-response" class="section level3 hasAnchor" number="5.6.7">
<h3><span class="header-section-number">5.6.7</span> Log Model CI for Expected Response<a href="normal-error-regression-model.html#log-model-ci-for-expected-response" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb587"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb587-1"><a href="normal-error-regression-model.html#cb587-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(Cars_M_Log, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">Acc060=</span><span class="fu">c</span>(<span class="dv">7</span>)), <span class="at">interval=</span><span class="st">&quot;confidence&quot;</span>)</span></code></pre></div>
<pre><code>##        fit     lwr      upr
## 1 3.592343 3.53225 3.652436</code></pre>
<div class="sourceCode" id="cb589"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb589-1"><a href="normal-error-regression-model.html#cb589-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">predict</span>(Cars_M_Log, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">Acc060=</span><span class="fu">c</span>(<span class="dv">7</span>)), <span class="at">interval=</span><span class="st">&quot;confidence&quot;</span>))</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 36.31908 34.20083 38.56852</code></pre>
<p>We are 95% confident that the mean price amoung all cars that accelerate from 0 to 60 mph in 7 seconds is between <span class="math inline">\(e^{3.53225} =34.2\)</span> and <span class="math inline">\(e^{3.652436}=38.6\)</span> thousand dollars.</p>
</div>
<div id="log-model-prediction-interval" class="section level3 hasAnchor" number="5.6.8">
<h3><span class="header-section-number">5.6.8</span> Log Model Prediction Interval<a href="normal-error-regression-model.html#log-model-prediction-interval" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb591"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb591-1"><a href="normal-error-regression-model.html#cb591-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(Cars_M_Log, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">Acc060=</span><span class="fu">c</span>(<span class="dv">7</span>)), <span class="at">interval=</span><span class="st">&quot;prediction&quot;</span>)</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 3.592343 3.042041 4.142645</code></pre>
<div class="sourceCode" id="cb593"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb593-1"><a href="normal-error-regression-model.html#cb593-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">predict</span>(Cars_M_Log, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">Acc060=</span><span class="fu">c</span>(<span class="dv">7</span>)), <span class="at">interval=</span><span class="st">&quot;prediction&quot;</span>))</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 36.31908 20.94796 62.96917</code></pre>
<p>We are 95% confident that the expected price for a car that accelerates from 0 to 60 mph in 7 seconds is between <span class="math inline">\(e^{3.04} =20.9\)</span> and <span class="math inline">\(e^{4.14}=63.9\)</span> thousand dollars.</p>
</div>
<div id="confidence-interval-comparison" class="section level3 hasAnchor" number="5.6.9">
<h3><span class="header-section-number">5.6.9</span> Confidence Interval Comparison<a href="normal-error-regression-model.html#confidence-interval-comparison" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>95% Confidence interval for average price of cars that take 7 seconds to accelerate:</p>
<p>Original Model:</p>
<div class="sourceCode" id="cb595"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb595-1"><a href="normal-error-regression-model.html#cb595-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(Cars_M_A060, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">Acc060=</span><span class="dv">7</span>), <span class="at">interval=</span><span class="st">&quot;confidence&quot;</span>, <span class="at">level=</span><span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>##       fit      lwr      upr
## 1 39.5502 37.21856 41.88184</code></pre>
<p>Transformed Model:</p>
<div class="sourceCode" id="cb597"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb597-1"><a href="normal-error-regression-model.html#cb597-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">predict</span>(Cars_M_Log, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">Acc060=</span><span class="fu">c</span>(<span class="dv">7</span>)), <span class="at">interval=</span><span class="st">&quot;confidence&quot;</span>, <span class="at">level=</span><span class="fl">0.95</span>))</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 36.31908 34.20083 38.56852</code></pre>
</div>
<div id="prediction-interval-comparison" class="section level3 hasAnchor" number="5.6.10">
<h3><span class="header-section-number">5.6.10</span> Prediction Interval Comparison<a href="normal-error-regression-model.html#prediction-interval-comparison" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>95% Prediction interval for price of an individual car that takes 7 seconds to accelerate:</p>
<p>Original Model:</p>
<div class="sourceCode" id="cb599"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb599-1"><a href="normal-error-regression-model.html#cb599-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(Cars_M_A060, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">Acc060=</span><span class="dv">7</span>), <span class="at">interval=</span><span class="st">&quot;prediction&quot;</span>, <span class="at">level=</span><span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>##       fit      lwr      upr
## 1 39.5502 18.19826 60.90215</code></pre>
<p>Transformed Model:</p>
<div class="sourceCode" id="cb601"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb601-1"><a href="normal-error-regression-model.html#cb601-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">predict</span>(Cars_M_Log, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">Acc060=</span><span class="fu">c</span>(<span class="dv">7</span>)), <span class="at">interval=</span><span class="st">&quot;prediction&quot;</span>, <span class="at">level=</span><span class="fl">0.95</span>))</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 36.31908 20.94796 62.96917</code></pre>
<p>Notice that the transformed interval is not symmetric and allows for a longer “tail” on the right than the left.</p>
</div>
<div id="log-model-visualization" class="section level3 hasAnchor" number="5.6.11">
<h3><span class="header-section-number">5.6.11</span> Log Model Visualization<a href="normal-error-regression-model.html#log-model-visualization" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-436-1.png" width="960" /></p>
<p>The log model suggests an nonlinear trend in price with respect to acceleration time and gives wider confidence and prediction intervals for cars that accelerate faster and tend to be more expensive. It also gives non-symmetric intervals. These results appear to be consistent with the observed data.</p>
</div>
<div id="comments-on-transformations" class="section level3 hasAnchor" number="5.6.12">
<h3><span class="header-section-number">5.6.12</span> Comments on Transformations<a href="normal-error-regression-model.html#comments-on-transformations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>We could have used another transformation, such as <span class="math inline">\(\sqrt{\text{Price}}\)</span></p></li>
<li><p>The log tranform leads to a nice interpretation involving percent change. Other transformations might yield better predictions, but are often hard to interpret.</p></li>
<li><p>There is often a tradeoff between model complexity and interpretability. We’ll talk more about this.</p></li>
<li><p>We did an example of a transformation in a model with a single explanatory variable.</p></li>
<li><p>If the explanatory variable is categorical:<br />
- <span class="math inline">\(e^{\beta_0}\)</span> represents the expected response in the baseline category<br />
- <span class="math inline">\(e^{\beta_j}\)</span> represents the number of times larger the expected response in category <span class="math inline">\(j\)</span> is, compared to the baseline category.</p></li>
<li><p>When working with multiple regression models, it is still important to mention holding other variables constant when interpreting parameters associated with one of the variables.</p></li>
</ul>
</div>
</div>
<div id="case-studies" class="section level2 hasAnchor" number="5.7">
<h2><span class="header-section-number">5.7</span> Case Studies<a href="normal-error-regression-model.html#case-studies" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this section, we’ll examine three case studies and think about what we should or shouldn’t conclude in each situation.</p>
<div id="flights-from-ny-to-chi" class="section level3 hasAnchor" number="5.7.1">
<h3><span class="header-section-number">5.7.1</span> Flights from NY to CHI<a href="normal-error-regression-model.html#flights-from-ny-to-chi" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A traveler lives in New York and wants to fly to Chicago. They consider flying out of two New York airports:</p>
<ul>
<li>Newark (EWR)<br />
</li>
<li>LaGuardia (LGA)</li>
</ul>
<p>We have data on the times of flights from both airports to Chicago’s O’Hare airport from 2013 (more than 14,000 flights).</p>
<p>Assuming these flights represent a random sample of all flights from these airports to Chicago, consider how the traveler might use this information to decide which airport to fly out of.</p>
<div class="sourceCode" id="cb603"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb603-1"><a href="normal-error-regression-model.html#cb603-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(nycflights13)</span>
<span id="cb603-2"><a href="normal-error-regression-model.html#cb603-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(flights)</span>
<span id="cb603-3"><a href="normal-error-regression-model.html#cb603-3" aria-hidden="true" tabindex="-1"></a>flights<span class="sc">$</span>origin <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(flights<span class="sc">$</span>origin)</span>
<span id="cb603-4"><a href="normal-error-regression-model.html#cb603-4" aria-hidden="true" tabindex="-1"></a>flights<span class="sc">$</span>dest <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(flights<span class="sc">$</span>dest)</span>
<span id="cb603-5"><a href="normal-error-regression-model.html#cb603-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb603-6"><a href="normal-error-regression-model.html#cb603-6" aria-hidden="true" tabindex="-1"></a>Flights_NY_CHI <span class="ot">&lt;-</span> flights <span class="sc">%&gt;%</span> </span>
<span id="cb603-7"><a href="normal-error-regression-model.html#cb603-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(origin <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;EWR&quot;</span>, <span class="st">&quot;LGA&quot;</span>) <span class="sc">&amp;</span> dest <span class="sc">==</span><span class="st">&quot;ORD&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb603-8"><a href="normal-error-regression-model.html#cb603-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(origin, dest, air_time)</span></code></pre></div>
<div class="sourceCode" id="cb604"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb604-1"><a href="normal-error-regression-model.html#cb604-1" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>Flights_NY_CHI, <span class="fu">aes</span>(<span class="at">x=</span>air_time, <span class="at">fill=</span>origin, <span class="at">color=</span>origin)) <span class="sc">+</span> <span class="fu">geom_density</span>(<span class="at">alpha=</span><span class="fl">0.2</span>) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Flight Time&quot;</span>)</span>
<span id="cb604-2"><a href="normal-error-regression-model.html#cb604-2" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>Flights_NY_CHI, <span class="fu">aes</span>(<span class="at">x=</span>air_time, <span class="at">y=</span>origin)) <span class="sc">+</span> <span class="fu">geom_boxplot</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Flight Time&quot;</span>)</span>
<span id="cb604-3"><a href="normal-error-regression-model.html#cb604-3" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(p1, p2, <span class="at">ncol=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-438-1.png" width="768" /></p>
<div class="sourceCode" id="cb605"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb605-1"><a href="normal-error-regression-model.html#cb605-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(knitr)</span>
<span id="cb605-2"><a href="normal-error-regression-model.html#cb605-2" aria-hidden="true" tabindex="-1"></a>T <span class="ot">&lt;-</span> Flights_NY_CHI <span class="sc">%&gt;%</span> <span class="fu">group_by</span>(origin) <span class="sc">%&gt;%</span> </span>
<span id="cb605-3"><a href="normal-error-regression-model.html#cb605-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">Mean_Airtime =</span> <span class="fu">mean</span>(air_time, <span class="at">na.rm=</span><span class="cn">TRUE</span>), </span>
<span id="cb605-4"><a href="normal-error-regression-model.html#cb605-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">SD =</span> <span class="fu">sd</span>(air_time, <span class="at">na.rm=</span><span class="cn">TRUE</span>), <span class="at">n=</span><span class="fu">sum</span>(<span class="sc">!</span><span class="fu">is.na</span>(air_time)))</span>
<span id="cb605-5"><a href="normal-error-regression-model.html#cb605-5" aria-hidden="true" tabindex="-1"></a><span class="fu">kable</span>(T)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">origin</th>
<th align="right">Mean_Airtime</th>
<th align="right">SD</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">EWR</td>
<td align="right">113.2603</td>
<td align="right">9.987122</td>
<td align="right">5828</td>
</tr>
<tr class="even">
<td align="left">LGA</td>
<td align="right">115.7998</td>
<td align="right">9.865270</td>
<td align="right">8507</td>
</tr>
</tbody>
</table>
<p><strong>Model for Flights Data</strong></p>
<div class="sourceCode" id="cb606"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb606-1"><a href="normal-error-regression-model.html#cb606-1" aria-hidden="true" tabindex="-1"></a>M_Flights <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>Flights_NY_CHI, air_time<span class="sc">~</span>origin)</span>
<span id="cb606-2"><a href="normal-error-regression-model.html#cb606-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(M_Flights)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = air_time ~ origin, data = Flights_NY_CHI)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -26.26  -7.26  -1.26   5.20  84.74 
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept) 113.2603     0.1299  872.06 &lt;0.0000000000000002 ***
## originLGA     2.5395     0.1686   15.06 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 9.915 on 14333 degrees of freedom
##   (622 observations deleted due to missingness)
## Multiple R-squared:  0.01558,    Adjusted R-squared:  0.01551 
## F-statistic: 226.9 on 1 and 14333 DF,  p-value: &lt; 0.00000000000000022</code></pre>
<p><strong>Confidence Interval</strong></p>
<div class="sourceCode" id="cb608"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb608-1"><a href="normal-error-regression-model.html#cb608-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(M_Flights)</span></code></pre></div>
<pre><code>##                 2.5 %     97.5 %
## (Intercept) 113.00572 113.514871
## originLGA     2.20905   2.869984</code></pre>
<p><strong>Question:</strong> If you were flying from New York to Chicago, would this information influence which airport you would fly out of? If so, which would you be more likely to choose?</p>
</div>
<div id="smoking-during-pregnancy" class="section level3 hasAnchor" number="5.7.2">
<h3><span class="header-section-number">5.7.2</span> Smoking During Pregnancy<a href="normal-error-regression-model.html#smoking-during-pregnancy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Many studies have shown that a mother’s smoking during pregnancy puts a baby at risk of low birth weight.</p>
<p>We have data on the from a sample of 80 babies born in North Carolina in 2004. Thirty of the mothers were smokers, and fifty were nonsmokers.</p>
<div class="sourceCode" id="cb610"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb610-1"><a href="normal-error-regression-model.html#cb610-1" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>NCBirths, <span class="fu">aes</span>(<span class="at">x=</span>weight, <span class="at">fill=</span>habit, <span class="at">color=</span>habit)) <span class="sc">+</span> <span class="fu">geom_density</span>(<span class="at">alpha=</span><span class="fl">0.2</span>) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Birthweight and Smoking&quot;</span>)</span>
<span id="cb610-2"><a href="normal-error-regression-model.html#cb610-2" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>NCBirths, <span class="fu">aes</span>(<span class="at">x=</span>weight, <span class="at">y=</span>habit)) <span class="sc">+</span> <span class="fu">geom_boxplot</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Birthweight and Smoking&quot;</span>)</span>
<span id="cb610-3"><a href="normal-error-regression-model.html#cb610-3" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(p1, p2, <span class="at">ncol=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-443-1.png" width="768" /></p>
<div class="sourceCode" id="cb611"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb611-1"><a href="normal-error-regression-model.html#cb611-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(knitr)</span>
<span id="cb611-2"><a href="normal-error-regression-model.html#cb611-2" aria-hidden="true" tabindex="-1"></a>T <span class="ot">&lt;-</span> NCBirths <span class="sc">%&gt;%</span> <span class="fu">group_by</span>(habit) <span class="sc">%&gt;%</span> <span class="fu">summarize</span>(<span class="at">Mean_Weight =</span> <span class="fu">mean</span>(weight), <span class="at">SD =</span> <span class="fu">sd</span>(weight), <span class="at">n=</span><span class="fu">n</span>())</span>
<span id="cb611-3"><a href="normal-error-regression-model.html#cb611-3" aria-hidden="true" tabindex="-1"></a><span class="fu">kable</span>(T)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">habit</th>
<th align="right">Mean_Weight</th>
<th align="right">SD</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">nonsmoker</td>
<td align="right">7.039200</td>
<td align="right">1.709388</td>
<td align="right">50</td>
</tr>
<tr class="even">
<td align="left">smoker</td>
<td align="right">6.616333</td>
<td align="right">1.106418</td>
<td align="right">30</td>
</tr>
</tbody>
</table>
<p><strong>Model for Birth Weights Data</strong></p>
<div class="sourceCode" id="cb612"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb612-1"><a href="normal-error-regression-model.html#cb612-1" aria-hidden="true" tabindex="-1"></a>M_Birthwt <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>NCBirths, weight<span class="sc">~</span>habit)</span>
<span id="cb612-2"><a href="normal-error-regression-model.html#cb612-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(M_Birthwt)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = weight ~ habit, data = NCBirths)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.0392 -0.6763  0.2372  0.8280  2.4437 
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)   7.0392     0.2140   32.89 &lt;0.0000000000000002 ***
## habitsmoker  -0.4229     0.3495   -1.21                0.23    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.514 on 78 degrees of freedom
## Multiple R-squared:  0.01842,    Adjusted R-squared:  0.005834 
## F-statistic: 1.464 on 1 and 78 DF,  p-value: 0.23</code></pre>
<p><strong>Confidence Interval</strong></p>
<div class="sourceCode" id="cb614"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb614-1"><a href="normal-error-regression-model.html#cb614-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(M_Birthwt)</span></code></pre></div>
<pre><code>##                 2.5 %    97.5 %
## (Intercept)  6.613070 7.4653303
## habitsmoker -1.118735 0.2730012</code></pre>
<p><strong>Question:</strong></p>
<p>What should we conclude about the effect of smoking on birth weight based on these results?</p>
</div>
<div id="smoking-during-pregnancy-cont" class="section level3 hasAnchor" number="5.7.3">
<h3><span class="header-section-number">5.7.3</span> Smoking During Pregnancy (cont)<a href="normal-error-regression-model.html#smoking-during-pregnancy-cont" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In fact, this sample of 80 babies is part of a larger dataset, consisting of 1,000 babies born in NC in 2004. When we consider the full dataset, notice that the difference between the groups is similar, but the p-value is much smaller, providing stronger evidence of a relationship between a mother’s smoking and lower birthweight.</p>
<div class="sourceCode" id="cb616"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb616-1"><a href="normal-error-regression-model.html#cb616-1" aria-hidden="true" tabindex="-1"></a>M_Birthwt_Full <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>ncbirths, weight<span class="sc">~</span>habit)</span>
<span id="cb616-2"><a href="normal-error-regression-model.html#cb616-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(M_Birthwt_Full)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = weight ~ habit, data = ncbirths)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.1443 -0.7043  0.1657  0.9157  4.6057 
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)  7.14427    0.05086 140.472 &lt;0.0000000000000002 ***
## habitsmoker -0.31554    0.14321  -2.203              0.0278 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.503 on 997 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.004846,   Adjusted R-squared:  0.003848 
## F-statistic: 4.855 on 1 and 997 DF,  p-value: 0.02779</code></pre>
</div>
<div id="exam-scores" class="section level3 hasAnchor" number="5.7.4">
<h3><span class="header-section-number">5.7.4</span> Exam Scores<a href="normal-error-regression-model.html#exam-scores" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Exam 1 vs Exam 2 scores for intro stat students at another college.</p>
<p>The blue line represents the least squares regression line, while the red line represents the line <span class="math inline">\(y=x\)</span>.</p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-448-1.png" width="768" /></p>
<p>Notice that out of the seven highest scoring students on Exam 1 (above 90), only two improved on Exam 2. Meanwhile, out of the six students who score lowest (below 70) on Exam 1, five improved on Exam 2.</p>
<p>One conclusion would be that the students who did best on Exam 1 didn’t study as hard and weren’t as prepared for Exam 2 as they were for Exam 1, while the students who scored lower worked harder and were better prepared for Exam 2 than they were for Exam 1.</p>
<p>While the above explanation is plausible, there is another possible explanation for this behavior. Think about what it might be.</p>
</div>
<div id="simulating-the-regression-effect" class="section level3 hasAnchor" number="5.7.5">
<h3><span class="header-section-number">5.7.5</span> Simulating the Regression Effect<a href="normal-error-regression-model.html#simulating-the-regression-effect" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We simulate test scores under the assumption that each person’s score on an exam is a combination of their true level of understanding, and a “luck” factor, simulated from a normal distribution.</p>
<p>We assume that each student’s true level of understanding is exactly the same on the second exam as on the first.</p>
<p>The numbers on the graph indicate the student’s true level of understanding.</p>
<div class="sourceCode" id="cb618"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb618-1"><a href="normal-error-regression-model.html#cb618-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10172023</span>)</span>
<span id="cb618-2"><a href="normal-error-regression-model.html#cb618-2" aria-hidden="true" tabindex="-1"></a>Understanding <span class="ot">&lt;-</span><span class="fu">runif</span>(<span class="dv">50</span>,<span class="dv">55</span>,<span class="dv">95</span>)</span>
<span id="cb618-3"><a href="normal-error-regression-model.html#cb618-3" aria-hidden="true" tabindex="-1"></a>Score1 <span class="ot">&lt;-</span> Understanding <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">50</span>, <span class="dv">0</span>, <span class="dv">5</span>)</span>
<span id="cb618-4"><a href="normal-error-regression-model.html#cb618-4" aria-hidden="true" tabindex="-1"></a>Score2 <span class="ot">&lt;-</span> Understanding <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">50</span>, <span class="dv">0</span>, <span class="dv">5</span>)</span>
<span id="cb618-5"><a href="normal-error-regression-model.html#cb618-5" aria-hidden="true" tabindex="-1"></a>Understanding <span class="ot">&lt;-</span> <span class="fu">round</span>(Understanding,<span class="dv">0</span>)</span>
<span id="cb618-6"><a href="normal-error-regression-model.html#cb618-6" aria-hidden="true" tabindex="-1"></a>Score1 <span class="ot">&lt;-</span> <span class="fu">round</span>(Score1,<span class="dv">0</span>)</span>
<span id="cb618-7"><a href="normal-error-regression-model.html#cb618-7" aria-hidden="true" tabindex="-1"></a>Score2 <span class="ot">&lt;-</span> <span class="fu">round</span>(Score2,<span class="dv">0</span>)</span>
<span id="cb618-8"><a href="normal-error-regression-model.html#cb618-8" aria-hidden="true" tabindex="-1"></a>TestSim <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(Understanding, Score1, Score2)</span>
<span id="cb618-9"><a href="normal-error-regression-model.html#cb618-9" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>TestSim, <span class="fu">aes</span>(<span class="at">y=</span>Score2, <span class="at">x=</span>Score1))<span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">stat_smooth</span>(<span class="at">method=</span><span class="st">&quot;lm&quot;</span>) <span class="sc">+</span></span>
<span id="cb618-10"><a href="normal-error-regression-model.html#cb618-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope=</span><span class="dv">1</span>, <span class="at">color=</span><span class="st">&quot;red&quot;</span>) <span class="sc">+</span> <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label=</span>Understanding), <span class="at">vjust =</span> <span class="dv">0</span>, <span class="at">nudge_y =</span> <span class="fl">0.5</span>) <span class="sc">+</span> </span>
<span id="cb618-11"><a href="normal-error-regression-model.html#cb618-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="fu">c</span>(<span class="dv">50</span>,<span class="dv">105</span>)) <span class="sc">+</span> <span class="fu">ylim</span>(<span class="fu">c</span>(<span class="dv">50</span>,<span class="dv">105</span>))</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-449-1.png" width="768" /></p>
<p><strong>Highest Exam 1 Scores</strong></p>
<div class="sourceCode" id="cb619"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb619-1"><a href="normal-error-regression-model.html#cb619-1" aria-hidden="true" tabindex="-1"></a><span class="fu">kable</span>(<span class="fu">head</span>(TestSim<span class="sc">%&gt;%</span><span class="fu">arrange</span>(<span class="fu">desc</span>(Score1))))</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">Understanding</th>
<th align="right">Score1</th>
<th align="right">Score2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">93</td>
<td align="right">97</td>
<td align="right">92</td>
</tr>
<tr class="even">
<td align="right">90</td>
<td align="right">97</td>
<td align="right">85</td>
</tr>
<tr class="odd">
<td align="right">88</td>
<td align="right">95</td>
<td align="right">85</td>
</tr>
<tr class="even">
<td align="right">93</td>
<td align="right">94</td>
<td align="right">103</td>
</tr>
<tr class="odd">
<td align="right">95</td>
<td align="right">94</td>
<td align="right">93</td>
</tr>
<tr class="even">
<td align="right">79</td>
<td align="right">89</td>
<td align="right">81</td>
</tr>
</tbody>
</table>
<p><strong>Lowest Exam 1 Scores</strong></p>
<div class="sourceCode" id="cb620"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb620-1"><a href="normal-error-regression-model.html#cb620-1" aria-hidden="true" tabindex="-1"></a><span class="fu">kable</span>(<span class="fu">head</span>(TestSim<span class="sc">%&gt;%</span><span class="fu">arrange</span>(Score1)))</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">Understanding</th>
<th align="right">Score1</th>
<th align="right">Score2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">55</td>
<td align="right">49</td>
<td align="right">61</td>
</tr>
<tr class="even">
<td align="right">60</td>
<td align="right">54</td>
<td align="right">57</td>
</tr>
<tr class="odd">
<td align="right">60</td>
<td align="right">56</td>
<td align="right">59</td>
</tr>
<tr class="even">
<td align="right">58</td>
<td align="right">57</td>
<td align="right">52</td>
</tr>
<tr class="odd">
<td align="right">66</td>
<td align="right">60</td>
<td align="right">71</td>
</tr>
<tr class="even">
<td align="right">63</td>
<td align="right">61</td>
<td align="right">62</td>
</tr>
</tbody>
</table>
<p>This phenomenon is called the <strong>regression effect</strong>.</p>
</div>
<div id="nfl-wins" class="section level3 hasAnchor" number="5.7.6">
<h3><span class="header-section-number">5.7.6</span> NFL Wins<a href="normal-error-regression-model.html#nfl-wins" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Wins by NFL teams in 2021 and 2022</p>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-452-1.png" width="768" /></p>
</div>
</div>
<div id="impact-of-model-assumption-violations" class="section level2 hasAnchor" number="5.8">
<h2><span class="header-section-number">5.8</span> Impact of Model Assumption Violations<a href="normal-error-regression-model.html#impact-of-model-assumption-violations" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this chapter, we’ve studied the normal error regression model and its underlying assumptions. We’ve seen that when these assumptions are realistic, we can use distributions derived from probability theory, such as t and F distributions to approximate sampling distributions, in place of the simulation-based methods seen in Chapters 3 and 4.</p>
<p>Of course, real data don’t come exactly from processes like the fictional ice cream dispenser described in Section 5.1, so it’s really a question of whether this model is a realistic approximation (or simplification) of the true mechanism that led to the data we observe. We can use diagnostics like residual and Normal-QQ plots, as well as our intuition and background knowledge to assess whether the normal error regression model is a reasonable approximation.</p>
<p>The p-values provided by the <code>lm</code> summary output, and <code>anova</code> commands, and the and intervals produced by the <code>confint</code>, and <code>predict</code> command, as well as many other R commands, depend on the assumptions of the normal error regression model, and should only be used when these assumptions are reasonable.</p>
<p>In situations where some model assumptions appear to be violated, we might be okay using certain tests/intervals, but not others. In general, we should proceed with caution in these situations.</p>
<p>The table below provides guidance on the potential impact of model assumption violation on predicted values, confidence intervals, and prediction intervals.</p>
<table>
<colgroup>
<col width="12%" />
<col width="11%" />
<col width="44%" />
<col width="30%" />
</colgroup>
<thead>
<tr class="header">
<th>Model assumption Violated</th>
<th>Predicted Values</th>
<th>Confidence Intervals</th>
<th>Prediction Intervals</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Linearity</td>
<td>Unreliable</td>
<td>Unreliable</td>
<td>Unreliable</td>
</tr>
<tr class="even">
<td>Constant Variance</td>
<td>Reliable</td>
<td>Somewhat unreliable - Some too wide, others too narrow</td>
<td>Very unreliable - Some too wide, others too narrow</td>
</tr>
<tr class="odd">
<td>Normality</td>
<td>Reliable</td>
<td>Possibly unreliable - might be symmetric when they shouldn’t be. Might be okay when skewness isn’t bad and sample size is large.</td>
<td>Very unreliable - will be symmetric when they shouldn’t be</td>
</tr>
<tr class="even">
<td>Independence</td>
<td>might be reliable</td>
<td>unreliable - either too wide or too narrow</td>
<td>unreliable - either too wide or too narrow</td>
</tr>
</tbody>
</table>
<p>When model assumptions are a concern, consider a using a transformation of the data, a more advanced model, or a more flexible technique, such as a nonparametric approach or statistical machine learning algorithm.</p>
<!---

## The Regression Effect

### The Regression Effect

You might be wondering how regression gets its name. It comes from a well known phenomenon, known as "regression to the mean", or the "regression effect". While the word "regression" is often construed with a negative context (i.e. getting worse), it could also refer to movement in the positive direction.  

Exam 1 vs Exam 2 scores for intro stat students at another college

<img src="bookdownproj_files/figure-html/unnamed-chunk-453-1.png" width="768" />

What is the relationship between scores on the two exams? 

### The Regression Effect

Exam 1 vs Exam 2 scores for intro stat students at another college

<img src="bookdownproj_files/figure-html/unnamed-chunk-454-1.png" width="768" />

How many of the 6 students who scored below 70 on Exam 1 improved their scores on Exam 2?

How many of the 7 students who scored above 90 improved on Exam 2?

### The Regression Effect

A low score on an exam is often the result of both poor preparation and bad luck.

A high score often results from both good preparation and good luck. 

While changes in study habits and preparation likely explain some improvement in low scores, we would also expect the lowest performers to improve simply because of better luck. 

Likewise, some of the highest performers may simply not be as lucky on exam 2, so a small dropoff should not be interpreted as weaker understanding of the exam material.


### Simulating Regression Effect {.smaller}


```r
set.seed(110322018)
Understanding <-rnorm(25, 80, 10)
Score1 <- Understanding + rnorm(25, 0, 5)
Score2 <- Understanding + rnorm(25, 0, 5)
Understanding <- round(Understanding,0)
TestSim <- data.frame(Understanding, Score1, Score2)
ggplot(data=TestSim, aes(y=Score2, x=Score1))+ geom_point() + stat_smooth(method="lm") +
  geom_abline(slope=1) + geom_text(aes(label=Understanding), vjust = 0, nudge_y = 0.5)
```

<img src="bookdownproj_files/figure-html/unnamed-chunk-455-1.png" width="768" />

This phenomon is called the **regression effect**.

### Test Scores Simulation - Highest Scores



```r
kable(head(TestSim%>%arrange(desc(Score1))))
```



| Understanding|   Score1|   Score2|
|-------------:|--------:|--------:|
|            97| 98.86412| 93.60285|
|            89| 98.57157| 88.25851|
|            94| 97.23330| 92.65175|
|            91| 93.92857| 98.23312|
|            85| 93.66503| 88.70963|
|            93| 92.06243| 88.67015|

These students' success on test 1 is due to a strong understanding and good luck. We would expect the understanding to carry over to test 2 (provided the student continues to study in a similar way), but not necessarily the luck. 

### Test Scores Simulation - Lowest Scores



```r
kable(head(TestSim%>%arrange(Score1)))
```



| Understanding|   Score1|   Score2|
|-------------:|--------:|--------:|
|            58| 54.44354| 50.30597|
|            69| 59.86641| 77.04696|
|            61| 61.35228| 65.54305|
|            66| 65.22433| 73.45304|
|            75| 65.87041| 80.79416|
|            72| 69.53082| 74.96092|

These students' lack of success on test 1 is due to a low understanding and poor luck. We would expect the understanding to carry over to test 2 (unless the student improves their preparation), but not necessarily the luck. 

### Another Example

Wins by NFL teams in 2021 and 2022

<img src="bookdownproj_files/figure-html/unnamed-chunk-458-1.png" width="768" />

### Other Examples of Regression Effect {.smaller}

A 1973 article by Kahneman, D. and Tversky, A., "On the Psychology of Prediction," Pysch. Rev. 80:237-251 describes an instance of the regression effect in the training of Israeli air force pilots. 

Trainees were praised after performing well and criticized after performing badly. The flight instructors observed that "high praise for good execution of complex maneuvers typically results in a decrement of performance on the next try." 

Kahneman and Tversky write that :

*"We normally reinforce others when their behavior is good and punish them when their behavior is bad. By regression alone, therefore, they [the trainees] are most likely to improve after being punished and most likely to deteriorate after being rewarded. Consequently, we are exposed to a lifetime schedule in which we are most often rewarded for punishing others, and punished for rewarding."*


## Responsible Statistical Inference   


### Statistical Significance vs Practical Importance

* “(S)cientists have embraced and even avidly pursued meaningless differences solely because they are statistically significant, and have ignored important effects because they failed to pass the screen of statistical significance...It is a safe bet that people have suffered or died because scientists (and editors, regulators, journalists and others) have used significance tests to interpret results, and have consequently failed to identify the most beneficial courses of action.” -ASA statement on p-values, 2016

### What a p-value tells us

Performing responsible statistical inference requires understanding what p-values do and do not tell us, and how they should and should not be interpreted.   

* A low p-value tells us that the data we observed are inconsistent with our null hypothesis or some assumption we make in our model.    

* A large p-value tells us that the data we observed could have plausibly been obtained under our supposed model and null hypothesis.   

* A p-value never provides evidence supporting the null hypothesis, it only tells us the strength of evidence against it.   

* A p-value is impacted by  
    - the size of the difference between group, or change per unit increase (effect size)     
    - the amount of variability in the data    
    - the sample size     
    
* Sometimes, a p-value tells us more about sample size, than relationship we're actually interested in. 

* A p-value does not tell us the "size" of a difference or effect, or whether it is practically meaningful. 


### Flights from New York to Chicago

A traveler lives in New York and wants to fly to Chicago. They consider flying out of two New York airports:   

* Newark (EWR)     
* LaGuardia (LGA)    

We have data on the times of flights from both airports to Chicago's O'Hare airport from 2013 (more than 14,000 flights). 

Assuming these flights represent a random sample of all flights from these airports to Chicago, consider how the traveler might use this information to decide which airport to fly out of. 


```r
library(nycflights13)
data(flights)
flights$origin <- as.factor(flights$origin)
flights$dest <- as.factor(flights$dest)
```


We'll create a dataset containing only flights from Newark and Laguardia to O'Hare, and only the variables we're interested in. 


```r
Flights_NY_CHI <- flights %>% 
  filter(origin %in% c("EWR", "LGA") & dest =="ORD") %>%
  select(origin, dest, air_time)
```

### Visualizing New York to Chicago Flights


```r
p1 <- ggplot(data=Flights_NY_CHI, aes(x=air_time, fill=origin, color=origin)) + geom_density(alpha=0.2) + ggtitle("Flight Time")
p2 <- ggplot(data=Flights_NY_CHI, aes(x=air_time, y=origin)) + geom_boxplot() + ggtitle("Flight Time")
grid.arrange(p1, p2, ncol=2)
```

<img src="bookdownproj_files/figure-html/unnamed-chunk-461-1.png" width="768" />


```r
library(knitr)
T <- Flights_NY_CHI %>% group_by(origin) %>% 
  summarize(Mean_Airtime = mean(air_time, na.rm=TRUE), 
            SD = sd(air_time, na.rm=TRUE), n=sum(!is.na(air_time)))
kable(T)
```



|origin | Mean_Airtime|       SD|    n|
|:------|------------:|--------:|----:|
|EWR    |     113.2603| 9.987122| 5828|
|LGA    |     115.7998| 9.865270| 8507|

**Question:** If you were flying from New York to Chicago, would this information influence which airport you would fly out of? If so, which would you be more likely to choose?   


### Model for Airlines Data


```r
M_Flights <- lm(data=Flights_NY_CHI, air_time~origin)
summary(M_Flights)
```

```
## 
## Call:
## lm(formula = air_time ~ origin, data = Flights_NY_CHI)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -26.26  -7.26  -1.26   5.20  84.74 
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(>|t|)    
## (Intercept) 113.2603     0.1299  872.06 <0.0000000000000002 ***
## originLGA     2.5395     0.1686   15.06 <0.0000000000000002 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 9.915 on 14333 degrees of freedom
##   (622 observations deleted due to missingness)
## Multiple R-squared:  0.01558,    Adjusted R-squared:  0.01551 
## F-statistic: 226.9 on 1 and 14333 DF,  p-value: < 0.00000000000000022
```

### Confidence Interval for Flights


```r
confint(M_Flights)
```

```
##                 2.5 %     97.5 %
## (Intercept) 113.00572 113.514871
## originLGA     2.20905   2.869984
```


* Flights from LGA are estimated to take 2.5 minutes longer than flights from EWR on average. 

* The very low p-value provides strong evidence of a difference in mean flight time. 

* We are 95% confident that flights from LGA to ORD take between 2.2 and 2.9 minutes longer, on average, than flights from EWR to ORD. 

### Flights Conclusions?

Although we have a low p-value, indicating a discernable difference, the size of this difference (2-3 minutes in airtime) is very small. A travelor would most likely have other, more important considerations when deciding which airport to fly from.  

The low p-value is due to the very large sample size, rather than the size of the difference.   

Note: there is also some question about whether it is appropriate to use a hypothesis test or confidence interval here at all. We have data on all flights in 2013, so one could argue that we have the entire population already. Perhaps, we could view this as a sample and generalize to flights in other years, though conditions change, so it is not clear that these flights from 2013 would be representative of flights in other years.  

### Smoking and Birthweight Example

We consider data on the relationship between a pregnant mother's smoking and the birthweight of the baby. Data come from a sample of 80 babies born in North Carolina in 2004. Thirty of the mothers were smokers, and fifty were nonsmokers. 




```r
p1 <- ggplot(data=NCBirths, aes(x=weight, fill=habit, color=habit)) + geom_density(alpha=0.2) + ggtitle("Birthweight and Smoking")
p2 <- ggplot(data=NCBirths, aes(x=weight, y=habit)) + geom_boxplot() + ggtitle("Birthweight and Smoking")
grid.arrange(p1, p2, ncol=2)
```

<img src="bookdownproj_files/figure-html/unnamed-chunk-466-1.png" width="768" />


```r
library(knitr)
T <- NCBirths %>% group_by(habit) %>% summarize(Mean_Weight = mean(weight), SD = sd(weight), n=n())
kable(T)
```



|habit     | Mean_Weight|       SD|  n|
|:---------|-----------:|--------:|--:|
|nonsmoker |    7.039200| 1.709388| 50|
|smoker    |    6.616333| 1.106418| 30|

### Model for Birthweight


```r
M_Birthwt <- lm(data=NCBirths, weight~habit)
summary(M_Birthwt)
```

```
## 
## Call:
## lm(formula = weight ~ habit, data = NCBirths)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.0392 -0.6763  0.2372  0.8280  2.4437 
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(>|t|)    
## (Intercept)   7.0392     0.2140   32.89 <0.0000000000000002 ***
## habitsmoker  -0.4229     0.3495   -1.21                0.23    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.514 on 78 degrees of freedom
## Multiple R-squared:  0.01842,    Adjusted R-squared:  0.005834 
## F-statistic: 1.464 on 1 and 78 DF,  p-value: 0.23
```

### Conclusions from Birthweight Data


```r
confint(M_Birthwt)
```

```
##                 2.5 %    97.5 %
## (Intercept)  6.613070 7.4653303
## habitsmoker -1.118735 0.2730012
```


* The average birtweight of babies whose mothers are smokers is estimated to be about 0.42 lbs less than the average birthweight for babies whose mothers are nonsmokers. 

* The large p-value of 0.23, tells us that there is not enough evidence to say that a mother's smoking is associated with lower birthweights. It is plausible that this difference could have occurred by chance.  

* We are 95% confident that the average birtweight of babies whose mothers are smokers is between 1.12 lbs less and 0.27 lbs more than the average birthweight for babies whose mothers are nonsmokers.   

**Question:**
Many studies have shown that a mother's smoking puts a baby at risk of low birthweight. Do our results contradict this research? Should we conclude that smoking has no impact on birthweights? 


### Impact of Small Sample Size

Notice that we observed a difference of about 0.4 lbs. in mean birthweight, which is a considerable difference. 

The large p-value is mosty due to the relatively small sample size. Even though we observed a mean difference of 0.4 lbs, the sample is to small to allow us to say conclusively that smoking is associated with lower birthweights. 

This is very different from concluding that smoking does not impact birthweight.  

This is an example of why we should never "accept the null hypothesis" or say that our data "support the null hypothesis."

### Larger Dataset

In fact, this sample of 80 babies is part of a larger dataset, consisting of 1,000 babies born in NC in 2004. When we consider the full dataset, notice that the difference between the groups is similar, but the p-value is much smaller, providing stronger evidence of a relationship between a mother's smoking and lower birthweight.  


```r
M_Birthwt_Full <- lm(data=ncbirths, weight~habit)
summary(M_Birthwt_Full)
```

```
## 
## Call:
## lm(formula = weight ~ habit, data = ncbirths)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.1443 -0.7043  0.1657  0.9157  4.6057 
## 
## Coefficients:
##             Estimate Std. Error t value            Pr(>|t|)    
## (Intercept)  7.14427    0.05086 140.472 <0.0000000000000002 ***
## habitsmoker -0.31554    0.14321  -2.203              0.0278 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.503 on 997 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.004846,   Adjusted R-squared:  0.003848 
## F-statistic: 4.855 on 1 and 997 DF,  p-value: 0.02779
```


### Cautions and Advice

**p-values are only (a small) part of a statistical analysis.** 

* For small samples, real differences might not be statistically significant.       
      -Don't accept null hypothesis. Gather more information.    
* For large, even very small differences will be statistically significant.    
      -Look at confidence interval. Is difference practically important?     
* When many hypotheses are tested at once (such as many food items) some will produce a significant result just by change.     
       -Use a multiple testing correction, such as Bonferroni   
* Interpret p-values on a “sliding scale”     
     - 0.049 is practically the same as 0.051
* Is sample representative of larger population?    
* Were treatments randomly assigned (for experiments)?    
* Are there other variables to consider?


--->

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="bootstrap-interval-estimation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="building-models-for-interpretation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/Stat255-LU/Notes/edit/master/05-Normal_Error_Regression_Model.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/Stat255-LU/Notes/blob/master/05-Normal_Error_Regression_Model.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
